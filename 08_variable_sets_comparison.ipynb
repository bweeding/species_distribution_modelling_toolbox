{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Sets Comparison: Final Variables vs Optimal Variables\n",
    "\n",
    "This notebook compares the `final_variable_set` from Variable Importance Analysis with `optimal_variables` from Spatial Spread Analysis and creates 2 optimized variable sets as arrays.\n",
    "\n",
    "## Overview:\n",
    "- **Variable Comparison**: Compare final variables from both approaches\n",
    "- **Overlap Analysis**: Analyze common and unique variables\n",
    "- **Performance Assessment**: Evaluate variable set performance\n",
    "- **2 Variable Sets Creation**: Generate optimized sets as arrays (Common Variables and Best Performing)\n",
    "- **Variable Name Cleaning**: Remove prefixes and handle special variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "#specie = 'leptocybe-invasa'  # Target species: 'leptocybe-invasa' or 'thaumastocoris-peregrinus'\n",
    "# training = 'south-east-asia' \n",
    "# bio = bio1  # Bioclimatic variable identifier\n",
    "savefig = True  # Set to True to save figures\n",
    "\n",
    "# Optional filters (leave empty to include all results)\n",
    "model_prefixes = []  # e.g., ['CHELSA', 'MPI-ESM']\n",
    "scenarios = []       # e.g., ['historical', 'future']\n",
    "\n",
    "# Paths\n",
    "base_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')  # Figures directory\n",
    "results_path = os.path.join(os.path.dirname(os.getcwd()), 'results')  # Figures directory\n",
    "# results_path = os.path.join(base_path, \"results\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(figs_path, exist_ok=True)\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable Name Cleaning Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VARIABLE NAME CLEANING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def infer_model_prefix(var_list):\n",
    "    \"\"\"Infer model prefix directly from variable names when metadata is missing.\"\"\"\n",
    "    for var in var_list:\n",
    "        if not isinstance(var, str):\n",
    "            continue\n",
    "        lower_var = var.lower()\n",
    "        if 'srtm' in lower_var or 'ndvi' in lower_var:\n",
    "            continue\n",
    "        if '_bioclim_' in var:\n",
    "            candidate = var.split('_bioclim_')[0]\n",
    "            if candidate:\n",
    "                return candidate\n",
    "        parts = var.rsplit('_', 1)\n",
    "        if len(parts) == 2 and parts[1].isdigit() and parts[0]:\n",
    "            return parts[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_variable_name(var_name, model_prefix=None):\n",
    "    \"\"\"\n",
    "    Clean variable name by removing prefixes, filtering out SRTM/NDVI, and converting to numeric.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_name : str\n",
    "        Original variable name\n",
    "    model_prefix : str, optional\n",
    "        Model prefix to strip (e.g., 'ensemble_mean', 'MPI-M-MPI-ESM-LR_GERICS-REMO2015')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int or None\n",
    "        Numeric variable value, or None if SRTM/NDVI (to be filtered out)\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    if not isinstance(var_name, str):\n",
    "        return None\n",
    "\n",
    "    # Filter out SRTM and NDVI variables immediately\n",
    "    lowered = var_name.lower()\n",
    "    if 'srtm' in lowered or 'ndvi' in lowered:\n",
    "        return None\n",
    "\n",
    "    cleaned_name = var_name\n",
    "\n",
    "    # Remove dynamic model-prefix patterns first (handles ensemble_mean and CMIP models)\n",
    "    if model_prefix:\n",
    "        prefix_variants = {\n",
    "            model_prefix,\n",
    "            model_prefix.lower(),\n",
    "            model_prefix.upper()\n",
    "        }\n",
    "        for prefix in prefix_variants:\n",
    "            for suffix in ('_bioclim_', '_'):\n",
    "                candidate = f\"{prefix}{suffix}\"\n",
    "                if cleaned_name.startswith(candidate):\n",
    "                    cleaned_name = cleaned_name[len(candidate):]\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "    # Remove common static prefixes\n",
    "    common_prefixes = [\n",
    "        'ensemble_mean_bioclim_',\n",
    "        'bioclim_',\n",
    "        'ensemble_mean_',\n",
    "        'mean_',\n",
    "        'std_',\n",
    "        'min_',\n",
    "        'max_'\n",
    "    ]\n",
    "    for prefix in common_prefixes:\n",
    "        if cleaned_name.startswith(prefix):\n",
    "            cleaned_name = cleaned_name[len(prefix):]\n",
    "            break\n",
    "\n",
    "    # Attempt to extract trailing numeric identifier\n",
    "    match = re.search(r'_bioclim_(\\d+)$', cleaned_name)\n",
    "    if match:\n",
    "        cleaned_name = match.group(1)\n",
    "    else:\n",
    "        match = re.search(r'_(\\d+)$', cleaned_name)\n",
    "        if match:\n",
    "            cleaned_name = match.group(1)\n",
    "        else:\n",
    "            match = re.search(r'(\\d+)$', cleaned_name)\n",
    "            if match:\n",
    "                cleaned_name = match.group(1)\n",
    "\n",
    "    try:\n",
    "        numeric_value = int(cleaned_name.lstrip('0') or '0')\n",
    "        return numeric_value\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_variable_list(var_list, model_prefix=None):\n",
    "    \"\"\"\n",
    "    Clean a list of variable names, filtering out SRTM/NDVI and converting to numeric.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_list : list\n",
    "        List of variable names\n",
    "    model_prefix : str, optional\n",
    "        Model prefix to strip from variable names\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of numeric variable values (SRTM/NDVI filtered out)\n",
    "    \"\"\"\n",
    "    cleaned_vars = []\n",
    "    for var in var_list:\n",
    "        cleaned_var = clean_variable_name(var, model_prefix=model_prefix)\n",
    "        if cleaned_var is not None:\n",
    "            cleaned_vars.append(cleaned_var)\n",
    "    return cleaned_vars\n",
    "\n",
    "def remove_duplicates_preserve_order(var_list):\n",
    "    \"\"\"\n",
    "    Remove duplicates while preserving order.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_list : list\n",
    "        List of variables (may contain duplicates)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List without duplicates\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for var in var_list:\n",
    "        if var not in seen:\n",
    "            seen.add(var)\n",
    "            result.append(var)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Comprehensive Analysis Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD COMPREHENSIVE ANALYSIS RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "def load_comprehensive_analysis_results(base_path, specie, training, bio, model_prefixes=None, scenarios=None):\n",
    "    \"\"\"\n",
    "    Load comprehensive analysis results across iterations, supporting multiple model prefixes and scenarios.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import re\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    # Normalize filters\n",
    "    model_prefixes = [mp.strip('_') for mp in (model_prefixes or []) if mp]\n",
    "    scenarios = [sc.lower() for sc in (scenarios or []) if sc]\n",
    "\n",
    "    # Scan only base_path directory\n",
    "    if not base_path or not os.path.isdir(base_path):\n",
    "        print(\"No valid base_path directory found to search for comprehensive summaries.\")\n",
    "        return results_dict\n",
    "\n",
    "    # Use single pattern: 06_comprehensive_analysis_summary_*.json\n",
    "    pattern = \"06_comprehensive_analysis_summary_*.json\"\n",
    "\n",
    "    files = []\n",
    "    # Use pathlib for reliable recursive searching of nested directories\n",
    "    root_path = Path(base_path)\n",
    "    if root_path.exists():\n",
    "        # Use rglob to recursively search all nested directories\n",
    "        matched = list(root_path.rglob(pattern))\n",
    "        # Filter out .ipynb_checkpoints directories\n",
    "        matched = [f for f in matched if '.ipynb_checkpoints' not in str(f)]\n",
    "        if matched:\n",
    "            files.extend([str(f) for f in matched])\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    unique_files = []\n",
    "    for fpath in files:\n",
    "        if fpath not in seen:\n",
    "            seen.add(fpath)\n",
    "            unique_files.append(fpath)\n",
    "    files = unique_files\n",
    "\n",
    "    if not files:\n",
    "        print(\"No comprehensive analysis summary files found with the expected patterns.\")\n",
    "        return results_dict\n",
    "\n",
    "    # Apply model prefix filter if provided\n",
    "    if model_prefixes:\n",
    "        filtered_files = []\n",
    "        for fpath in files:\n",
    "            fname = os.path.basename(fpath)\n",
    "            if any(f\"_{mp}_\" in fname or fname.endswith(f\"_{mp}.json\") for mp in model_prefixes):\n",
    "                filtered_files.append(fpath)\n",
    "        if not filtered_files:\n",
    "            print(f\"No files matched the specified model prefixes: {model_prefixes}\")\n",
    "        else:\n",
    "            files = filtered_files\n",
    "\n",
    "    # Apply scenario filter if provided\n",
    "    if scenarios:\n",
    "        filtered_files = []\n",
    "        for fpath in files:\n",
    "            fname = os.path.basename(fpath).lower()\n",
    "            if any(f\"_{sc}_\" in fname for sc in scenarios):\n",
    "                filtered_files.append(fpath)\n",
    "        if not filtered_files:\n",
    "            print(f\"No files matched the specified scenarios: {scenarios}\")\n",
    "        else:\n",
    "            files = filtered_files\n",
    "\n",
    "    print(f\"Found {len(files)} comprehensive analysis summary files\")\n",
    "\n",
    "    for file_path in files:\n",
    "        try:\n",
    "            filename = os.path.basename(file_path)\n",
    "            base_name = filename.replace('.json', '')\n",
    "\n",
    "            # Attempt to extract iteration identifier\n",
    "            iteration = None\n",
    "            match = re.search(r'iteration[_-]?(\\d+)', base_name, re.IGNORECASE)\n",
    "            if match:\n",
    "                iteration = f\"iteration_{match.group(1)}\"\n",
    "            else:\n",
    "                # Fallback: use trailing numeric chunk if available\n",
    "                match = re.search(r'_(\\d+)$', base_name)\n",
    "                if match:\n",
    "                    iteration = f\"iteration_{match.group(1)}\"\n",
    "\n",
    "            if not iteration:\n",
    "                iteration = base_name\n",
    "\n",
    "            # Load JSON content\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            data['source_file'] = filename\n",
    "\n",
    "            # Ensure unique iteration keys (important when multiple model prefixes share numbers)\n",
    "            key = iteration\n",
    "            if key in results_dict:\n",
    "                hints = [iteration]\n",
    "                if data.get('model_prefix'):\n",
    "                    hints.append(str(data['model_prefix']))\n",
    "                if data.get('scenario'):\n",
    "                    hints.append(str(data['scenario']))\n",
    "                key = '_'.join(hints)\n",
    "                suffix = 1\n",
    "                while key in results_dict:\n",
    "                    key = f\"{iteration}_{suffix}\"\n",
    "                    suffix += 1\n",
    "\n",
    "            results_dict[key] = data\n",
    "            print(f\"Loaded {key} from {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "# Load results\n",
    "print(\"Loading comprehensive analysis results...\")\n",
    "comprehensive_results = load_comprehensive_analysis_results(\n",
    "    base_path,\n",
    "    specie,\n",
    "    training,\n",
    "    bio,\n",
    "    model_prefixes=model_prefixes,\n",
    "    scenarios=scenarios\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded {len(comprehensive_results)} comprehensive analysis results\")\n",
    "for iteration in comprehensive_results.keys():\n",
    "    print(f\"  - {iteration}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract and Compare Variable Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT AND COMPARE VARIABLE SETS\n",
    "# =============================================================================\n",
    "\n",
    "def extract_variable_sets(comprehensive_results):\n",
    "    \"\"\"\n",
    "    Extract final_variable_set and optimal_variables from comprehensive results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    comprehensive_results : dict\n",
    "        Dictionary containing comprehensive results from all iterations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_comparison = {}\n",
    "    \n",
    "    for iteration, results in comprehensive_results.items():\n",
    "        # Extract final variables from variable importance analysis\n",
    "        final_variables_raw = results.get('variable_importance_summary', {}).get('final_variable_set', [])\n",
    "        \n",
    "        # Extract optimal variables from spatial spread analysis\n",
    "        optimal_variables_raw = results.get('spatial_spread_summary', {}).get('optimal_variables', [])\n",
    "        \n",
    "        # Determine model prefix from metadata or infer from variable names (supports ensemble_mean-only runs)\n",
    "        metadata_candidates = [\n",
    "            results.get('model_prefix'),\n",
    "            results.get('model'),\n",
    "            results.get('model_name'),\n",
    "            results.get('metadata', {}).get('model_prefix') if isinstance(results.get('metadata'), dict) else None,\n",
    "            results.get('experiment_metadata', {}).get('model_prefix') if isinstance(results.get('experiment_metadata'), dict) else None,\n",
    "        ]\n",
    "        model_prefix = next((candidate for candidate in metadata_candidates if candidate), None)\n",
    "        if not model_prefix:\n",
    "            model_prefix = infer_model_prefix(final_variables_raw + optimal_variables_raw)\n",
    "        if not model_prefix:\n",
    "            model_prefix = 'ensemble_mean'\n",
    "        \n",
    "        # Clean variable names (apply Variable Name Cleaning Functions with model_prefix)\n",
    "        final_variables = clean_variable_list(final_variables_raw, model_prefix=model_prefix)\n",
    "        optimal_variables = clean_variable_list(optimal_variables_raw, model_prefix=model_prefix)\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        final_variables = remove_duplicates_preserve_order(final_variables)\n",
    "        optimal_variables = remove_duplicates_preserve_order(optimal_variables)\n",
    "        \n",
    "        # Calculate overlap\n",
    "        final_set = set(final_variables)\n",
    "        optimal_set = set(optimal_variables)\n",
    "        \n",
    "        common_variables = list(final_set.intersection(optimal_set))\n",
    "        final_only = list(final_set - optimal_set)\n",
    "        optimal_only = list(optimal_set - final_set)\n",
    "        \n",
    "        # Calculate overlap percentage\n",
    "        total_unique = len(final_set.union(optimal_set))\n",
    "        overlap_percentage = (len(common_variables) / total_unique * 100) if total_unique > 0 else 0\n",
    "        \n",
    "        variable_comparison[iteration] = {\n",
    "            'final_variables': final_variables,\n",
    "            'optimal_variables': optimal_variables,\n",
    "            'common_variables': common_variables,\n",
    "            'final_only': final_only,\n",
    "            'optimal_only': optimal_only,\n",
    "            'overlap_percentage': overlap_percentage,\n",
    "            'total_final': len(final_variables),\n",
    "            'total_optimal': len(optimal_variables),\n",
    "            'total_common': len(common_variables)\n",
    "        }\n",
    "    \n",
    "    return variable_comparison\n",
    "\n",
    "def create_variable_comparison_table(variable_comparison):\n",
    "    \"\"\"\n",
    "    Create comparison table for variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        Comparison table\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for iteration, comparison in variable_comparison.items():\n",
    "        row = {\n",
    "            'Iteration': iteration,\n",
    "            'Final_Variables_Count': comparison['total_final'],\n",
    "            'Optimal_Variables_Count': comparison['total_optimal'],\n",
    "            'Common_Variables_Count': comparison['total_common'],\n",
    "            'Overlap_Percentage': comparison['overlap_percentage'],\n",
    "            'Final_Variables': ', '.join(map(str, comparison['final_variables'])),\n",
    "            'Optimal_Variables': ', '.join(map(str, comparison['optimal_variables'])),\n",
    "            'Common_Variables': ', '.join(map(str, comparison['common_variables'])),\n",
    "            'Final_Only': ', '.join(map(str, comparison['final_only'])),\n",
    "            'Optimal_Only': ', '.join(map(str, comparison['optimal_only']))\n",
    "        }\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Extract variable sets\n",
    "print(\"Extracting variable sets from comprehensive results...\")\n",
    "variable_comparison = extract_variable_sets(comprehensive_results)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_table = create_variable_comparison_table(variable_comparison)\n",
    "\n",
    "print(f\"\\nVariable Sets Comparison Table:\")\n",
    "print(comparison_table.to_string(index=False))\n",
    "\n",
    "# Display summary statistics\n",
    "if not comparison_table.empty:\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"• Average Final Variables: {comparison_table['Final_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"• Average Optimal Variables: {comparison_table['Optimal_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"• Average Common Variables: {comparison_table['Common_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"• Average Overlap: {comparison_table['Overlap_Percentage'].mean():.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create 2 Optimized Variable Sets as Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE 2 OPTIMIZED VARIABLE SETS AS ARRAYS\n",
    "# =============================================================================\n",
    "\n",
    "def create_optimized_variable_sets(variable_comparison):\n",
    "    \"\"\"\n",
    "    Create 2 optimized variable sets as arrays based on analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    optimized_sets : dict\n",
    "        Dictionary containing 2 optimized variable sets as arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    # Collect all variables from all iterations\n",
    "    all_final_variables = []\n",
    "    all_optimal_variables = []\n",
    "    all_common_variables = []\n",
    "    \n",
    "    for iteration, comparison in variable_comparison.items():\n",
    "        all_final_variables.extend(comparison['final_variables'])\n",
    "        all_optimal_variables.extend(comparison['optimal_variables'])\n",
    "        all_common_variables.extend(comparison['common_variables'])\n",
    "    \n",
    "    # Count variable frequency\n",
    "    from collections import Counter\n",
    "    \n",
    "    final_freq = Counter(all_final_variables)\n",
    "    optimal_freq = Counter(all_optimal_variables)\n",
    "    common_freq = Counter(all_common_variables)\n",
    "    \n",
    "    # Calculate variable scores (frequency + importance)\n",
    "    all_variables = set(all_final_variables + all_optimal_variables)\n",
    "    variable_scores = {}\n",
    "    \n",
    "    for var in all_variables:\n",
    "        final_score = final_freq.get(var, 0)\n",
    "        optimal_score = optimal_freq.get(var, 0)\n",
    "        common_score = common_freq.get(var, 0)\n",
    "        \n",
    "        # Combined score: common variables get highest weight\n",
    "        total_score = common_score * 3 + final_score + optimal_score\n",
    "        variable_scores[var] = total_score\n",
    "    \n",
    "    # Sort variables by score\n",
    "    sorted_variables = sorted(variable_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create 2 optimized sets as arrays\n",
    "    optimized_sets = {}\n",
    "    \n",
    "    # Set 1: Most frequent common variables (highest consensus)\n",
    "    common_vars_sorted = sorted(common_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    set1_vars = [var for var, freq in common_vars_sorted[:5]]  # Top 5 common variables\n",
    "    optimized_sets[\"Set 1 - Common Variables\"] = np.array(set1_vars)\n",
    "    \n",
    "    # Set 2: Best performing variables (highest combined score)\n",
    "    set2_vars = [var for var, score in sorted_variables[:6]]  # Top 6 variables by score\n",
    "    optimized_sets[\"Set 2 - Best Performing\"] = np.array(set2_vars)\n",
    "    \n",
    "    # # Set 3: Balanced approach (mix of common and unique high-scoring variables)\n",
    "    # # Take top 3 common + top 3 unique high-scoring variables\n",
    "    # common_top3 = [var for var, freq in common_vars_sorted[:3]]\n",
    "    # unique_vars = [var for var, score in sorted_variables if var not in common_top3][:3]\n",
    "    # set3_vars = common_top3 + unique_vars\n",
    "    # optimized_sets[\"Set 3 - Balanced Approach\"] = np.array(set3_vars)\n",
    "    \n",
    "    # Add metadata for each set (create separate dictionary to avoid modification during iteration)\n",
    "    metadata_dict = {}\n",
    "    for set_name, variables in optimized_sets.items():\n",
    "        # Calculate set characteristics\n",
    "        common_count = sum(1 for var in variables if var in common_freq)\n",
    "        final_count = sum(1 for var in variables if var in final_freq)\n",
    "        optimal_count = sum(1 for var in variables if var in optimal_freq)\n",
    "        \n",
    "        # Add metadata to separate dictionary\n",
    "        metadata_dict[f\"{set_name}_metadata\"] = {\n",
    "            'variable_count': len(variables),\n",
    "            'common_variables': common_count,\n",
    "            'final_variables': final_count,\n",
    "            'optimal_variables': optimal_count,\n",
    "            'consensus_score': common_count / len(variables) if len(variables) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Add metadata to optimized_sets after iteration is complete\n",
    "    optimized_sets.update(metadata_dict)\n",
    "    \n",
    "    return optimized_sets, variable_scores\n",
    "\n",
    "def create_variable_sets_table(optimized_sets):\n",
    "    \"\"\"\n",
    "    Create table for the 2 optimized variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    optimized_sets : dict\n",
    "        Dictionary containing optimized variable sets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        Variable sets table\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets:\n",
    "            variables = optimized_sets[set_name]\n",
    "            metadata = optimized_sets.get(f\"{set_name}_metadata\", {})\n",
    "            \n",
    "            row = {\n",
    "                'Set_Name': set_name,\n",
    "                'Variable_Count': metadata.get('variable_count', len(variables)),\n",
    "                'Common_Variables': metadata.get('common_variables', 0),\n",
    "                'Final_Variables': metadata.get('final_variables', 0),\n",
    "                'Optimal_Variables': metadata.get('optimal_variables', 0),\n",
    "                'Consensus_Score': metadata.get('consensus_score', 0),\n",
    "                'Variables': ', '.join(map(str, variables)) if len(variables) > 0 else ''\n",
    "            }\n",
    "            data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create optimized variable sets\n",
    "print(\"Creating 2 optimized variable sets as arrays...\")\n",
    "optimized_sets, variable_scores = create_optimized_variable_sets(variable_comparison)\n",
    "\n",
    "# Create variable sets table\n",
    "sets_table = create_variable_sets_table(optimized_sets)\n",
    "\n",
    "print(f\"\\nOptimized Variable Sets:\")\n",
    "print(sets_table.to_string(index=False))\n",
    "\n",
    "# Display the sets in the requested array format\n",
    "print(f\"\\nVariable Sets as Arrays (with Variable Name Cleaning Applied):\")\n",
    "print(\"# Variable Sets as NumPy Arrays\")\n",
    "# for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "    if set_name in optimized_sets:\n",
    "        variables = optimized_sets[set_name]\n",
    "        print(f\"\\n{set_name}:\")\n",
    "        print(f\"variables_{set_name.lower().replace(' ', '_').replace('-', '_')} = np.array({list(variables)})\")\n",
    "        print(f\"# Array shape: {variables.shape}\")\n",
    "        print(f\"# Variables: {list(variables)}\")\n",
    "\n",
    "# Display variable scores for reference\n",
    "print(f\"\\nVariable Scores (Top 10):\")\n",
    "sorted_scores = sorted(variable_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (var, score) in enumerate(sorted_scores[:10]):\n",
    "    print(f\"{i+1:2d}. {var}: {score:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "if savefig:\n",
    "    print(\"Saving results...\")\n",
    "    \n",
    "    # Save comparison table\n",
    "    if not comparison_table.empty:\n",
    "        comparison_file = os.path.join(results_path, f\"08_variable_comparison_{specie}_{training}_{bio}.csv\")\n",
    "        comparison_table.to_csv(comparison_file, index=False)\n",
    "        print(f\"Variable comparison table saved to: {comparison_file}\")\n",
    "    \n",
    "    # Save variable sets table\n",
    "    if not sets_table.empty:\n",
    "        sets_file = os.path.join(results_path, f\"08_optimized_variable_sets_{specie}_{training}_{bio}.csv\")\n",
    "        sets_table.to_csv(sets_file, index=False)\n",
    "        print(f\"Optimized variable sets table saved to: {sets_file}\")\n",
    "    \n",
    "    # Save optimized sets in JSON format (convert numpy arrays to lists)\n",
    "    json_sets = {}\n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets and len(optimized_sets[set_name]) > 0:\n",
    "            # Convert numpy array to list for JSON serialization\n",
    "            json_sets[set_name] = optimized_sets[set_name].tolist()\n",
    "    \n",
    "    json_file = os.path.join(results_path, f\"08_optimized_variable_sets_{specie}_{training}_{bio}.json\")\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(json_sets, f, indent=2)\n",
    "    print(f\"Optimized variable sets JSON saved to: {json_file}\")\n",
    "    \n",
    "    # Save comprehensive results (only the 2 optimized sets, exclude metadata)\n",
    "    comprehensive_file = os.path.join(results_path, f\"08_comprehensive_variable_analysis_{specie}_{training}_{bio}.json\")\n",
    "    # Filter to only include the 2 optimized sets (exclude metadata entries)\n",
    "    optimized_sets_only = {}\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets:\n",
    "            optimized_sets_only[set_name] = optimized_sets[set_name].tolist() if isinstance(optimized_sets[set_name], np.ndarray) else optimized_sets[set_name]\n",
    "    \n",
    "    comprehensive_data = {\n",
    "        'variable_comparison': variable_comparison,\n",
    "        'optimized_sets': optimized_sets_only,\n",
    "        'variable_scores': variable_scores\n",
    "    }\n",
    "    with open(comprehensive_file, 'w') as f:\n",
    "        json.dump(comprehensive_data, f, indent=2, default=str)\n",
    "    print(f\"Comprehensive variable analysis saved to: {comprehensive_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping file saving (savefig=False)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"VARIABLE SETS COMPARISON COMPLETED\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if variable_comparison and optimized_sets:\n",
    "    print(f\"\\nANALYSIS SUMMARY:\")\n",
    "    print(f\"• Iterations Analyzed: {len(variable_comparison)}\")\n",
    "    print(f\"• Comparison Tables Created: 2\")\n",
    "    print(f\"• Optimized Variable Sets: 2 (as NumPy arrays)\")\n",
    "    print(f\"• Variable Names Cleaned: Yes\")\n",
    "    print(f\"• Prefixes Removed: Yes\")\n",
    "    print(f\"• SRTM/NDVI Filtered Out: Yes\")\n",
    "    print(f\"• Converted to Numeric: Yes\")\n",
    "    \n",
    "    print(f\"\\nOPTIMIZED VARIABLE SETS (ARRAYS):\")\n",
    "    sets = {\n",
    "        \"Set2\": list(optimized_sets.get(\"Set 1 - Common Variables\", [])),\n",
    "        \"Set3\": list(optimized_sets.get(\"Set 2 - Best Performing\", [])),\n",
    "    }\n",
    "\n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets:\n",
    "            variables = optimized_sets[set_name]\n",
    "            metadata = optimized_sets.get(f\"{set_name}_metadata\", {})\n",
    "            print(f\"• {set_name}: {len(variables)} variables\")\n",
    "            print(f\"  - Array: {list(variables)}\")\n",
    "            print(f\"  - Consensus Score: {metadata.get('consensus_score', 0):.2f}\")\n",
    "    \n",
    "    print(f\"\\nOUTPUT FILES:\")\n",
    "    print(f\"• CSV Tables: {results_path}\")\n",
    "    print(f\"• JSON Files: {results_path}\")\n",
    "\n",
    "    \n",
    "    print(f\"\\nKEY INSIGHTS:\")\n",
    "    if not comparison_table.empty:\n",
    "        avg_overlap = comparison_table['Overlap_Percentage'].mean()\n",
    "        avg_final = comparison_table['Final_Variables_Count'].mean()\n",
    "        avg_optimal = comparison_table['Optimal_Variables_Count'].mean()\n",
    "        \n",
    "        print(f\"• Average Variable Overlap: {avg_overlap:.1f}%\")\n",
    "        print(f\"• Average Final Variables: {avg_final:.1f}\")\n",
    "        print(f\"• Average Optimal Variables: {avg_optimal:.1f}\")\n",
    "        \n",
    "        if avg_overlap > 70:\n",
    "            print(f\"• Integration Level: HIGH - Strong consensus between approaches\")\n",
    "        elif avg_overlap > 50:\n",
    "            print(f\"• Integration Level: MODERATE - Some consensus between approaches\")\n",
    "        else:\n",
    "            print(f\"• Integration Level: LOW - Limited consensus between approaches\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDATIONS:\")\n",
    "    print(f\"1. Use Set 1 for maximum consensus (common variables)\")\n",
    "    print(f\"2. Use Set 2 for best performance (highest scoring variables)\")\n",
    "    print(f\"3. All variable names are cleaned and ready for use\")\n",
    "    print(f\"4. Variables are provided as numeric arrays for easy integration\")\n",
    "    print(f\"5. SRTM and NDVI variables have been filtered out\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nNO DATA FOUND:\")\n",
    "    print(f\"• No comprehensive analysis results found\")\n",
    "    print(f\"• Please run the main analysis notebook first\")\n",
    "    print(f\"• Ensure JSON files are saved in the correct location\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(\"VARIABLE SETS COMPARISON COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
