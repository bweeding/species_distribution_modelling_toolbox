{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b15204-7112-48a4-97c4-bc90bc40550d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Generate background pseudo-absence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb119d4-0533-42db-bf15-4f048c1e6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIGURATION PARAMETERS ###############\n",
    "# Modify these variables to customize the analysis for your species and regions\n",
    "\n",
    "# Species selection - choose the target species for distribution modeling\n",
    "# specie = 'leptocybe-invasa' # 'thaumastocoris-peregrinus' # \n",
    "\n",
    "# Geographic regions for training and testing\n",
    "# training = 'east-asia' # 'australia' #  # Region used for model training\n",
    "# interest = 'south-east-asia'  # Region of interest for prediction/testing\n",
    "\n",
    "# Pseudo-absence point generation parameters\n",
    "# count = 10000  # Number of background points to generate\n",
    "\n",
    "# Spatial resolution settings\n",
    "# # 100m ~ 0.001 deg (high resolution)\n",
    "# # 1000m ~ 0.01 deg (medium resolution)\n",
    "# ref_res = (0.01, 0.01) # deg  # Reference resolution for raster operations\n",
    "\n",
    "# Output options\n",
    "# savefig = True  # Whether to save generated figures to disk\n",
    "\n",
    "# Alternative configuration example:\n",
    "# specie = 'leptocybe-invasa' # 'thaumastocoris-peregrinus' # \n",
    "# training = 'south-east-asia'  # Use same region for training and testing\n",
    "# interest = 'south-east-asia'\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5982acd0-c651-4b32-853e-d45ee7fa2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT REQUIRED LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "# Standard library imports\n",
    "import os  # File system operations for path handling and directory management\n",
    "\n",
    "# Core scientific computing libraries\n",
    "import numpy as np  # Numerical computing - arrays, mathematical operations\n",
    "import pandas as pd  # Data manipulation and analysis - DataFrames, CSV handling\n",
    "import geopandas as gpd  # Geospatial data handling - vector data, shapefiles\n",
    "import rioxarray as rioxr  # Raster I/O for xarray - geospatial raster operations\n",
    "\n",
    "# Specialized geospatial processing libraries\n",
    "import geowombat as gw  # High-performance geospatial processing library\n",
    "from geowombat.data import rgbn  # Sample data for geowombat (not used in this notebook)\n",
    "from geocube.api.core import make_geocube  # Convert vector data to raster format\n",
    "\n",
    "# Species distribution modeling library\n",
    "import elapid as ela  # Species distribution modeling library - MaxEnt, sampling functions\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization - figures, plots\n",
    "import matplotlib as mpl  # Matplotlib configuration - colormaps, styling\n",
    "\n",
    "# Cartographic and mapping libraries\n",
    "import cartopy.crs as ccrs  # Cartographic projections - coordinate reference systems\n",
    "import cartopy.feature as cfeature  # Cartographic features - coastlines, borders, land\n",
    "import cartopy.io.shapereader as shapereader  # Shapefile reading utilities\n",
    "\n",
    "# Warning suppression for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warning messages for cleaner output\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "# Set larger font sizes for better readability in plots\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368fcaa-6dd8-4398-b79e-b1a2ef817453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default cartographic projection for mapping\n",
    "projection = ccrs.PlateCarree()  # Equirectangular projection (lat/lon coordinates)\n",
    "\n",
    "def make_map(projection, res, figsize=None, ncols=None):\n",
    "    \"\"\"\n",
    "    Create a map with cartographic features for visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    projection : cartopy.crs\n",
    "        Cartographic projection to use for the map\n",
    "    res : str\n",
    "        Resolution scale for cartographic features ('50m', '110m', '50m')\n",
    "    figsize : tuple, optional\n",
    "        Figure size in inches (width, height)\n",
    "    ncols : int, optional\n",
    "        Number of columns for subplot layout\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The created figure object\n",
    "    axes : list or array\n",
    "        The axes object(s) for plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure and axes based on layout requirements\n",
    "    if ncols == None:\n",
    "        # Single plot layout\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        axes = [plt.axes(projection=projection)]\n",
    "    else:\n",
    "        # Multi-column subplot layout\n",
    "        fig, axes = plt.subplots(figsize=figsize, ncols=ncols, \n",
    "                                subplot_kw={'projection': projection})\n",
    "    \n",
    "    # Add cartographic features to each axis\n",
    "    for ax in axes:\n",
    "        # Add country borders\n",
    "        ax.add_feature(cfeature.BORDERS.with_scale(res))\n",
    "        \n",
    "        # Add state/province boundaries (dotted gray lines)\n",
    "        ax.add_feature(cfeature.STATES.with_scale(res),\n",
    "                       linestyle=':', edgecolor='gray', linewidth=0.5)\n",
    "        \n",
    "        # Add land areas (light gray fill)\n",
    "        ax.add_feature(cfeature.LAND.with_scale(res), color='lightgray')\n",
    "        \n",
    "        # Add coastlines\n",
    "        ax.add_feature(cfeature.COASTLINE.with_scale(res))\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d7d23-5c4e-45af-a75c-56e972395a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DIRECTORY STRUCTURE SETUP\n",
    "# =============================================================================\n",
    "# Define paths for data storage and output organization\n",
    "\n",
    "# Alternative data path (commented out - for server environments)\n",
    "# data_path = os.path.join(os.sep, 'scratch', 'aciar-fst', 'data')\n",
    "\n",
    "# Main data directory - contains input datasets (land cover, species data, etc.)\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# Output directories for different types of results\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')  # Generated figures/plots\n",
    "docs_path = os.path.join(os.path.dirname(os.getcwd()), 'docs')  # Documentation files\n",
    "\n",
    "# Species-specific output directory structure\n",
    "out_path = os.path.join(os.path.dirname(os.getcwd()), 'out', specie)  # Main output for species\n",
    "input_path = os.path.join(out_path, 'input')  # Processed input data\n",
    "train_path = os.path.join(input_path, 'train')  # Training region data\n",
    "test_path = os.path.join(input_path, 'test')  # Testing region data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdcac5-d356-461c-acf0-a9b7782d50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GEOGRAPHIC REGIONS DEFINITION\n",
    "# =============================================================================\n",
    "# Dictionary defining different geographic regions for species distribution modeling\n",
    "# Each key represents a region name, and the value is a list of countries in that region\n",
    "\n",
    "regions = {\n",
    "    'east-asia': ['China', 'Taiwan', 'Japan', 'North Korea', 'South Korea'],\n",
    "    'indo': [\"Indonesia\",'Malaysia','Singapore','Brunei','East Timor'],\n",
    "    'sea': ['Myanmar', 'Cambodia', 'Laos', 'Philippines', 'Thailand', 'Vietnam'],\n",
    "    'south-east-asia': ['Brunei', 'Myanmar', 'Cambodia', 'East Timor', 'Indonesia', 'Laos', 'Malaysia', 'Philippines', 'Singapore', 'Thailand', 'Vietnam'],\n",
    "    'australia': ['Australia'],\n",
    "    'australasia' : ['Australia', 'New Zealand'],\n",
    "    'india-sri-lanka' : ['Sri Lanka'],\n",
    "    'all' : ['Australia','France','Italy','Portugal','South Africa','United States of America','Madagascar','Spain','Greece','Cyprus','Mexico','Kenya','Algeria','Israel','Egypt','Ethiopia','Ghana','Malawi','Mauritius','Morocco','Mozambique','Rwanda','Sierra Leone','United Republic of Tanzania','Tunisia','Uganda','Zimbabwe','China','India','Iran','Iraq','Jordan','Sri Lanka','Syria','Taiwan','Turkey','Malta','Montenegro','United Kingdom','Argentina','Brazil','Chile','Paraguay','Uruguay']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34583079-1df0-45d4-9c7c-2546a5a9e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD GEOGRAPHIC BOUNDARIES\n",
    "# =============================================================================\n",
    "# Load shapefiles containing country boundaries for the study regions\n",
    "\n",
    "# Alternative approach: Load separate shapefiles for train and test regions\n",
    "# This would create separate GeoDataFrames for each region\n",
    "# gdf_countries = {}\n",
    "# for mode in ['train', 'test']:\n",
    "#     if mode == 'train':\n",
    "#         region = training\n",
    "#         file_path = train_path\n",
    "#     else:  # mode == 'test'\n",
    "#         region = interest\n",
    "#         file_path = test_path\n",
    "#     gdf_countries[mode] = gpd.read_file(os.path.join(file_path, '%s.shp' %region))\n",
    "\n",
    "# Current approach: Load the training region shapefile\n",
    "# This will be used as the reference boundary for the analysis\n",
    "gdf_countries = gpd.read_file(os.path.join(input_path, '%s.shp' %training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170c90c-ef57-4092-b9c8-bb6b0e321ed8",
   "metadata": {},
   "source": [
    "## Load Presence/Occurrence Data\n",
    "This section loads the species occurrence data (presence points) that will be used to generate pseudo-absence points. The presence data represents known locations where the species has been observed or recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf8dee-6452-4957-83d9-934dd14e72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load presence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1cca0-938b-4e82-8442-37a37f6543b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPARE RASTER TEMPLATES FOR SAMPLING\n",
    "# =============================================================================\n",
    "# Create raster templates from shapefiles to define the sampling area for pseudo-absence points\n",
    "\n",
    "occurences = {}  # Dictionary to store occurrence data for train/test regions\n",
    "\n",
    "# Process both training and testing regions\n",
    "for mode in ['train', 'test']:\n",
    "    # Determine region and file path based on mode\n",
    "    if mode == 'train':\n",
    "        region = training\n",
    "        file_path = train_path\n",
    "    else:  # mode == 'test'\n",
    "        region = interest\n",
    "        file_path = test_path\n",
    "\n",
    "    # Convert region shapefile to raster format for sampling\n",
    "    # This creates a binary raster mask defining the study area\n",
    "    shpfile = gpd.read_file(os.path.join(input_path, '%s.shp' %training))\n",
    "    \n",
    "    # Create a raster grid from the shapefile with 0.05 degree resolution\n",
    "    # Resolution: 0.05 degrees â‰ˆ 5.5 km at the equator\n",
    "    grid = make_geocube(shpfile, resolution=(0.05, -0.05))\n",
    "    \n",
    "    # Save the raster template with compression for efficient storage\n",
    "    grid.rio.to_raster(os.path.join(file_path, '%s.tif' %training), compress='zstd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7a900-85cd-41d4-87e6-7179c9320233",
   "metadata": {},
   "source": [
    "## 1. Random Pseudo-Absence Generation\n",
    "This method generates pseudo-absence points by randomly sampling locations within the study area. This is the simplest approach and serves as a baseline for comparison with more sophisticated methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3983e-eeb7-4b14-8f7c-f81d0f19aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'random':\n",
    "    print('random')\n",
    "    \n",
    "    # =============================================================================\n",
    "    # RANDOM PSEUDO-ABSENCE POINT GENERATION\n",
    "    # =============================================================================\n",
    "    # Generate randomly distributed background points within the study area\n",
    "    \n",
    "    pseudoabsence_random = {}  # Dictionary to store random background points\n",
    "    raster_files = {}  # Dictionary to store raster file paths\n",
    "    \n",
    "    # Process both training and testing regions\n",
    "    for mode in ['train', 'test']:\n",
    "        # Determine region and file path based on mode\n",
    "        if mode == 'train':\n",
    "            region = training\n",
    "            file_path = train_path\n",
    "        else:  # mode == 'test'\n",
    "            region = interest\n",
    "            file_path = test_path\n",
    "        \n",
    "        # Define raster file path for the region\n",
    "        raster_files[mode] = os.path.join(file_path, '%s.tif' %region)\n",
    "        \n",
    "        # Generate random background points using elapid's sample_raster function\n",
    "        # This samples 'count' number of random points within the raster area\n",
    "        pseudoabsence_random[mode] = ela.sample_raster(raster_files[mode], count=count)\n",
    "    \n",
    "        # Load presence/occurrence data for the region\n",
    "        occurences_file_name = os.path.join(file_path, '%s_presence_%s_%s.csv' %(specie, region, iteration))\n",
    "        df = pd.read_csv(occurences_file_name)\n",
    "        \n",
    "        # Convert presence data to GeoDataFrame with point geometry\n",
    "        occurences[mode] = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "    \n",
    "        # Display summary statistics\n",
    "        print('Number of presences in %s is: %s' %(region, len(occurences[mode])))\n",
    "        print('Number of random selected background points in %s is: %s' %(region, len(pseudoabsence_random[mode])))\n",
    "        \n",
    "        # Prepare background points for saving\n",
    "        # Convert geometry to separate longitude and latitude columns\n",
    "        pseudoabsence_random[mode] = pseudoabsence_random[mode].to_frame(name='geometry')\n",
    "        pseudoabsence_random[mode]['lon'] = pseudoabsence_random[mode]['geometry'].x\n",
    "        pseudoabsence_random[mode]['lat'] = pseudoabsence_random[mode]['geometry'].y\n",
    "        \n",
    "        # Save background points to CSV file\n",
    "        pseudoabsence_random[mode].to_csv(\n",
    "            os.path.join(file_path, '%s_background_random_%s.csv' %(specie, region)), \n",
    "            columns=['lon', 'lat'], \n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7a820-b946-4489-9fa1-75e41bc54b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'random':\n",
    "    # =============================================================================\n",
    "    # VISUALIZE RANDOM PSEUDO-ABSENCE POINTS\n",
    "    # =============================================================================\n",
    "    # Create maps showing the distribution of random background points and presence points\n",
    "    \n",
    "    resolution = '50m'  # Cartographic feature resolution\n",
    "    \n",
    "    # Create a 2-column map layout for training and testing regions\n",
    "    fig, axes = make_map(figsize=(18,10), ncols=2, projection=projection, res=resolution)\n",
    "    \n",
    "    # Plot training region data (left panel)\n",
    "    pseudoabsence_random['train'].plot(ax=axes[0], markersize=1, color='tab:red', \n",
    "                                      label='Background points')\n",
    "    occurences['train'].plot(ax=axes[0], marker='*', markersize=100, color='tab:blue', \n",
    "                            label='Presence points')\n",
    "    \n",
    "    # Plot testing region data (right panel)\n",
    "    pseudoabsence_random['test'].plot(ax=axes[1], markersize=1, color='tab:red', \n",
    "                                     label='Background points')\n",
    "    occurences['test'].plot(ax=axes[1], marker='*', markersize=100, color='tab:green', \n",
    "                           label='Presence points')\n",
    "    \n",
    "    # Add grid lines to both maps for better spatial reference\n",
    "    for ax in axes:\n",
    "        ax.gridlines(color='grey', linestyle=':', draw_labels=True, rotate_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3531a1-3223-4039-a150-4b4965d1ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'random':\n",
    "    if savefig:\n",
    "        fig.savefig(os.path.join(figs_path, '02_background_random_%s.png' %specie), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993984c-f068-4953-8a73-841a09f30b72",
   "metadata": {},
   "source": [
    "## 2. Biased Pseudo-Absence Generation\n",
    "This section implements more sophisticated methods for generating pseudo-absence points by biasing the selection towards areas that are environmentally similar to where the species is known to occur. This approach can improve model performance by focusing on ecologically relevant areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88141c-6b8d-41db-94e9-6d0d8de8d477",
   "metadata": {},
   "source": [
    "### 2.1 Land Cover-Based Biased Sampling\n",
    "This method uses the Copernicus Global Land Cover dataset to bias pseudo-absence point selection towards forest types where the species is more likely to occur. The approach assigns different weights to different forest types based on their suitability for the target species.\n",
    "\n",
    "**Data Source**: Copernicus Global Land Cover (https://land.copernicus.eu/global/products/lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939b1c1-a7b7-4157-add1-7e213c7f40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    print('biased-land-cover')\n",
    "    raster_files = {}\n",
    "\n",
    "    land_cover_file = os.path.join(data_path, 'land-cover', 'PROBAV_LC100_global_v3.0.1_2019-nrt_Forest-Type-layer_EPSG-4326.tif')\n",
    "    land_cover_glo = rioxr.open_rasterio(land_cover_file, masked=True,cache=False,dask=True)\n",
    "    \n",
    "    # land_cover_glo = rioxr.open_rasterio('/scratch/bweeding/raster_test.tif')\n",
    "    \n",
    "    # subset global dataset to regions\n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'train':\n",
    "            region = training\n",
    "            file_path = train_path\n",
    "        else:  # mode == 'test'\n",
    "            region = interest\n",
    "            file_path = test_path\n",
    "    \n",
    "        # raster = rioxr.open_rasterio(raster_files[region], masked=True,chunks={\"y\":5969,\"x\":3939},lock=False)\n",
    "        raster_files[mode] = os.path.join(file_path, '%s.tif' %region)\n",
    "        raster = rioxr.open_rasterio(raster_files[mode], masked=True,lock=False,cache=False,dask=True)\n",
    "        \n",
    "        print(\"raster opened\")\n",
    "        \n",
    "        land_cover_box = land_cover_glo.rio.clip_box(\n",
    "            minx=raster.x.min() - 1,\n",
    "            miny=raster.y.min() - 1,\n",
    "            maxx=raster.x.max() + 1,\n",
    "            maxy=raster.y.max() + 1,\n",
    "        )\n",
    "    \n",
    "        print(\"land_cover_box\")\n",
    "        \n",
    "        #land_cover_box_file = os.path.join('/mnt','bweeding_workspace','ACIAR','temp','land-cover_box_%s.tif' %region)\n",
    "        land_cover_box_file = os.path.join(input_path, 'land-cover_box_%s.tif' %region)\n",
    "        \n",
    "        # if not os.path.exists('temp'):\n",
    "        #     os.makedirs('temp')\n",
    "    \n",
    "        print(\"lcb_path_and_dir_created\")\n",
    "        \n",
    "        land_cover_box.rio.to_raster(land_cover_box_file,compress='zstd',windowed=True)\n",
    "        # land_cover_box.to_raster\n",
    "    \n",
    "        print(\"land_cover_box_to_raster_done\")\n",
    "        \n",
    "        land_cover_box.close()\n",
    "    land_cover_glo.close()\n",
    "    \n",
    "    print('regrid regional datasets to coarser grid')\n",
    "    \n",
    "    # regrid regional datasets to coarser grid\n",
    "    land_cover_regions = {}\n",
    "    \n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'train':\n",
    "            region = training\n",
    "            file_path = train_path\n",
    "        else:  # mode == 'test'\n",
    "            region = interest\n",
    "            file_path = test_path\n",
    "            \n",
    "        #land_cover_box_file = os.path.join('/mnt','bweeding_workspace','ACIAR','temp', 'land-cover_box_%s.tif' %region)\n",
    "        #land_cover_output_file = os.path.join('/mnt','bweeding_workspace','ACIAR','temp', 'land-cover_%s.tif' %region)\n",
    "        land_cover_box_file = os.path.join(input_path, 'land-cover_box_%s.tif' %region)\n",
    "        land_cover_output_file = os.path.join(input_path, 'land-cover_%s.tif' %region)\n",
    "        shapes = [shape for shape in gdf_countries.geometry]\n",
    "        \n",
    "        with gw.config.update(ref_res=ref_res):\n",
    "            with gw.open(land_cover_box_file, resampling=\"bilinear\", nodata=255, chunks=1024) as src:\n",
    "                data = src.isel(band=0).rio.clip(geometries=shapes)\n",
    "                data.rio.to_raster(land_cover_output_file,compress='zstd')\n",
    "    \n",
    "        # load forest type for regions\n",
    "        land_cover_regions[mode] = rioxr.open_rasterio(land_cover_output_file, mask_and_scale=True).isel(band=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049f484-d648-4ed1-9287-4210817c6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    print('Processing forest type land cover dataset...')\n",
    "    \n",
    "    # =============================================================================\n",
    "    # FOREST TYPE WEIGHTING SYSTEM\n",
    "    # =============================================================================\n",
    "    # Define weights for different forest types based on species habitat preferences\n",
    "    # Each entry contains: [Code, Description, Weight (0-1), Color for visualization]\n",
    "    # Weight indicates likelihood that species occurs in this forest type (0=never, 1=always)\n",
    "    \n",
    "    forest_dict = {\n",
    "        0: ['N/K', 'Unknown', 0, 'white'],           # Unknown areas - no preference\n",
    "        1: ['ENF', 'Evergreen Needleleaf Forest', 0.8, 'red'],    # High suitability\n",
    "        2: ['EBF', 'Evergreen Broadleaf Forest', 1.0, 'orange'],  # Highest suitability\n",
    "        3: ['DNF', 'Deciduous Needleleaf Forest', 0.2, 'green'],  # Low suitability\n",
    "        4: ['DBF', 'Deciduous Broadleaf Forest', 0.4, 'blue'],    # Medium suitability\n",
    "        5: ['MF', 'Mixed Forest', 0.5, 'purple']                  # Medium-high suitability\n",
    "    }\n",
    "    \n",
    "    # Display the weighting scheme for reference\n",
    "    print(\"\\033[1mForest Type Weights (0=unsuitable, 1=highly suitable):\\033[0m\")\n",
    "    for key, val in forest_dict.items():\n",
    "        print(f\"{val[1]}: {val[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a9d22-3b73-405e-8fd9-d91b046fe877",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    land_cover_bias_file_names = {}\n",
    "    \n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'train':\n",
    "            region = training\n",
    "            file_path = train_path\n",
    "        else:  # mode == 'test'\n",
    "            region = interest\n",
    "            file_path = test_path\n",
    "        \n",
    "        # changes flag values to normalised and weighted \n",
    "        land_cover_region_norm = land_cover_regions[mode].copy(deep=False)\n",
    "        values = land_cover_region_norm.values\n",
    "    \n",
    "        # make raster based on likelihood values\n",
    "        for key, val in forest_dict.items():\n",
    "            values[np.where(values == key)] = val[2]\n",
    "        land_cover_region_norm.values = values\n",
    "        \n",
    "        # save biased raster to file\n",
    "        land_cover_bias_file_names[mode] = 'land-cover_biased_%s.tif' %region\n",
    "        land_cover_region_norm.rio.to_raster(os.path.join(file_path, land_cover_bias_file_names[mode]),compress='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bd2c2-bf27-4bfc-ac26-847b0ed05ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    pseudoabsence_bias_land_cover = {}\n",
    "    \n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'train':\n",
    "            region = training\n",
    "            file_path = train_path\n",
    "        else:  # mode == 'test'\n",
    "            region = interest\n",
    "            file_path = test_path\n",
    "    \n",
    "        pseudoabsence_bias_land_cover[mode] = ela.sample_bias_file(os.path.join(file_path, land_cover_bias_file_names[mode]), count=count)\n",
    "\n",
    "        occurences_file_name = os.path.join(file_path, '%s_presence_%s_%s.csv' %(specie, region, iteration))\n",
    "        df = pd.read_csv(occurences_file_name)\n",
    "        occurences[mode] = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "\n",
    "        print('Number of presences in %s is: %s' %(region, len(occurences[mode])))\n",
    "        print('Number of random selected background points in %s is: %s' %(region, len(pseudoabsence_bias_land_cover[mode])))\n",
    "        \n",
    "        # save background points to file\n",
    "        pseudoabsence_bias_land_cover[mode] = pseudoabsence_bias_land_cover[mode].to_frame(name='geometry')\n",
    "        pseudoabsence_bias_land_cover[mode]['lon'] = pseudoabsence_bias_land_cover[mode]['geometry'].x\n",
    "        pseudoabsence_bias_land_cover[mode]['lat'] = pseudoabsence_bias_land_cover[mode]['geometry'].y\n",
    "        pseudoabsence_bias_land_cover[mode].to_csv(os.path.join(file_path, '%s_background_biased-land-cover_%s.csv' %(specie, region)), columns=['lon', 'lat'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68ee60-d01b-40fa-901d-f416d895f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    # fig, axes, gl = make_map(figsize=(18,6), projection=projection, res=resolution, ncols=2)\n",
    "    \n",
    "    nrows, ncols = 2, 2\n",
    "    fig, axes = plt.subplots(figsize=(18,8), ncols=ncols, nrows=nrows, constrained_layout=True)\n",
    "    \n",
    "    labels = [forest_dict[x][0] for x in forest_dict.keys()]\n",
    "    legend = [forest_dict[x][1] for x in forest_dict.keys()]\n",
    "    \n",
    "    cmap_lc = mpl.colors.ListedColormap([forest_dict[x][3] for x in forest_dict.keys()])\n",
    "    # cmap.set_bad('transparent')\n",
    "    norm_lc = mpl.colors.BoundaryNorm(np.arange(-0.5,6), cmap_lc.N) \n",
    "    fmt = mpl.ticker.FuncFormatter(lambda x, pos: labels[norm_lc(x)])\n",
    "    \n",
    "    for iax in range(axes.size):\n",
    "        r, c = iax // ncols, iax % ncols\n",
    "        if r == 0:\n",
    "            gdf_countries.plot(ax=axes[0, c], facecolor='lightgray', edgecolor='k')\n",
    "        if r == 1:\n",
    "            gdf_countries.plot(ax=axes[1, c], facecolor='lightgray', edgecolor='k')\n",
    "    \n",
    "    pcol = land_cover_regions['train'].plot(ax=axes[0, 0], cmap=cmap_lc, norm=norm_lc, add_colorbar=False, add_labels=False)\n",
    "    plt.colorbar(pcol, format=fmt, ticks=np.linspace(0,5,6))\n",
    "    pcol = land_cover_regions['test'].plot(ax=axes[1, 0], cmap=cmap_lc, norm=norm_lc, add_colorbar=False, add_labels=False)\n",
    "    plt.colorbar(pcol, format=fmt, ticks=np.linspace(0,5,6))\n",
    "    axes[0, 0].set_title('Forest Type based on Copernicus Land Cover dataset')\n",
    "    \n",
    "    scat = pseudoabsence_bias_land_cover['train'].plot(ax=axes[0, 1], markersize=1, color='tab:red', label='background')\n",
    "    occurences['train'].plot(ax=axes[0, 1], marker='*', markersize=100, color='tab:blue', label='presence')\n",
    "    pseudoabsence_bias_land_cover['test'].plot(ax=axes[1, 1], markersize=1, color='tab:red', label='background')\n",
    "    occurences['test'].plot(ax=axes[1, 1], marker='*', markersize=100, color='tab:green', label='presence')\n",
    "    axes[0, 1].set_title('Background and presence points')\n",
    "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1e809-6a63-4350-97b9-267e9ddf3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased-land-cover':\n",
    "    if savefig:\n",
    "        fig.savefig(os.path.join(figs_path, '02_background_biased-land-cover_%s_%s_%s.png' %(specie, training, iteration)), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab53184-561c-40d1-b484-34cc0bed1d9a",
   "metadata": {},
   "source": [
    "### 2.2 Planted Forest-Based Biased Sampling\n",
    "This method uses a specialized dataset of planted forests in East Asia to bias pseudo-absence point selection towards areas with planted Eucalyptus forests, which are known to be suitable habitats for the target species.\n",
    "\n",
    "**Data Source**: Planted Forest Dataset for East Asia (Abbasi et al. 2023)\n",
    "**Reference**: https://www.nature.com/articles/s41597-023-02383-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65f984-d348-4c0c-b20f-f51269113c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if planted forest-based biased sampling is selected\n",
    "if pseudoabsence == 'biased':\n",
    "    print('Generating planted forest-biased pseudo-absence points...')\n",
    "    \n",
    "    # Use training region for this analysis\n",
    "    region = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b546e-49d3-4af9-9a17-c2ae2bd89cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased':\n",
    "    # =============================================================================\n",
    "    # PLANTED FOREST TYPE WEIGHTING\n",
    "    # =============================================================================\n",
    "    # Define weights for different forest types based on species preferences\n",
    "    # Higher weights indicate higher likelihood of species occurrence\n",
    "    \n",
    "    forest_type_dict = {\n",
    "        'Tropical Forest and Savanna': 0,  # No preference (weight = 0)\n",
    "        'Temperate Forest': 0,             # No preference (weight = 0)  \n",
    "        'Eucalyptus': 1                    # High preference (weight = 1) - target species prefers Eucalyptus\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b9d7b-353d-4723-b5db-f0004485d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased':\n",
    "    forest_type_bias_file = os.path.join(train_path, 'forest-type_biased_%s.tif' %region)\n",
    "    if not os.path.isfile(forest_type_bias_file):\n",
    "     \n",
    "        planted_forest_file = os.path.join('zip://', data_path, 'planted-forest-east-asia', 'planted-forest-east-asia.zip')\n",
    "    \n",
    "        # planted_eucalyptus = gpd.read_file(planteplanted_forest_file, where=\"Genus='Eucalyptus'\")\n",
    "        tropical_forest = gpd.read_file(planted_forest_file, where=\"Biome='Tropical Forest and Savanna'\", include_fields=['Biome', 'Genus', 'Type'])\n",
    "        temperate_forest = gpd.read_file(planted_forest_file, where=\"Biome='Temperate Forest'\", include_fields=['Biome', 'Genus', 'Type'])\n",
    "        forest_type_region = pd.concat([tropical_forest, temperate_forest])\n",
    "    \n",
    "    \n",
    "        # indicate likelihood that specie occurs in Genus or Biome type type with a number between 0 and 1\n",
    "        # changes flag values to normalised and weighted\n",
    "        forest_type_region['norm'] = 0\n",
    "        for key, val in forest_type_dict.items():\n",
    "            forest_type_region.loc[forest_type_region.Biome == key, 'norm'] = val\n",
    "            if key == 'Eucalyptus':\n",
    "                forest_type_region.loc[forest_type_region.Genus == key, 'norm'] = val\n",
    "    #         temperate_forest.loc[\n",
    "    #             temperate_forest['potential'] = 0.5\n",
    "    #             temperate_forest.loc[temperate_forest.Genus == 'Eucalyptus', 'potential'] = 1\n",
    "    #             tropical_forest['potential'] = 1\n",
    "        \n",
    "        # rasterize vector data\n",
    "        forest_type_raster = make_geocube(\n",
    "        vector_data=forest_type_region,\n",
    "        measurements=['norm'],\n",
    "        resolution=(0.01, -0.01),#0.0174532925199433\n",
    "    #     fill = 0\n",
    "        )\n",
    "        \n",
    "        # save raster to file\n",
    "        forest_type_raster.rio.to_raster(forest_type_bias_file,compress='zstd')\n",
    "    else:\n",
    "        forest_type_raster = rioxr.open_rasterio(forest_type_bias_file)\n",
    "        \n",
    "    pseudoabsence_bias_forest = ela.sample_bias_file(forest_type_bias_file, count=count)\n",
    "    \n",
    "    print('Number of presences in %s is: %s' %(region, len(occurences[mode])))\n",
    "    print('Number of background points with a bias towards forests in %s is: %s' %(region, len(pseudoabsence_bias_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141bde9-fd7d-495f-a776-b5e062306a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased':\n",
    "    # save background points to file\n",
    "    pseudoabsence_bias_forest = pseudoabsence_bias_forest.to_frame(name='geometry')\n",
    "    pseudoabsence_bias_forest['lon'] = pseudoabsence_bias_forest['geometry'].x\n",
    "    pseudoabsence_bias_forest['lat'] = pseudoabsence_bias_forest['geometry'].y\n",
    "    pseudoabsence_bias_forest.to_csv(os.path.join(train_path, '%s_background_biased_forest-type_%s.csv' %(specie, region)), columns=['lon', 'lat'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71949a-6b6d-4425-8439-ce767c5d6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased':\n",
    "    # fig, axes, gl = make_map(figsize=(18,6), projection=projection, res=resolution, ncols=2)\n",
    "    fig, axes = plt.subplots(figsize=(18,5), ncols=2)\n",
    "    \n",
    "    cmap_ft = mpl.colors.ListedColormap(['white', 'orange', 'green'])\n",
    "    cmap_ft.set_bad('k', alpha=0)\n",
    "    bounds=[0,.333,.667,1]\n",
    "    norm_ft = mpl.colors.BoundaryNorm(bounds, cmap_ft.N)\n",
    "    \n",
    "    gdf_countries.plot(ax=axes[0], facecolor='lightgray', edgecolor='k')\n",
    "    try:\n",
    "        pcol = forest_type_raster.norm.plot(ax=axes[0], cmap=cmap_ft, norm=norm_ft, add_colorbar=False, add_labels=False)\n",
    "    except AttributeError:\n",
    "        pcol = forest_type_raster.plot(ax=axes[0], cmap=cmap_ft, norm=norm_ft, add_colorbar=False, add_labels=False)\n",
    "    \n",
    "    plt.colorbar(pcol)\n",
    "    axes[0].set_title('Forest Type normalised and weighted, based on Abbasi et al. 2023')\n",
    "    axes[0].set_xlim(72, 146)\n",
    "        \n",
    "    gdf_countries.plot(ax=axes[1], facecolor='lightgray', edgecolor='k')\n",
    "    pseudoabsence_bias_forest.plot(ax=axes[1], markersize=1, color='tab:red', label='background')\n",
    "    occurences[mode].plot(ax=axes[1], marker='*', markersize=100, color='tab:blue', label='presence')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cd8a6-dd77-45dd-b6ea-d9f1db73bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pseudoabsence == 'biased':\n",
    "    if savefig:\n",
    "        fig.savefig(os.path.join(figs_path, '02_background_biased-forest-type_%s_%s_%s.png' %(specie, region, iteration)), transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
