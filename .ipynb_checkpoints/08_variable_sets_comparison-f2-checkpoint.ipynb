{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Sets Comparison: Final Variables vs Optimal Variables\n",
    "\n",
    "This notebook compares the `final_variable_set` from Variable Importance Analysis with `optimal_variables` from Spatial Spread Analysis and creates 3 optimized variable sets as arrays.\n",
    "\n",
    "## Overview:\n",
    "- **Variable Comparison**: Compare final variables from both approaches\n",
    "- **Overlap Analysis**: Analyze common and unique variables\n",
    "- **Performance Assessment**: Evaluate variable set performance\n",
    "- **3 Variable Sets Creation**: Generate optimized sets as arrays\n",
    "- **Variable Name Cleaning**: Remove prefixes and handle special variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "#specie = 'leptocybe-invasa'  # Target species: 'leptocybe-invasa' or 'thaumastocoris-peregrinus'\n",
    "# training = 'south-east-asia' \n",
    "# bio = bio1  # Bioclimatic variable identifier\n",
    "savefig = True  # Set to True to save figures\n",
    "\n",
    "# Paths\n",
    "base_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')  # Figures directory\n",
    "results_path = os.path.join(os.path.dirname(os.getcwd()), 'results')  # Figures directory\n",
    "# results_path = os.path.join(base_path, \"results\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(figs_path, exist_ok=True)\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable Name Cleaning Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VARIABLE NAME CLEANING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def clean_variable_name(var_name):\n",
    "    \"\"\"\n",
    "    Clean variable name by removing prefixes, filtering out SRTM/NDVI, and converting to numeric.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_name : str\n",
    "        Original variable name\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int or None\n",
    "        Numeric variable value, or None if SRTM/NDVI (to be filtered out)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove common prefixes\n",
    "    prefixes_to_remove = [\n",
    "        'ensemble_mean_bioclim_',\n",
    "        'bioclim_',\n",
    "        'ensemble_mean_',\n",
    "        'mean_',\n",
    "        'std_',\n",
    "        'min_',\n",
    "        'max_'\n",
    "    ]\n",
    "    \n",
    "    cleaned_name = var_name\n",
    "    for prefix in prefixes_to_remove:\n",
    "        if cleaned_name.startswith(prefix):\n",
    "            cleaned_name = cleaned_name[len(prefix):]\n",
    "            break\n",
    "    \n",
    "    # Filter out SRTM and NDVI variables\n",
    "    if 'srtm' in cleaned_name.lower() or 'ndvi' in cleaned_name.lower():\n",
    "        return None  # Return None to indicate this variable should be filtered out\n",
    "    \n",
    "    # Convert to numeric (remove leading zeros)\n",
    "    try:\n",
    "        # Remove leading zeros and convert to int\n",
    "        numeric_value = int(cleaned_name.lstrip('0') or '0')\n",
    "        return numeric_value\n",
    "    except ValueError:\n",
    "        # If conversion fails, return None to filter out\n",
    "        return None\n",
    "\n",
    "def clean_variable_list(var_list):\n",
    "    \"\"\"\n",
    "    Clean a list of variable names, filtering out SRTM/NDVI and converting to numeric.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_list : list\n",
    "        List of variable names\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of numeric variable values (SRTM/NDVI filtered out)\n",
    "    \"\"\"\n",
    "    cleaned_vars = []\n",
    "    for var in var_list:\n",
    "        cleaned_var = clean_variable_name(var)\n",
    "        if cleaned_var is not None:  # Only include non-None variables\n",
    "            cleaned_vars.append(cleaned_var)\n",
    "    return cleaned_vars\n",
    "\n",
    "def remove_duplicates_preserve_order(var_list):\n",
    "    \"\"\"\n",
    "    Remove duplicates while preserving order.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_list : list\n",
    "        List of variables (may contain duplicates)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List without duplicates\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for var in var_list:\n",
    "        if var not in seen:\n",
    "            seen.add(var)\n",
    "            result.append(var)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Comprehensive Analysis Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD COMPREHENSIVE ANALYSIS RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "def load_comprehensive_analysis_results(base_path, specie, training, bio):\n",
    "    \"\"\"\n",
    "    Load comprehensive analysis results from different iterations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Base path to the project directory\n",
    "    specie : str\n",
    "        Species name\n",
    "    training : str\n",
    "        Training region\n",
    "    bio : str\n",
    "        Bio variables type\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results_dict : dict\n",
    "        Dictionary containing results from all iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    results_dict = {}\n",
    "    figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')  # Figures directory\n",
    "    \n",
    "    # Look for comprehensive analysis summary files\n",
    "    pattern = f\"06_comprehensive_analysis_summary_{specie}_{training}_{bio}_*.json\"\n",
    "    \n",
    "    print(f\"Looking for files matching pattern: {pattern}\")\n",
    "    \n",
    "    # Find all matching files\n",
    "    import glob\n",
    "    files = glob.glob(os.path.join(figs_path, pattern))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No comprehensive analysis summary files found in {figs_path}\")\n",
    "        print(f\"Looking for any JSON files with 'comprehensive' in the name...\")\n",
    "        \n",
    "        # Try broader search\n",
    "        all_json_files = glob.glob(os.path.join(figs_path, \"*comprehensive*.json\"))\n",
    "        print(f\"Found {len(all_json_files)} files with 'comprehensive' in name:\")\n",
    "        for f in all_json_files:\n",
    "            print(f\"  - {os.path.basename(f)}\")\n",
    "        \n",
    "        files = all_json_files\n",
    "    \n",
    "    print(f\"Found {len(files)} comprehensive analysis summary files\")\n",
    "    \n",
    "    for file_path in files:\n",
    "        try:\n",
    "            # Extract iteration from filename\n",
    "            filename = os.path.basename(file_path)\n",
    "            \n",
    "            # Try to extract iteration number\n",
    "            if \"iteration\" in filename.lower():\n",
    "                # Extract iteration number from filename\n",
    "                import re\n",
    "                match = re.search(r'iteration[_-]?(\\d+)', filename, re.IGNORECASE)\n",
    "                if match:\n",
    "                    iteration = f\"iteration_{match.group(1)}\"\n",
    "                else:\n",
    "                    iteration = filename.replace('.json', '')\n",
    "            else:\n",
    "                iteration = filename.replace('.json', '')\n",
    "            \n",
    "            # Load JSON file\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            results_dict[iteration] = data\n",
    "            print(f\"‚úì Loaded {iteration} from {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error loading {file_path}: {str(e)}\")\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "# Load results\n",
    "print(\"Loading comprehensive analysis results...\")\n",
    "comprehensive_results = load_comprehensive_analysis_results(base_path, specie, training, bio)\n",
    "\n",
    "print(f\"\\nLoaded {len(comprehensive_results)} comprehensive analysis results\")\n",
    "for iteration in comprehensive_results.keys():\n",
    "    print(f\"  - {iteration}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract and Compare Variable Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT AND COMPARE VARIABLE SETS\n",
    "# =============================================================================\n",
    "\n",
    "def extract_variable_sets(comprehensive_results):\n",
    "    \"\"\"\n",
    "    Extract final_variable_set and optimal_variables from comprehensive results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    comprehensive_results : dict\n",
    "        Dictionary containing comprehensive results from all iterations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_comparison = {}\n",
    "    \n",
    "    for iteration, results in comprehensive_results.items():\n",
    "        # Extract final variables from variable importance analysis\n",
    "        final_variables_raw = results.get('variable_importance_summary', {}).get('final_variable_set', [])\n",
    "        \n",
    "        # Extract optimal variables from spatial spread analysis\n",
    "        optimal_variables_raw = results.get('spatial_spread_summary', {}).get('optimal_variables', [])\n",
    "        \n",
    "        # Clean variable names (apply Variable Name Cleaning Functions)\n",
    "        final_variables = clean_variable_list(final_variables_raw)\n",
    "        optimal_variables = clean_variable_list(optimal_variables_raw)\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        final_variables = remove_duplicates_preserve_order(final_variables)\n",
    "        optimal_variables = remove_duplicates_preserve_order(optimal_variables)\n",
    "        \n",
    "        # Calculate overlap\n",
    "        final_set = set(final_variables)\n",
    "        optimal_set = set(optimal_variables)\n",
    "        \n",
    "        common_variables = list(final_set.intersection(optimal_set))\n",
    "        final_only = list(final_set - optimal_set)\n",
    "        optimal_only = list(optimal_set - final_set)\n",
    "        \n",
    "        # Calculate overlap percentage\n",
    "        total_unique = len(final_set.union(optimal_set))\n",
    "        overlap_percentage = (len(common_variables) / total_unique * 100) if total_unique > 0 else 0\n",
    "        \n",
    "        variable_comparison[iteration] = {\n",
    "            'final_variables': final_variables,\n",
    "            'optimal_variables': optimal_variables,\n",
    "            'common_variables': common_variables,\n",
    "            'final_only': final_only,\n",
    "            'optimal_only': optimal_only,\n",
    "            'overlap_percentage': overlap_percentage,\n",
    "            'total_final': len(final_variables),\n",
    "            'total_optimal': len(optimal_variables),\n",
    "            'total_common': len(common_variables)\n",
    "        }\n",
    "    \n",
    "    return variable_comparison\n",
    "\n",
    "def create_variable_comparison_table(variable_comparison):\n",
    "    \"\"\"\n",
    "    Create comparison table for variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        Comparison table\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for iteration, comparison in variable_comparison.items():\n",
    "        row = {\n",
    "            'Iteration': iteration,\n",
    "            'Final_Variables_Count': comparison['total_final'],\n",
    "            'Optimal_Variables_Count': comparison['total_optimal'],\n",
    "            'Common_Variables_Count': comparison['total_common'],\n",
    "            'Overlap_Percentage': comparison['overlap_percentage'],\n",
    "            'Final_Variables': ', '.join(map(str, comparison['final_variables'])),\n",
    "            'Optimal_Variables': ', '.join(map(str, comparison['optimal_variables'])),\n",
    "            'Common_Variables': ', '.join(map(str, comparison['common_variables'])),\n",
    "            'Final_Only': ', '.join(map(str, comparison['final_only'])),\n",
    "            'Optimal_Only': ', '.join(map(str, comparison['optimal_only']))\n",
    "        }\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Extract variable sets\n",
    "print(\"Extracting variable sets from comprehensive results...\")\n",
    "variable_comparison = extract_variable_sets(comprehensive_results)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_table = create_variable_comparison_table(variable_comparison)\n",
    "\n",
    "print(f\"\\nüìä Variable Sets Comparison Table:\")\n",
    "print(comparison_table.to_string(index=False))\n",
    "\n",
    "# Display summary statistics\n",
    "if not comparison_table.empty:\n",
    "    print(f\"\\nüìà Summary Statistics:\")\n",
    "    print(f\"‚Ä¢ Average Final Variables: {comparison_table['Final_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"‚Ä¢ Average Optimal Variables: {comparison_table['Optimal_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"‚Ä¢ Average Common Variables: {comparison_table['Common_Variables_Count'].mean():.1f}\")\n",
    "    print(f\"‚Ä¢ Average Overlap: {comparison_table['Overlap_Percentage'].mean():.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create 3 Optimized Variable Sets as Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE 3 OPTIMIZED VARIABLE SETS AS ARRAYS\n",
    "# =============================================================================\n",
    "\n",
    "def create_optimized_variable_sets(variable_comparison):\n",
    "    \"\"\"\n",
    "    Create 3 optimized variable sets as arrays based on analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable_comparison : dict\n",
    "        Dictionary containing variable sets comparison\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    optimized_sets : dict\n",
    "        Dictionary containing 3 optimized variable sets as arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    # Collect all variables from all iterations\n",
    "    all_final_variables = []\n",
    "    all_optimal_variables = []\n",
    "    all_common_variables = []\n",
    "    \n",
    "    for iteration, comparison in variable_comparison.items():\n",
    "        all_final_variables.extend(comparison['final_variables'])\n",
    "        all_optimal_variables.extend(comparison['optimal_variables'])\n",
    "        all_common_variables.extend(comparison['common_variables'])\n",
    "    \n",
    "    # Count variable frequency\n",
    "    from collections import Counter\n",
    "    \n",
    "    final_freq = Counter(all_final_variables)\n",
    "    optimal_freq = Counter(all_optimal_variables)\n",
    "    common_freq = Counter(all_common_variables)\n",
    "    \n",
    "    # Calculate variable scores (frequency + importance)\n",
    "    all_variables = set(all_final_variables + all_optimal_variables)\n",
    "    variable_scores = {}\n",
    "    \n",
    "    for var in all_variables:\n",
    "        final_score = final_freq.get(var, 0)\n",
    "        optimal_score = optimal_freq.get(var, 0)\n",
    "        common_score = common_freq.get(var, 0)\n",
    "        \n",
    "        # Combined score: common variables get highest weight\n",
    "        total_score = common_score * 3 + final_score + optimal_score\n",
    "        variable_scores[var] = total_score\n",
    "    \n",
    "    # Sort variables by score\n",
    "    sorted_variables = sorted(variable_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create 3 optimized sets as arrays\n",
    "    optimized_sets = {}\n",
    "    \n",
    "    # Set 1: Most frequent common variables (highest consensus)\n",
    "    common_vars_sorted = sorted(common_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    set1_vars = [var for var, freq in common_vars_sorted[:5]]  # Top 5 common variables\n",
    "    optimized_sets[\"Set 1 - Common Variables\"] = np.array(set1_vars)\n",
    "    \n",
    "    # Set 2: Best performing variables (highest combined score)\n",
    "    set2_vars = [var for var, score in sorted_variables[:6]]  # Top 6 variables by score\n",
    "    optimized_sets[\"Set 2 - Best Performing\"] = np.array(set2_vars)\n",
    "    \n",
    "    # # Set 3: Balanced approach (mix of common and unique high-scoring variables)\n",
    "    # # Take top 3 common + top 3 unique high-scoring variables\n",
    "    # common_top3 = [var for var, freq in common_vars_sorted[:3]]\n",
    "    # unique_vars = [var for var, score in sorted_variables if var not in common_top3][:3]\n",
    "    # set3_vars = common_top3 + unique_vars\n",
    "    # optimized_sets[\"Set 3 - Balanced Approach\"] = np.array(set3_vars)\n",
    "    \n",
    "    # Add metadata for each set (create separate dictionary to avoid modification during iteration)\n",
    "    metadata_dict = {}\n",
    "    for set_name, variables in optimized_sets.items():\n",
    "        # Calculate set characteristics\n",
    "        common_count = sum(1 for var in variables if var in common_freq)\n",
    "        final_count = sum(1 for var in variables if var in final_freq)\n",
    "        optimal_count = sum(1 for var in variables if var in optimal_freq)\n",
    "        \n",
    "        # Add metadata to separate dictionary\n",
    "        metadata_dict[f\"{set_name}_metadata\"] = {\n",
    "            'variable_count': len(variables),\n",
    "            'common_variables': common_count,\n",
    "            'final_variables': final_count,\n",
    "            'optimal_variables': optimal_count,\n",
    "            'consensus_score': common_count / len(variables) if len(variables) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Add metadata to optimized_sets after iteration is complete\n",
    "    optimized_sets.update(metadata_dict)\n",
    "    \n",
    "    return optimized_sets, variable_scores\n",
    "\n",
    "def create_variable_sets_table(optimized_sets):\n",
    "    \"\"\"\n",
    "    Create table for the 3 optimized variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    optimized_sets : dict\n",
    "        Dictionary containing optimized variable sets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        Variable sets table\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets:\n",
    "            variables = optimized_sets[set_name]\n",
    "            metadata = optimized_sets.get(f\"{set_name}_metadata\", {})\n",
    "            \n",
    "            row = {\n",
    "                'Set_Name': set_name,\n",
    "                'Variable_Count': metadata.get('variable_count', len(variables)),\n",
    "                'Common_Variables': metadata.get('common_variables', 0),\n",
    "                'Final_Variables': metadata.get('final_variables', 0),\n",
    "                'Optimal_Variables': metadata.get('optimal_variables', 0),\n",
    "                'Consensus_Score': metadata.get('consensus_score', 0),\n",
    "                'Variables': ', '.join(map(str, variables)) if len(variables) > 0 else ''\n",
    "            }\n",
    "            data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create optimized variable sets\n",
    "print(\"Creating 3 optimized variable sets as arrays...\")\n",
    "optimized_sets, variable_scores = create_optimized_variable_sets(variable_comparison)\n",
    "\n",
    "# Create variable sets table\n",
    "sets_table = create_variable_sets_table(optimized_sets)\n",
    "\n",
    "print(f\"\\nüéØ Optimized Variable Sets:\")\n",
    "print(sets_table.to_string(index=False))\n",
    "\n",
    "# Display the sets in the requested array format\n",
    "print(f\"\\nüìã Variable Sets as Arrays (with Variable Name Cleaning Applied):\")\n",
    "print(\"# Variable Sets as NumPy Arrays\")\n",
    "# for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "    if set_name in optimized_sets:\n",
    "        variables = optimized_sets[set_name]\n",
    "        print(f\"\\n{set_name}:\")\n",
    "        print(f\"variables_{set_name.lower().replace(' ', '_').replace('-', '_')} = np.array({list(variables)})\")\n",
    "        print(f\"# Array shape: {variables.shape}\")\n",
    "        print(f\"# Variables: {list(variables)}\")\n",
    "\n",
    "# Display variable scores for reference\n",
    "print(f\"\\nüìä Variable Scores (Top 10):\")\n",
    "sorted_scores = sorted(variable_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (var, score) in enumerate(sorted_scores[:10]):\n",
    "    print(f\"{i+1:2d}. {var}: {score:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "if savefig:\n",
    "    print(\"Saving results...\")\n",
    "    \n",
    "    # Save comparison table\n",
    "    if not comparison_table.empty:\n",
    "        comparison_file = os.path.join(results_path, f\"08_variable_comparison_{specie}_{training}_{bio}.csv\")\n",
    "        comparison_table.to_csv(comparison_file, index=False)\n",
    "        print(f\"‚úì Variable comparison table saved to: {comparison_file}\")\n",
    "    \n",
    "    # Save variable sets table\n",
    "    if not sets_table.empty:\n",
    "        sets_file = os.path.join(results_path, f\"08_optimized_variable_sets_{specie}_{training}_{bio}.csv\")\n",
    "        sets_table.to_csv(sets_file, index=False)\n",
    "        print(f\"‚úì Optimized variable sets table saved to: {sets_file}\")\n",
    "    \n",
    "    # Save optimized sets in JSON format (convert numpy arrays to lists)\n",
    "    json_sets = {}\n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets and len(optimized_sets[set_name]) > 0:\n",
    "            # Convert numpy array to list for JSON serialization\n",
    "            json_sets[set_name] = optimized_sets[set_name].tolist()\n",
    "    \n",
    "    json_file = os.path.join(results_path, f\"08_optimized_variable_sets_{specie}_{training}_{bio}.json\")\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(json_sets, f, indent=2)\n",
    "    print(f\"‚úì Optimized variable sets JSON saved to: {json_file}\")\n",
    "    \n",
    "    # Save variable scores\n",
    "    scores_file = os.path.join(results_path, f\"08_variable_scores_{specie}_{training}_{bio}.json\")\n",
    "    with open(scores_file, 'w') as f:\n",
    "        json.dump(variable_scores, f, indent=2)\n",
    "    print(f\"‚úì Variable scores saved to: {scores_file}\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    comprehensive_file = os.path.join(results_path, f\"08_comprehensive_variable_analysis_{specie}_{training}_{bio}.json\")\n",
    "    comprehensive_data = {\n",
    "        'variable_comparison': variable_comparison,\n",
    "        'optimized_sets': {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in optimized_sets.items()},\n",
    "        'variable_scores': variable_scores\n",
    "    }\n",
    "    with open(comprehensive_file, 'w') as f:\n",
    "        json.dump(comprehensive_data, f, indent=2, default=str)\n",
    "    print(f\"‚úì Comprehensive variable analysis saved to: {comprehensive_file}\")\n",
    "    \n",
    "    # Save Python code for the variable sets\n",
    "    python_file = os.path.join(results_path, f\"08_variable_sets_code_{specie}_{training}_{bio}.py\")\n",
    "    with open(python_file, 'w') as f:\n",
    "        f.write(\"# Optimized Variable Sets (with Variable Name Cleaning Applied)\\\\n\")\n",
    "        f.write(\"import numpy as np\\\\n\\\\n\")\n",
    "        \n",
    "        # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "        for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "            if set_name in optimized_sets and len(optimized_sets[set_name]) > 0:\n",
    "                variables = optimized_sets[set_name]\n",
    "                var_name = set_name.lower().replace(' ', '_').replace('-', '_')\n",
    "                f.write(f\"# {set_name}\\\\n\")\n",
    "                f.write(f\"variables_{var_name} = np.array({list(variables)})\\\\n\\\\n\")\n",
    "    \n",
    "    print(f\"‚úì Python code for variable sets saved to: {python_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping file saving (savefig=False)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üéØ VARIABLE SETS COMPARISON COMPLETED\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if variable_comparison and optimized_sets:\n",
    "    print(f\"\\nüìä ANALYSIS SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Iterations Analyzed: {len(variable_comparison)}\")\n",
    "    print(f\"‚Ä¢ Comparison Tables Created: 2\")\n",
    "    print(f\"‚Ä¢ Optimized Variable Sets: 3 (as NumPy arrays)\")\n",
    "    print(f\"‚Ä¢ Variable Names Cleaned: ‚úì\")\n",
    "    print(f\"‚Ä¢ Prefixes Removed: ‚úì\")\n",
    "    print(f\"‚Ä¢ SRTM/NDVI Filtered Out: ‚úì\")\n",
    "    print(f\"‚Ä¢ Converted to Numeric: ‚úì\")\n",
    "    \n",
    "    print(f\"\\nüéØ OPTIMIZED VARIABLE SETS (ARRAYS):\")\n",
    "    sets = {\n",
    "        \"Set2\": list(optimized_sets.get(\"Set 1 - Common Variables\", [])),\n",
    "        \"Set3\": list(optimized_sets.get(\"Set 2 - Best Performing\", [])),\n",
    "    }\n",
    "\n",
    "    # for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\", \"Set 3 - Balanced Approach\"]:\n",
    "    for set_name in [\"Set 1 - Common Variables\", \"Set 2 - Best Performing\"]:\n",
    "        if set_name in optimized_sets:\n",
    "            variables = optimized_sets[set_name]\n",
    "            metadata = optimized_sets.get(f\"{set_name}_metadata\", {})\n",
    "            print(f\"‚Ä¢ {set_name}: {len(variables)} variables\")\n",
    "            print(f\"  - Array: {list(variables)}\")\n",
    "            print(f\"  - Consensus Score: {metadata.get('consensus_score', 0):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "    print(f\"‚Ä¢ CSV Tables: {results_path}\")\n",
    "    print(f\"‚Ä¢ JSON Files: {results_path}\")\n",
    "    print(f\"‚Ä¢ Python Code: {results_path}\")\n",
    "    \n",
    "    print(f\"\\nüîç KEY INSIGHTS:\")\n",
    "    if not comparison_table.empty:\n",
    "        avg_overlap = comparison_table['Overlap_Percentage'].mean()\n",
    "        avg_final = comparison_table['Final_Variables_Count'].mean()\n",
    "        avg_optimal = comparison_table['Optimal_Variables_Count'].mean()\n",
    "        \n",
    "        print(f\"‚Ä¢ Average Variable Overlap: {avg_overlap:.1f}%\")\n",
    "        print(f\"‚Ä¢ Average Final Variables: {avg_final:.1f}\")\n",
    "        print(f\"‚Ä¢ Average Optimal Variables: {avg_optimal:.1f}\")\n",
    "        \n",
    "        if avg_overlap > 70:\n",
    "            print(f\"‚Ä¢ Integration Level: HIGH - Strong consensus between approaches\")\n",
    "        elif avg_overlap > 50:\n",
    "            print(f\"‚Ä¢ Integration Level: MODERATE - Some consensus between approaches\")\n",
    "        else:\n",
    "            print(f\"‚Ä¢ Integration Level: LOW - Limited consensus between approaches\")\n",
    "    \n",
    "    print(f\"\\nüéØ RECOMMENDATIONS:\")\n",
    "    print(f\"1. Use Set 1 for maximum consensus (common variables)\")\n",
    "    print(f\"2. Use Set 2 for best performance (highest scoring variables)\")\n",
    "    print(f\"3. Use Set 3 for balanced approach (mix of common and unique)\")\n",
    "    print(f\"4. All variable names are cleaned and ready for use\")\n",
    "    print(f\"5. Variables are provided as numeric arrays for easy integration\")\n",
    "    print(f\"6. SRTM and NDVI variables have been filtered out\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  NO DATA FOUND:\")\n",
    "    print(f\"‚Ä¢ No comprehensive analysis results found\")\n",
    "    print(f\"‚Ä¢ Please run the main analysis notebook first\")\n",
    "    print(f\"‚Ä¢ Ensure JSON files are saved in the correct location\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(\"‚úÖ VARIABLE SETS COMPARISON COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
