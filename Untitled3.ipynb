{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6cbc31-6c90-480f-a933-346ab46a1774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data: 9627 samples, 20 features\n",
      "Feature columns: ['Unnamed: 0', 'ensemble_mean_bioclim_01', 'ensemble_mean_bioclim_02', 'ensemble_mean_bioclim_03', 'ensemble_mean_bioclim_04', 'ensemble_mean_bioclim_05', 'ensemble_mean_bioclim_06', 'ensemble_mean_bioclim_07', 'ensemble_mean_bioclim_08', 'ensemble_mean_bioclim_09', 'ensemble_mean_bioclim_10', 'ensemble_mean_bioclim_11', 'ensemble_mean_bioclim_12', 'ensemble_mean_bioclim_13', 'ensemble_mean_bioclim_14', 'ensemble_mean_bioclim_15', 'ensemble_mean_bioclim_16', 'ensemble_mean_bioclim_17', 'ensemble_mean_bioclim_18', 'ensemble_mean_bioclim_19']\n",
      "Class distribution: {0: 9149, 1: 478}\n",
      "Using MaxEnt with simple feature importance...\n",
      "Using simple feature importance (no CV)...\n",
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Starting with 20 features, targeting 5\n",
      "Using simple feature importance (no CV)...\n",
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_19. Remaining: 19\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_18. Remaining: 18\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_17. Remaining: 17\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_16. Remaining: 16\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_15. Remaining: 15\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_14. Remaining: 14\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_13. Remaining: 13\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_12. Remaining: 12\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_11. Remaining: 11\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_10. Remaining: 10\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_09. Remaining: 9\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_08. Remaining: 8\n",
      "Using simple feature importance (no CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_07. Remaining: 7\n",
      "Using simple feature importance (no CV)...\n",
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_06. Remaining: 6\n",
      "Using simple feature importance (no CV)...\n",
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "Removed ensemble_mean_bioclim_05. Remaining: 5\n",
      "Using simple feature importance (no CV)...\n",
      "MaxEnt model fitted successfully\n",
      "MaxEnt doesn't have feature_importances_, using permutation importance...\n",
      "Permutation importance failed: index 0 is out of bounds for axis 0 with size 0\n",
      "Using equal importance as fallback\n",
      "\n",
      "Top 12 most important features:\n",
      "                          importance\n",
      "feature                             \n",
      "Unnamed: 0                       1.0\n",
      "ensemble_mean_bioclim_01         1.0\n",
      "ensemble_mean_bioclim_02         1.0\n",
      "ensemble_mean_bioclim_03         1.0\n",
      "ensemble_mean_bioclim_04         1.0\n",
      "ensemble_mean_bioclim_05         1.0\n",
      "ensemble_mean_bioclim_06         1.0\n",
      "ensemble_mean_bioclim_07         1.0\n",
      "ensemble_mean_bioclim_08         1.0\n",
      "ensemble_mean_bioclim_09         1.0\n",
      "ensemble_mean_bioclim_10         1.0\n",
      "ensemble_mean_bioclim_11         1.0\n",
      "\n",
      "Final selected features: ['Unnamed: 0', 'ensemble_mean_bioclim_01', 'ensemble_mean_bioclim_02', 'ensemble_mean_bioclim_03', 'ensemble_mean_bioclim_04']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aciar/lib/python3.11/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Implement load_projections() to return (individual_list, ensemble)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 418\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal selected features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# 2) Ensemble vs average comparison\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m individual, ensemble \u001b[38;5;241m=\u001b[39m \u001b[43mload_projections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m cmp \u001b[38;5;241m=\u001b[39m compare_ensemble_vs_average(individual, ensemble)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnsemble vs Average comparison:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 87\u001b[0m, in \u001b[0;36mload_projections\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_projections\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[np\u001b[38;5;241m.\u001b[39mndarray], np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# individual = [np.load(\"model1_proj.npy\"), np.load(\"model2_proj.npy\"), ...]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# ensemble = np.load(\"ensemble_proj.npy\")\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# return individual, ensemble\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplement load_projections() to return (individual_list, ensemble)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Implement load_projections() to return (individual_list, ensemble)"
     ]
    }
   ],
   "source": [
    "# Variable Importance & Ensemble vs Average Comparison\n",
    "#\n",
    "# This cell provides two workflows:\n",
    "# 1) Feature importance on bioclim predictors with iterative elimination\n",
    "# 2) Ensemble projected change vs average of individual models\n",
    "#\n",
    "# Assumptions:\n",
    "# - You already have a modeling dataset X (bioclim features) and y (labels/probabilities)\n",
    "# - You have per-model projections (rasters/arrays) and an ensemble projection of the same shape\n",
    "#\n",
    "# Fill the hooks marked with TODO to connect to your data.\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# MaxEnt integration (if available)\n",
    "try:\n",
    "    import elapid as ela\n",
    "    MAXENT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MAXENT_AVAILABLE = False\n",
    "    print(\"elapid not available - will use RandomForest for feature importance\")\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Config hooks (edit as needed)\n",
    "# -----------------------------\n",
    "# Paths to hook into your existing data pipeline\n",
    "DATA_DIR = \"/scratch/gito_aciar/sdm-toolbox/out/leptocybe-invasa/output/exp_ensemble_mean_random_south-east-asia_False_False/\"\n",
    "TRAIN_DATA_FILE = \"ensemble_mean_model-train_input-data_leptocybe-invasa_random_south-east-asia_Set1_1.csv\"\n",
    "\n",
    "# Load training data from your existing pipeline\n",
    "# Expected: CSV with bioclim features, 'class' column (0/1), 'SampleWeight', and 'geometry'\n",
    "# TODO: adjust the path to match your actual training data file\n",
    "\n",
    "def load_training_data(csv_path: str = None) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Load training data from CSV file created by your pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        X: DataFrame with only predictor columns (bioclim features)\n",
    "        y: Series with binary target (0/1)\n",
    "        sample_weight: Series with sample weights\n",
    "    \"\"\"\n",
    "    if csv_path is None:\n",
    "        # Default path - your specific training data file\n",
    "        csv_path = os.path.join(DATA_DIR, TRAIN_DATA_FILE)\n",
    "    \n",
    "    # Load the training table\n",
    "    train = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Split features/labels/weights; drop non-feature columns\n",
    "    # x_train contains only predictor columns used by the model\n",
    "    x_train = train.drop(columns=['class', 'SampleWeight', 'geometry'])\n",
    "    # y_train is the binary target: 1 for presence, 0 for background\n",
    "    y_train = train['class']\n",
    "    # sample_weight per observation passed to the learner to correct bias/imbalance\n",
    "    sample_weight_train = train['SampleWeight']\n",
    "    \n",
    "    print(f\"Loaded training data: {x_train.shape[0]} samples, {x_train.shape[1]} features\")\n",
    "    print(f\"Feature columns: {list(x_train.columns)}\")\n",
    "    print(f\"Class distribution: {y_train.value_counts().to_dict()}\")\n",
    "    \n",
    "    return x_train, y_train, sample_weight_train\n",
    "\n",
    "# Placeholder to load projections from several individual models and the ensemble\n",
    "# Should return arrays of same shape, e.g., (H, W) or (N,) flattened\n",
    "# TODO: replace with your actual loader\n",
    "\n",
    "def load_projections() -> Tuple[List[np.ndarray], np.ndarray]:\n",
    "    # Example:\n",
    "    # individual = [np.load(\"model1_proj.npy\"), np.load(\"model2_proj.npy\"), ...]\n",
    "    # ensemble = np.load(\"ensemble_proj.npy\")\n",
    "    # return individual, ensemble\n",
    "    raise NotImplementedError(\"Implement load_projections() to return (individual_list, ensemble)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Feature importance + elimination\n",
    "# -----------------------------\n",
    "\n",
    "def compute_feature_importance_simple(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    sample_weight: pd.Series = None,\n",
    "    use_maxent: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simple feature importance without cross-validation (faster, more reliable).\n",
    "    \"\"\"\n",
    "    print(\"Using simple feature importance (no CV)...\")\n",
    "    \n",
    "    if use_maxent and MAXENT_AVAILABLE:\n",
    "        model = ela.MaxentModel(transform='logistic', beta_multiplier=1.5)\n",
    "        model_name = \"MaxEnt\"\n",
    "    else:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,  # Reduced for speed\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        )\n",
    "        model_name = \"RandomForest\"\n",
    "    \n",
    "    # Fit on full dataset\n",
    "    try:\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X, y, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X, y)\n",
    "        print(f\"{model_name} model fitted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting {model_name}: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Get feature importances\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        imp_df = pd.DataFrame({\n",
    "            'importance': importances,\n",
    "            'feature': X.columns\n",
    "        }).set_index('feature').sort_values('importance', ascending=False)\n",
    "        print(f\"Using {model_name} feature_importances_\")\n",
    "    else:\n",
    "        # For MaxEnt without feature_importances_, use permutation importance on full dataset\n",
    "        print(\"MaxEnt doesn't have feature_importances_, using permutation importance...\")\n",
    "        try:\n",
    "            pi = permutation_importance(\n",
    "                model, X, y, \n",
    "                n_repeats=5,  # Reduced for speed\n",
    "                scoring=\"roc_auc\", \n",
    "                n_jobs=-1, \n",
    "                random_state=42,\n",
    "                sample_weight=sample_weight\n",
    "            )\n",
    "            imp_df = pd.DataFrame({\n",
    "                'importance': pi.importances_mean,\n",
    "                'feature': X.columns\n",
    "            }).set_index('feature').sort_values('importance', ascending=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Permutation importance failed: {e}\")\n",
    "            # Last resort: equal importance\n",
    "            imp_df = pd.DataFrame({\n",
    "                'importance': [1.0] * len(X.columns),\n",
    "                'feature': X.columns\n",
    "            }).set_index('feature')\n",
    "            print(\"Using equal importance as fallback\")\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def compute_feature_importance(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    sample_weight: pd.Series = None,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    use_maxent: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute feature importance using cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Target labels\n",
    "        sample_weight: Sample weights (optional)\n",
    "        n_splits: Number of CV folds\n",
    "        random_state: Random seed\n",
    "        use_maxent: Whether to use MaxEnt instead of RandomForest\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    if use_maxent and MAXENT_AVAILABLE:\n",
    "        # Use MaxEnt model (same as your pipeline)\n",
    "        model_class = lambda: ela.MaxentModel(transform='logistic', beta_multiplier=1.5)\n",
    "        model_name = \"MaxEnt\"\n",
    "    else:\n",
    "        # Use RandomForest as fallback\n",
    "        model_class = lambda: RandomForestClassifier(\n",
    "            n_estimators=500,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        model_name = \"RandomForest\"\n",
    "\n",
    "    perm_imps: List[pd.Series] = []\n",
    "    aucs: List[float] = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold+1}: train={len(train_idx)}, test={len(test_idx)}\")\n",
    "        \n",
    "        # Check if test set is empty\n",
    "        if len(test_idx) == 0:\n",
    "            print(f\"Warning: Empty test set in fold {fold+1}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Check class distribution in test set\n",
    "        test_class_dist = y_test.value_counts()\n",
    "        print(f\"  Test set class distribution: {test_class_dist.to_dict()}\")\n",
    "        \n",
    "        # Skip if test set has only one class (can't compute AUC)\n",
    "        if len(test_class_dist) < 2:\n",
    "            print(f\"  Warning: Test set has only one class in fold {fold+1}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Handle sample weights\n",
    "        if sample_weight is not None:\n",
    "            sample_weight_train = sample_weight.iloc[train_idx]\n",
    "            sample_weight_test = sample_weight.iloc[test_idx]\n",
    "        else:\n",
    "            sample_weight_train = None\n",
    "            sample_weight_test = None\n",
    "        \n",
    "        # Fit model\n",
    "        model = model_class()\n",
    "        try:\n",
    "            if sample_weight_train is not None:\n",
    "                model.fit(X_train, y_train, sample_weight=sample_weight_train)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error fitting model in fold {fold+1}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Get predictions\n",
    "        try:\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_prob = model.predict_proba(X_test)[:, 1]\n",
    "            else:\n",
    "                # For MaxEnt, use predict method\n",
    "                y_prob = model.predict(X_test)\n",
    "            \n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            aucs.append(auc)\n",
    "            print(f\"  AUC: {auc:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error computing AUC in fold {fold+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Permutation importance on the held-out fold\n",
    "        try:\n",
    "            pi = permutation_importance(\n",
    "                model, X_test, y_test, \n",
    "                n_repeats=10, \n",
    "                scoring=\"roc_auc\", \n",
    "                n_jobs=-1, \n",
    "                random_state=random_state,\n",
    "                sample_weight=sample_weight_test\n",
    "            )\n",
    "            perm_imps.append(pd.Series(pi.importances_mean, index=X.columns))\n",
    "            print(f\"  Permutation importance computed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error computing permutation importance in fold {fold+1}: {e}\")\n",
    "            # Fallback: use feature importances from the model if available\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                perm_imps.append(pd.Series(model.feature_importances_, index=X.columns))\n",
    "                print(f\"  Using model feature_importances_ as fallback\")\n",
    "            else:\n",
    "                print(f\"  No fallback available, skipping fold {fold+1}\")\n",
    "                continue\n",
    "\n",
    "    # Check if we have any valid results\n",
    "    if len(perm_imps) == 0:\n",
    "        raise ValueError(\"No valid folds were processed. Check your data and class distribution.\")\n",
    "    \n",
    "    if len(aucs) == 0:\n",
    "        print(\"Warning: No valid AUC scores computed.\")\n",
    "        auc_mean, auc_std = 0.0, 0.0\n",
    "    else:\n",
    "        auc_mean, auc_std = np.mean(aucs), np.std(aucs)\n",
    "    \n",
    "    imp_df = pd.concat(perm_imps, axis=1)\n",
    "    imp_df.columns = [f\"fold_{i+1}\" for i in range(imp_df.shape[1])]\n",
    "    imp_df[\"mean_importance\"] = imp_df.mean(axis=1)\n",
    "    imp_df.sort_values(\"mean_importance\", ascending=False, inplace=True)\n",
    "\n",
    "    print(f\"{model_name} CV AUC mean: {auc_mean:.3f} Â± {auc_std:.3f} (from {len(aucs)} valid folds)\")\n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def iterative_elimination(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    sample_weight: pd.Series = None,\n",
    "    target_num_features: int = 5,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    use_maxent: bool = False,\n",
    "    use_simple: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Iteratively remove least important features until target number is reached.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Target labels\n",
    "        sample_weight: Sample weights (optional)\n",
    "        target_num_features: Target number of features to keep\n",
    "        n_splits: Number of CV folds\n",
    "        random_state: Random seed\n",
    "        use_maxent: Whether to use MaxEnt instead of RandomForest\n",
    "        use_simple: Whether to use simple (no CV) feature importance\n",
    "    \"\"\"\n",
    "    remaining_features = list(X.columns)\n",
    "    history: List[Dict[str, object]] = []\n",
    "\n",
    "    print(f\"Starting with {len(remaining_features)} features, targeting {target_num_features}\")\n",
    "\n",
    "    while len(remaining_features) > target_num_features:\n",
    "        X_sub = X[remaining_features]\n",
    "        \n",
    "        if use_simple:\n",
    "            imp_df = compute_feature_importance_simple(\n",
    "                X_sub, y, sample_weight=sample_weight, use_maxent=use_maxent\n",
    "            )\n",
    "            least_important = imp_df.index[-1]\n",
    "            importance_snapshot = imp_df[\"importance\"].to_dict()\n",
    "        else:\n",
    "            imp_df = compute_feature_importance(\n",
    "                X_sub, y, sample_weight=sample_weight, \n",
    "                n_splits=n_splits, random_state=random_state, use_maxent=use_maxent\n",
    "            )\n",
    "            least_important = imp_df.index[-1]\n",
    "            importance_snapshot = imp_df[\"mean_importance\"].to_dict()\n",
    "\n",
    "        remaining_features.remove(least_important)\n",
    "\n",
    "        history.append({\n",
    "            \"removed\": least_important,\n",
    "            \"num_features\": len(remaining_features),\n",
    "            \"importance_snapshot\": importance_snapshot,\n",
    "        })\n",
    "        print(f\"Removed {least_important}. Remaining: {len(remaining_features)}\")\n",
    "\n",
    "    if use_simple:\n",
    "        final_importance = compute_feature_importance_simple(\n",
    "            X[remaining_features], y, sample_weight=sample_weight, use_maxent=use_maxent\n",
    "        )\n",
    "    else:\n",
    "        final_importance = compute_feature_importance(\n",
    "            X[remaining_features], y, sample_weight=sample_weight,\n",
    "            n_splits=n_splits, random_state=random_state, use_maxent=use_maxent\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"selected_features\": remaining_features,\n",
    "        \"final_importance\": final_importance,\n",
    "        \"elimination_history\": history,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Ensemble vs average comparison\n",
    "# -----------------------------\n",
    "\n",
    "def compare_ensemble_vs_average(individual: List[np.ndarray], ensemble: np.ndarray) -> Dict[str, object]:\n",
    "    # Align shapes: flatten\n",
    "    ind_stack = np.vstack([arr.ravel() for arr in individual])  # shape: (M, N)\n",
    "    ensemble_flat = ensemble.ravel()  # shape: (N,)\n",
    "\n",
    "    avg_flat = ind_stack.mean(axis=0)\n",
    "    diff = ensemble_flat - avg_flat\n",
    "\n",
    "    metrics = {\n",
    "        \"mean_abs_diff\": float(np.mean(np.abs(diff))),\n",
    "        \"rmse\": float(np.sqrt(np.mean(diff**2))),\n",
    "        \"pearson_r\": float(np.corrcoef(ensemble_flat, avg_flat)[0, 1]),\n",
    "        \"bias\": float(np.mean(diff)),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"diff_flat\": diff,  # can be reshaped back by caller if needed\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage (enable by setting to True)\n",
    "# -----------------------------\n",
    "if True:\n",
    "    # 1) Feature importance + elimination\n",
    "    X, y, sample_weight = load_training_data()\n",
    "    \n",
    "    # Option 1: Use simple feature importance (recommended - faster and more reliable)\n",
    "    if MAXENT_AVAILABLE:\n",
    "        print(\"Using MaxEnt with simple feature importance...\")\n",
    "        imp = compute_feature_importance_simple(X, y, sample_weight=sample_weight, use_maxent=True)\n",
    "        result = iterative_elimination(X, y, sample_weight=sample_weight, target_num_features=5, use_maxent=True, use_simple=True)\n",
    "    else:\n",
    "        print(\"Using RandomForest with simple feature importance...\")\n",
    "        imp = compute_feature_importance_simple(X, y, sample_weight=sample_weight, use_maxent=False)\n",
    "        result = iterative_elimination(X, y, sample_weight=sample_weight, target_num_features=5, use_maxent=False, use_simple=True)\n",
    "    \n",
    "    print(\"\\nTop 12 most important features:\")\n",
    "    print(imp.head(12))\n",
    "    print(f\"\\nFinal selected features: {result['selected_features']}\")\n",
    "\n",
    "    # 2) Ensemble vs average comparison\n",
    "    individual, ensemble = load_projections()\n",
    "    cmp = compare_ensemble_vs_average(individual, ensemble)\n",
    "    print(\"\\nEnsemble vs Average comparison:\")\n",
    "    print(json.dumps(cmp[\"metrics\"], indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055eb52-9d3a-4eda-8153-d83a7d9d669a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
