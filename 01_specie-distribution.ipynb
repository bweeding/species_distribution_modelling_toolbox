{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2877812-a9ed-4ddc-ad7d-0205472c6993",
   "metadata": {},
   "source": [
    "# Specie distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b7ca8-8a86-49c9-be38-d0fc115e2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION SECTION - MODIFY THESE SETTINGS AS NEEDED\n",
    "# =============================================================================\n",
    "\n",
    "# specie = 'leptocybe-invasa' # 'thaumastocoris-peregrinus' # \n",
    "# training = 'sea' # 'australia'\n",
    "# interest = 'sea'\n",
    "# savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f160c-7dfc-405a-8b76-13379c36f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT REQUIRED LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import elapid as ela\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader\n",
    "\n",
    "from cartopy.io.shapereader import Reader, natural_earth\n",
    "from cartopy.feature import ShapelyFeature\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da18ad4-fd56-47b6-a5fc-95a88373f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAPPING CONFIGURATION AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "# Set default figure size and projection for all maps\n",
    "figsize = (18,12)  # Large figure size for detailed maps\n",
    "projection = ccrs.PlateCarree()  # Equirectangular projection (lat/lon coordinates)\n",
    "\n",
    "def make_map(figsize, projection, res):\n",
    "    \"\"\"\n",
    "    Create a standardized map with cartographic features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    figsize : tuple\n",
    "        Figure size in inches (width, height)\n",
    "    projection : cartopy.crs\n",
    "        Map projection to use\n",
    "    res : str\n",
    "        Resolution for cartographic features ('110m', '50m', '10m')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax, gl : matplotlib figure, axes, and gridlines objects\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=projection)\n",
    "    \n",
    "    # Add cartographic features in order of importance\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale(res))  # Country borders\n",
    "    ax.add_feature(cfeature.STATES.with_scale(res),   # State/province borders\n",
    "                   linestyle=':', edgecolor='gray', linewidth=0.5)\n",
    "    ax.add_feature(cfeature.LAND.with_scale(res), color='lightgray')  # Land areas\n",
    "    ax.add_feature(cfeature.COASTLINE.with_scale(res))  # Coastlines\n",
    "    \n",
    "    # Add gridlines for coordinate reference\n",
    "    gl = ax.gridlines(color='grey', linestyle=':', draw_labels=True, rotate_labels=False)\n",
    "       \n",
    "    return fig, ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6dc173-e007-485f-a1af-59bd82e9fc5e",
   "metadata": {},
   "source": [
    "## 1. Species Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ec736-a238-46af-b205-fbbee4bc4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DIRECTORY SETUP AND PATH CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Define main data directory (parent directory of current working directory)\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "   \n",
    "# Set up figures output directory\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')\n",
    "# Remove existing figures directory if it exists to start fresh\n",
    "if os.path.exists(figs_path):\n",
    "    shutil.rmtree(figs_path)\n",
    "\n",
    "# Create fresh figures directory\n",
    "os.makedirs(figs_path, exist_ok=True)\n",
    "\n",
    "# Set up output directory structure for the specific species\n",
    "out_path = os.path.join(os.path.dirname(os.getcwd()), 'out', specie)\n",
    "input_path = os.path.join(out_path, 'input')\n",
    "\n",
    "# Create all necessary directories for train/test data storage\n",
    "for path in [figs_path, os.path.join(input_path, 'train'), os.path.join(input_path, 'test')]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c015ecc-5358-457a-8403-d7a77afa1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD GLOBAL SPECIES OCCURRENCE DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Load the aggregated occurrence data for the specified species\n",
    "# The CSV file contains all known occurrence records with coordinates and source information\n",
    "occurences_global = pd.read_csv(os.path.join(data_path, 'species', specie, '%s_aggregated.csv' %specie))\n",
    "print('Number of occurences globally is: %s' %len(occurences_global))\n",
    "display(occurences_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0841d23-f2cd-429b-97c6-2b402f162721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# REGIONAL DEFINITIONS FOR SPECIES DISTRIBUTION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Dictionary defining different geographic regions for training and testing\n",
    "# Each key represents a region name, and the value is a list of country names\n",
    "# These regions are used to filter occurrence data for specific geographic areas\n",
    "regions = {\n",
    "    'east-asia': ['China', 'Taiwan', 'Japan', 'North Korea', 'South Korea'],\n",
    "    'indo': [\"Indonesia\",'Malaysia','Singapore','Brunei','East Timor'],\n",
    "    'sea': ['Myanmar', 'Cambodia', 'Laos', 'Philippines', 'Thailand', 'Vietnam'],\n",
    "    'south-east-asia': ['Brunei', 'Myanmar', 'Cambodia', 'East Timor', 'Indonesia', 'Laos', 'Malaysia', 'Philippines', 'Singapore', 'Thailand', 'Vietnam'],\n",
    "    'australia': ['Australia'],\n",
    "    'australasia' : ['Australia', 'New Zealand'],\n",
    "    'india-sri-lanka' : ['Sri Lanka'],\n",
    "    'all' : ['Australia','France','Italy','Portugal','South Africa','United States of America','Madagascar','Spain','Greece','Cyprus','Mexico','Kenya','Algeria','Israel','Egypt','Ethiopia','Ghana','Malawi','Mauritius','Morocco','Mozambique','Rwanda','Sierra Leone','United Republic of Tanzania','Tunisia','Uganda','Zimbabwe','China','India','Iran','Iraq','Jordan','Sri Lanka','Syria','Taiwan','Turkey','Malta','Montenegro','United Kingdom','Argentina','Brazil','Chile','Paraguay','Uruguay']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879fd6f-e92f-4685-8843-83ed9d902b63",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA CLEANING FOR LONGITUDE VALUES\n",
    "# =============================================================================\n",
    "\n",
    "# Clean longitude data for leptocybe-invasa species\n",
    "# Remove spaces from longitude values and convert to float for proper numeric processing\n",
    "if specie == 'leptocybe-invasa':\n",
    "    occurences_global['lon'] = occurences_global['lon'].str.replace(' ', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee28a7d-a914-4c44-868d-065675ea0bf3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE GEOPANDAS DATAFRAME AND FILTER VALID COORDINATES\n",
    "# =============================================================================\n",
    "\n",
    "# Convert longitude and latitude columns to Point geometries for spatial analysis\n",
    "geometry = gpd.points_from_xy(occurences_global['lon'], occurences_global['lat'])\n",
    "# Create GeoDataFrame with source information and geometry\n",
    "occurences = gpd.GeoDataFrame(occurences_global['source'], geometry=geometry)\n",
    "\n",
    "# Remove occurrences that have invalid or empty coordinates\n",
    "# This filters out any records where coordinates couldn't be properly parsed\n",
    "occurences = occurences[~occurences.is_empty]\n",
    "print('Number of occurences globally after removing occurrences without coordinates: %s' %len(occurences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5d942-a805-4dd3-932f-25b7254bc73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE GLOBAL OCCURRENCE MAP BY DATA SOURCE\n",
    "# =============================================================================\n",
    "\n",
    "# Assign unique colors to each data source for visualization\n",
    "colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "dict_color = {src: colors[i]  for i, src in enumerate(occurences.source.unique())}\n",
    "occurences['color'] = occurences['source'].map(dict_color)\n",
    "\n",
    "# Create a global map with cartographic features\n",
    "fig, ax, gl = make_map(figsize, projection, res='110m')\n",
    "\n",
    "# Plot occurrence points colored by data source\n",
    "for src, df in occurences.groupby('source'):\n",
    "    ax.scatter(x=df.geometry.x, y=df.geometry.y, color=df.color, label=src, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Add a reference box showing the SEA-22 region boundaries\n",
    "ax.plot([89.26, 146.96, 146.96, 89.26, 89.26], [-15.14, -15.14, 27.26, 27.26, -15.14], transform=ccrs.PlateCarree(), label='SEA-22', color=colors[len(occurences.source.unique())])   \n",
    "ax.legend(loc='lower left')                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb845b4-368a-4588-a4c3-93b2756532e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE GLOBAL OCCURRENCE MAP\n",
    "# =============================================================================\n",
    "\n",
    "if savefig:\n",
    "    fig.savefig(os.path.join(figs_path, '01_presence_%s_global.png' %specie), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59720c4b-4d95-4c87-91e0-448000277387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD COUNTRY BOUNDARIES FROM NATURAL EARTH DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Download and load country boundary data from Natural Earth dataset\n",
    "# This provides high-quality vector data for country polygons\n",
    "resolution = '50m'  # Medium resolution for good detail without excessive file size\n",
    "category = 'cultural'  # Cultural features (countries, states, etc.)\n",
    "name = 'admin_0_countries'  # Administrative level 0 (country-level boundaries)\n",
    "\n",
    "# Download the shapefile from Natural Earth\n",
    "shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "# Load the country boundaries as a GeoDataFrame\n",
    "countries = gpd.read_file(shpfilename)\n",
    "# display(countries)  # Uncomment to inspect the loaded country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81417b76-880f-409f-a276-375cb70771a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT COUNTRIES FOR TRAINING REGION AND CREATE BOUNDARY SHAPEFILE\n",
    "# =============================================================================\n",
    "\n",
    "# Create a combined GeoDataFrame containing all countries in the training region\n",
    "gdf_countries = gpd.GeoDataFrame()\n",
    "for country in regions[training]:\n",
    "    # Extract the country polygon from the global countries dataset\n",
    "    cntry = countries.loc[countries['ADMIN'] == country]\n",
    "    # Combine all countries in the region into a single GeoDataFrame\n",
    "    gdf_countries = pd.concat([gdf_countries, cntry])\n",
    "\n",
    "# Save the regional boundary as a shapefile for use in downstream analysis\n",
    "# This creates a single polygon representing the entire training region\n",
    "gdf_countries.to_file(os.path.join(input_path, '%s.shp' %training))\n",
    "# Alternative save locations (commented out):\n",
    "# gdf_countries.to_file(os.path.join(input_path, 'train', '%s.shp' %training))\n",
    "# gdf_countries.to_file(os.path.join(input_path, 'test', '%s.shp' %training))\n",
    "\n",
    "# Uncomment the following lines to inspect the regional boundary data:\n",
    "# gdf_countries\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# display(gdf_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47782caf-5692-46d8-aee5-cdc50548ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTER OCCURRENCES BY TRAINING REGION\n",
    "# =============================================================================\n",
    "\n",
    "# Perform spatial filtering to identify occurrences within the training region\n",
    "# Start with the first country in the region\n",
    "in_region = occurences.within(gdf_countries.geometry.values[0])\n",
    "\n",
    "# Iterate through remaining countries and combine results using OR logic\n",
    "# This ensures we capture occurrences in any country within the training region\n",
    "for i in range(1, len(gdf_countries)):\n",
    "    in_region = in_region | occurences.within(gdf_countries.geometry.values[i])\n",
    "    \n",
    "# Extract only the occurrences that fall within the training region\n",
    "occurences_region = occurences[in_region]\n",
    "\n",
    "print('Number of occurences in %s is: %s' %(training, len(occurences_region)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a043b5-ad1c-48c9-9686-6393b7321c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ALTERNATIVE SPATIAL JOIN METHOD (COMMENTED OUT)\n",
    "# =============================================================================\n",
    "\n",
    "# Alternative approach using spatial join to identify country for each occurrence\n",
    "# This method would add country information to each occurrence point\n",
    "# Currently commented out as we use the within() method above for filtering\n",
    "\n",
    "# result = gpd.sjoin(occurences, countries, how='left')  # Spatial join to get country info\n",
    "# result2 = result['ADMIN'].unique()  # Get unique country names\n",
    "# print(result2)  # Display all countries where occurrences are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b6c7d-4f23-409a-a801-c4f304010afe",
   "metadata": {},
   "source": [
    "## 2. Define Training and Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65992fe-9182-4320-bf06-743fc2f4cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT COORDINATES FROM GEOMETRY FOR TRAIN/TEST SPLITTING\n",
    "# =============================================================================\n",
    "\n",
    "# Extract longitude and latitude coordinates from the Point geometry objects\n",
    "# This creates separate columns for lon/lat that are needed for train/test splitting\n",
    "occurences_region['lon'] = occurences_region['geometry'].x\n",
    "occurences_region['lat'] = occurences_region['geometry'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50860c5-9e41-4527-a5a9-aed3d684e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATE MULTIPLE TRAIN/TEST SPLITS FOR MODEL VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# --- Split Parameters ---\n",
    "n_repeats = n_iteration  # Number of train/test splits to generate\n",
    "train_size = 0.7  # 70% of data for training, 30% for testing\n",
    "\n",
    "# --- Random Sampling Setup ---\n",
    "# Use ShuffleSplit for random sampling without stratification\n",
    "# random_state=42 ensures reproducible results across runs\n",
    "splitter = ShuffleSplit(n_splits=n_repeats, train_size=train_size, random_state=42)\n",
    "\n",
    "# Generate multiple train/test splits and save each one\n",
    "for i, (train_idx, test_idx) in enumerate(splitter.split(occurences_region), start=1):\n",
    "    # Create training and testing datasets\n",
    "    train_df = occurences_region.iloc[train_idx].reset_index(drop=True)\n",
    "    test_df = occurences_region.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    # Save train and test datasets as CSV files\n",
    "    # Only save longitude and latitude columns for downstream modeling\n",
    "    train_df.to_csv(os.path.join(input_path, 'train', '%s_presence_%s_%s.csv' %(specie, training, i)), columns=['lon', 'lat'], index=False)\n",
    "    test_df.to_csv(os.path.join(input_path, 'test', '%s_presence_%s_%s.csv' %(specie, interest, i)), columns=['lon', 'lat'], index=False)\n",
    "\n",
    "    print(f\"Split {i} -> Train: {len(train_df)} rows, Test: {len(test_df)} rows\")\n",
    "\n",
    "    # Create visualization of the train/test split\n",
    "    fig, ax, gl = make_map(figsize, projection, res='50m')\n",
    "    \n",
    "    # Plot regional boundaries and train/test points\n",
    "    gdf_countries.plot(ax=ax, alpha=0.5)  # Regional boundaries (semi-transparent)\n",
    "    train_df.plot(ax=ax, marker='*', markersize=100, color='tab:red', label=\"train\")  # Training points (red)\n",
    "    test_df.plot(ax=ax, marker='*', markersize=100, color='tab:blue', label=\"test\")  # Testing points (blue)\n",
    "      \n",
    "    ax.legend(loc='lower left')\n",
    "    \n",
    "    # Save the visualization if savefig is enabled\n",
    "    if savefig:\n",
    "        fig.savefig(os.path.join(figs_path, '01_presence_%s_%s.png' %(specie, i)), transparent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894bc31-fea1-475d-b30d-5d33951ff538",
   "metadata": {},
   "source": [
    "load host data (Eucalyptus) from Abbasi et al. 2023\n",
    "https://www.nature.com/articles/s41597-023-02383-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cf8c6-5c31-4ef8-9bbd-8f3cf570963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD EUCALYPTUS FOREST DATA FOR EAST ASIA REGION\n",
    "# =============================================================================\n",
    "\n",
    "# Load Eucalyptus forest distribution data if the training region is East Asia\n",
    "# This data provides information about planted Eucalyptus forests in the region\n",
    "if training == 'east-asia':\n",
    "    # Construct path to the zipped shapefile containing planted forest data\n",
    "    planted_forest_file = os.path.join('zip://', data_path, 'planted-forest-east-asia', 'planted-forest-east-asia.zip')\n",
    "    # Load only Eucalyptus species from the planted forest dataset\n",
    "    # The 'where' parameter filters the data to include only Eucalyptus genus\n",
    "    eucalyptus_forest = gpd.read_file(planted_forest_file, where=\"Genus='Eucalyptus'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
