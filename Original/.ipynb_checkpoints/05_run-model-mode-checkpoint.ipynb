{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b15204-7112-48a4-97c4-bc90bc40550d",
   "metadata": {},
   "source": [
    "# Run Maxent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7b778-d906-49be-86c9-9759448f7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CHANGE THESE TO YOUR LIKING ###############\n",
    "\n",
    "#specie = 'leptocybe-invasa' # 'thaumastocoris-peregrinus' # 'leptocybe-invasa' # \n",
    "#pseudoabsence = 'random' # 'biased-land-cover' # 'biased' # 'random' # \n",
    "#training = 'india-sri-lanka'# 'australia' # \n",
    "#interest = 'south-east-asia'\n",
    "# bioclim = bioclim_model\n",
    "bioclim = bioclim\n",
    "bio = bio1\n",
    "#bioclim = [i for i in range(1,20)] # [1, 5, 6, 12, 13, 14] # [1, 16, 6, 11] # [10, 16, 14] # [1,2,6,11,13,15,16] #\n",
    "topo = topo1\n",
    "ndvi = ndvi1\n",
    "# topo = True\n",
    "savefig = True\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d412007-8c3c-4d88-b041-99f47ef4ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rioxr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import elapid as ela\n",
    "from sklearn import metrics, inspection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6557f1-586b-4229-babf-5135b0e90569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_layout(nplots):\n",
    "\n",
    "    ncols = min(int(np.ceil(np.sqrt(nplots))), 4)\n",
    "    nrows = int(np.ceil(nplots / ncols))\n",
    "    \n",
    "    return ncols, nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c5c92-7ef0-4dce-bd31-a2cc9fef5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = os.path.join(os.sep, 'scratch', 'aciar-fst', 'data')\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')\n",
    "docs_path = os.path.join(os.path.dirname(os.getcwd()), 'docs')\n",
    "out_path = os.path.join(os.path.dirname(os.getcwd()), 'out', specie)\n",
    "input_path = os.path.join(out_path, 'input')\n",
    "train_path = os.path.join(input_path, 'train')\n",
    "test_path = os.path.join(input_path, 'test')\n",
    "output_path = os.path.join(out_path, 'output')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f19209-7f3b-409d-b4e7-d7a98dac6591",
   "metadata": {},
   "source": [
    "Load shapefiles of training and test regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78573035-d8c3-4e4a-b5b5-0d0dec559050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and combine countries in one dataframe\n",
    "gdf_countries = {}\n",
    "# for region in [training, interest]:\n",
    "#     file_path = train_path if region == training else test_path\n",
    "#     gdf_countries[region] = gpd.read_file(os.path.join(file_path, '%s.shp' %region))\n",
    "\n",
    "gdf_countries = gpd.read_file(os.path.join(input_path, '%s.shp' %training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7a900-85cd-41d4-87e6-7179c9320233",
   "metadata": {},
   "source": [
    "## 1. Train model for region of specie occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a59e2f-1490-4a88-9e39-92bbd8d76c7f",
   "metadata": {},
   "source": [
    "### 1.1 load predictive variable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e425b37-7c46-4d47-9adf-6de927cc88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasters, labels = (['srtm_%s.tif' %training], ['srtm']) if topo else ([], []) # 'ndvi_east-asia.tif', 'ndvi' # \n",
    "\n",
    "rasters, labels = (\n",
    "    (['srtm_%s.tif' % training], ['srtm']) if topo else ([], [])\n",
    ")\n",
    "rasters, labels = (\n",
    "    rasters + (['ndvi_%s.tif' % training] if ndvi else []),\n",
    "    labels  + (['ndvi'] if ndvi else [])\n",
    ")\n",
    "\n",
    "\n",
    "# if Future:\n",
    "#     for no in bioclim:\n",
    "#         rasters.append('bio_%s_%s_future.tif' %(no, training))\n",
    "#         labels.append('bioclim_%02d' %no)\n",
    "# else:\n",
    "#     for no in bioclim:\n",
    "#         rasters.append('bio_%s_%s.tif' %(no, training))\n",
    "#         labels.append('bioclim_%02d' %no)\n",
    "\n",
    "for no in bioclim:\n",
    "    rasters.append('%s_bio_%s_%s.tif' %(model_prefix, no, training))\n",
    "    labels.append('%s_bioclim_%02d' %(model_prefix, no))\n",
    "\n",
    "raster_paths = [os.path.join(input_path, raster) for raster in rasters]\n",
    "# rasters, raster_paths, labels\n",
    "\n",
    "# initialise dataset for model output\n",
    "training_output = xr.Dataset()\n",
    "for raster, label in zip(raster_paths, labels):\n",
    "    da = rioxr.open_rasterio(raster, masked=True)\n",
    "    training_output[label] = da\n",
    "\n",
    "# print(label)\n",
    "# print(da)\n",
    "\n",
    "# # Plot semua raster dari dataset\n",
    "# num_plots = len(labels)\n",
    "# fig, axes = plt.subplots(4, 5, figsize=(20, 16))  # 4 baris, 5 kolom\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, label in zip(axes, labels):\n",
    "#     training_data[label].plot(ax=ax, cmap='viridis')\n",
    "#     ax.set_title(label)\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Sembunyikan subplot kosong jika ada\n",
    "# for ax in axes[len(labels):]:\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(training_output)\n",
    "# training_output.to_netcdf('../data/training_output.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d49fd-4f91-411c-8ad4-90c0f202894f",
   "metadata": {},
   "source": [
    "### 1.2 load and merge presence and background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ba83f-5574-4abf-8515-fe905117d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_file_name = '%s_presence_%s_%s.csv' %(specie, training, iteration)\n",
    "background_file_name = '%s_background_%s_%s.csv' %(specie, pseudoabsence, training)\n",
    "train_input_data_name = '%s_model-train_input-data_%s_%s_%s_%s_%s.csv' %(model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "\n",
    "presence_csv = pd.read_csv(os.path.join(input_path, 'train', presence_file_name))\n",
    "geometry = gpd.points_from_xy(presence_csv['lon'], presence_csv['lat'])\n",
    "presence_gdf = gpd.GeoDataFrame(geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "background_csv = pd.read_csv(os.path.join(input_path, 'train', background_file_name))\n",
    "geometry = gpd.points_from_xy(background_csv['lon'], background_csv['lat'])\n",
    "background_gdf = gpd.GeoDataFrame(geometry=geometry, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cc7b4-b97d-45cc-9843-a0c2025572ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_train = ela.annotate(\n",
    "    presence_gdf.geometry,\n",
    "    raster_paths=raster_paths, \n",
    "    labels=labels, \n",
    "    drop_na=True,\n",
    ")\n",
    "\n",
    "background_train = ela.annotate(\n",
    "    background_gdf, #pseudoabsence_random, pseudoabsence_bias_eucalyptus, #pseudoabsence_bias_perc_planted\n",
    "    raster_paths=raster_paths, \n",
    "    labels=labels, \n",
    "    drop_na=True,\n",
    ")\n",
    "\n",
    "train = ela.stack_geodataframes(\n",
    "    presence_train,\n",
    "    background_train,\n",
    "    add_class_label=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc0b43-7772-427f-9ac5-54d542a03b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66728b4-87b4-4ce7-acd8-79cac73690d3",
   "metadata": {},
   "source": [
    "### 1.3 run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0a717-0fa9-4520-9d29-bcd8b49d973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1.3 Run Model\")\n",
    "experiment_name = 'exp_%s_%s_%s' %(pseudoabsence, training, interest)\n",
    "run_name = '%s_model-train_%s_%s_%s_%s_%s.ela' %(model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "nc_name = '%s_model-train_%s_%s_%s_%s_%s.nc' %(model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "raster_name = '%s_model-train_%s_%s_%s_%s_%s.tif' %(model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "\n",
    "exp_path = os.path.join(output_path, experiment_name)\n",
    "if not os.path.exists(exp_path):\n",
    "    os.makedirs(exp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188e2b0-981b-477d-a7a3-200842f5cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model input data to csv\n",
    "train.to_csv(os.path.join(exp_path, train_input_data_name))\n",
    "\n",
    "# split the x/y data\n",
    "x_train = train.drop(columns=['class', 'geometry'])\n",
    "y_train = train['class']\n",
    "\n",
    "# train the model\n",
    "model_train = ela.MaxentModel(transform='logistic', beta_multiplier=1.5)\n",
    "print(model_train.get_params())\n",
    "model_train.fit(x_train, y_train)\n",
    "\n",
    "# write the fitted model to file\n",
    "ela.save_object(model_train, os.path.join(exp_path, run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba25d5-500f-4ae3-9f10-6cf41f92ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "y_train_predict = model_train.predict(x_train)\n",
    "\n",
    "# save the environment variables and model predictions to xarray.Dataset\n",
    "array = training_output.isel(band=0).to_array().values\n",
    "nodata = np.nan\n",
    "nodata_idx = np.isnan(array)\n",
    "rop = ela.geo.apply_model_to_array(model_train, array, nodata, nodata_idx)\n",
    "\n",
    "training_output['rop'] = (('band', 'y', 'x'), rop)\n",
    "training_output['rop'].attrs['long_name'] = \"relative occurrence probability\"\n",
    "\n",
    "# write model output to netcdf\n",
    "training_output.to_netcdf(os.path.join(exp_path, nc_name))\n",
    "\n",
    "# write model predictions to raster\n",
    "ela.apply_model_to_rasters(model_train, raster_paths, os.path.join(exp_path, raster_name), quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4693e-7362-425b-bcdd-8ffa309932a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training performance\n",
    "\n",
    "# ROC-curve\n",
    "# fpr_train, tpr_train, thresholds = metrics.roc_curve(y_train, y_train_predict)\n",
    "auc_train = metrics.roc_auc_score(y_train, y_train_predict)\n",
    "\n",
    "# PR-curve\n",
    "precision_train, recall_train, _= metrics.precision_recall_curve(y_train, y_train_predict) \n",
    "pr_auc_train = metrics.auc(recall_train, precision_train)\n",
    "\n",
    "print(f\"Training ROC-AUC score: {auc_train:0.3f}\")\n",
    "print(f\"PR-AUC Score: {pr_auc_train:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa69830-5a2b-4fc0-8335-2b5eeab47958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(ncols=3, figsize=(18,6),constrained_layout=True)\n",
    "\n",
    "#ax[0].hist(y_train_predict[y_train==0], bins=np.linspace(0,1,int((y_train==0).sum()/100 + 1)), density=True, color='tab:red', alpha=0.7, label='pseudo-absence')\n",
    "#ax[0].hist(y_train_predict[y_train==1], bins=np.linspace(0,1,int((y_train==1).sum()/10+1)), density=True, color='tab:green', alpha=0.7, label='presence')\n",
    "\n",
    "#ax[0].set_xlabel('Relative Occurrence Probability')\n",
    "#ax[0].set_ylabel('Counts')\n",
    "#ax[0].set_title('Probability Distribution')\n",
    "\n",
    "#ax[0].legend(loc='upper right')\n",
    "\n",
    "#ax[1].plot([0, 1], [0, 1], '--', label=f'AUC score: 0.5 (No Skill)', color='gray')\n",
    "#ax[1].text(0.4, 0.4, 'random classifier', fontsize=12, color='gray',\n",
    "#           rotation=45, rotation_mode='anchor', horizontalalignment='left',\n",
    "#           verticalalignment='bottom',transform=ax[1].transAxes)\n",
    "\n",
    "#ax[1].plot([0, 0, 1], [0, 1, 1], '--', label=f'AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "#ax[1].text(0, 1, '  perfect classifier', fontsize=12, color='tab:blue', \n",
    "#           horizontalalignment='left', verticalalignment='bottom')\n",
    "#ax[1].scatter(0, 1, marker='*', s=100, color='tab:blue')\n",
    "\n",
    "#ax[1].plot(fpr_train, tpr_train, label=f'AUC score: {auc_train:0.3f}', color='tab:orange')\n",
    "#ax[1].axis('equal')\n",
    "#ax[1].set_xlabel('False Positive Rate')\n",
    "#ax[1].set_ylabel('True Positive Rate')\n",
    "#ax[1].set_title('MaxEnt ROC Curve')\n",
    "#ax[1].legend(loc='lower right')\n",
    "\n",
    "#ax[2].plot([0, 1], [0.5, 0.5], '--', color='gray', label=f'AUC score: 0.5 (No Skill)')\n",
    "#ax[2].text(0.5, 0.52, 'random classifier', fontsize=12, color='gray',\n",
    "#           horizontalalignment='center', verticalalignment='center')\n",
    "#ax[2].plot([0, 1, 1], [1, 1, 0], '--', label=f'AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "#ax[2].text(1, 1, 'perfect classifier  ', fontsize=12, color='tab:blue', \n",
    "#           horizontalalignment='right', verticalalignment='bottom')\n",
    "#ax[2].scatter(1, 1, marker='*', s=100, color='tab:blue')\n",
    "\n",
    "#ax[2].plot(recall_train, precision_train, label=f'AUC score: {pr_auc_train:0.3f}', color='tab:orange')\n",
    "#ax[2].axis('equal')\n",
    "#ax[2].set_xlabel('Recall')\n",
    "#ax[2].set_ylabel('Precision')\n",
    "#ax[2].set_title('MaxEnt PR Curve')\n",
    "#ax[2].legend(loc='lower left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993984c-f068-4953-8a73-841a09f30b72",
   "metadata": {},
   "source": [
    "## 2. Predict model for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674151b7-99a5-43e3-9220-ff76066070cf",
   "metadata": {},
   "source": [
    "### 2.1 load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c5392-3677-4518-8cba-4375bb9e36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2.1 load test data\")\n",
    "\n",
    "rasters, labels = (\n",
    "    (['srtm_%s.tif' % training], ['srtm']) if topo else ([], [])\n",
    ")\n",
    "rasters, labels = (\n",
    "    rasters + (['ndvi_%s.tif' % training] if ndvi else []),\n",
    "    labels  + (['ndvi'] if ndvi else [])\n",
    ")\n",
    "\n",
    "# rasters, labels = (['srtm_%s.tif' %interest], ['srtm']) if topo else ([], []) # 'ndvi_east-asia.tif', 'ndvi' # \n",
    "# if Future:\n",
    "#     for no in bioclim:\n",
    "#         rasters.append('bio_%s_%s_future.tif' %(no, interest))\n",
    "#         labels.append('bioclim_%02d' %no)\n",
    "# else:\n",
    "#     for no in bioclim:\n",
    "#         rasters.append('bio_%s_%s.tif' %(no, interest))\n",
    "#         labels.append('bioclim_%02d' %no)\n",
    "\n",
    "for no in bioclim:\n",
    "    rasters.append('%s_bio_%s_%s.tif' %(model_prefix, no, training))\n",
    "    labels.append('%s_bioclim_%02d' %(model_prefix, no))\n",
    "\n",
    "    \n",
    "raster_paths = [os.path.join(input_path, raster) for raster in rasters]\n",
    "\n",
    "# initialise dataset for model output\n",
    "test_output = xr.Dataset()\n",
    "for raster, label in zip(raster_paths, labels):\n",
    "    da = rioxr.open_rasterio(raster, masked=True)\n",
    "    test_output[label] = da\n",
    "\n",
    "# print(label)\n",
    "# print(da)\n",
    "\n",
    "# # Plot semua raster dari dataset\n",
    "# num_plots = len(labels)\n",
    "# fig, axes = plt.subplots(4, 5, figsize=(20, 16))  # 4 baris, 5 kolom\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, label in zip(axes, labels):\n",
    "#     training_data[label].plot(ax=ax, cmap='viridis')\n",
    "#     ax.set_title(label)\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Sembunyikan subplot kosong jika ada\n",
    "# for ax in axes[len(labels):]:\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(training_output)\n",
    "# training_output.to_netcdf('../data/test_output.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89635dc6-33a8-4211-9b49-355940d49921",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_file_name = '%s_presence_%s_%s.csv' %(specie, interest, iteration)\n",
    "background_file_name = '%s_background_%s_%s.csv' %(specie, pseudoabsence, interest)\n",
    "test_input_data_name = '%s_model-test_input-data_%s_%s_%s_%s_%s.csv' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)\n",
    "\n",
    "#####----------------------------\n",
    "# if Future:\n",
    "#     presence_csv = pd.read_csv(os.path.join(input_path, 'test', presence_file_name))\n",
    "#     geometry = gpd.points_from_xy(presence_csv['lon'], presence_csv['lat'])\n",
    "#     presence_gdf = gpd.GeoDataFrame(geometry=geometry, crs='EPSG:4326')\n",
    "#     print(presence_gdf.geometry)\n",
    "#     print(presence_gdf)\n",
    "#     presence_gdf = presence_gdf.drop(presence_gdf.index)\n",
    "    \n",
    "# else:\n",
    "presence_csv = pd.read_csv(os.path.join(input_path, 'test', presence_file_name))\n",
    "geometry = gpd.points_from_xy(presence_csv['lon'], presence_csv['lat'])\n",
    "presence_gdf = gpd.GeoDataFrame(geometry=geometry, crs='EPSG:4326')\n",
    "        \n",
    "background_csv = pd.read_csv(os.path.join(input_path, 'test', background_file_name))\n",
    "geometry = gpd.points_from_xy(background_csv['lon'], background_csv['lat'])\n",
    "background_gdf = gpd.GeoDataFrame(geometry=geometry, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d79056-5e1e-4ac8-b2ad-94748ef3be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(presence_gdf) == 0:\n",
    "    print('There are no occurrences of this specie in this region!')\n",
    "    # chose arbitrary coordinate to make the code run\n",
    "    presence_gdf.geometry=gpd.points_from_xy([115], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefb62e-ee35-45b2-bcd6-086b9b8afbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_test = ela.annotate(\n",
    "    presence_gdf.geometry,\n",
    "    raster_paths=raster_paths, \n",
    "    labels=labels, \n",
    "    drop_na=True,\n",
    ")\n",
    "\n",
    "background_test = ela.annotate(\n",
    "    background_gdf, #pseudoabsence_random, pseudoabsence_bias_eucalyptus, #pseudoabsence_bias_perc_planted\n",
    "    raster_paths=raster_paths, \n",
    "    labels=labels, \n",
    "    drop_na=True,\n",
    ")\n",
    "\n",
    "test = ela.stack_geodataframes(\n",
    "    presence_test,\n",
    "    background_test,\n",
    "    add_class_label=True,\n",
    ")\n",
    "\n",
    "test.to_csv(os.path.join(exp_path, test_input_data_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f67ff-84d7-4e34-8b2d-b7740f6f49b8",
   "metadata": {},
   "source": [
    "### 2.2 model predict for region of interest/ test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b889a-5e5b-4a94-9b91-d26f10453687",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_name = '%s_model-test_%s_%s_%s_%s_%s.nc' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)\n",
    "raster_name = '%s_model-test_%s_%s_%s_%s_%s.tif' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd517e-431b-42ce-8bdd-d84205318c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2.2 model predict for region of interest/ test data\")\n",
    "# split the x/y data\n",
    "x_test = test.drop(columns=['class', 'geometry'])\n",
    "y_test = test['class']\n",
    "\n",
    "# predict the model for the test data\n",
    "y_test_predict = model_train.predict(x_test)\n",
    "\n",
    "print(y_test_predict)\n",
    "# save the environment variables and model predictions to xarray.Dataset\n",
    "\n",
    "array = test_output.isel(band=0).to_array().values\n",
    "nodata = np.nan\n",
    "nodata_idx = np.isnan(array)\n",
    "rop = ela.geo.apply_model_to_array(model_train, array, nodata, nodata_idx)\n",
    "\n",
    "test_output['rop'] = (('band', 'y', 'x'), rop)\n",
    "test_output['rop'].attrs['long_name'] = \"relative occurrence probability\"\n",
    "\n",
    "# write model output to netcdf\n",
    "test_output.to_netcdf(os.path.join(exp_path, nc_name))\n",
    "\n",
    "# write model predictions to raster\n",
    "ela.apply_model_to_rasters(model_train, raster_paths, os.path.join(exp_path, raster_name), quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9a5b5-2e20-495c-b74c-a43cd01dcf61",
   "metadata": {},
   "source": [
    "### 2.3 test data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b6561-543d-46cf-8167-878dd0f0bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2.3 test data performance\")\n",
    "# ROC-curve\n",
    "# fpr_test, tpr_test, _ = metrics.roc_curve(y_test, y_test_predict)\n",
    "auc_test = metrics.roc_auc_score(y_test, y_test_predict)\n",
    "\n",
    "# PR-curve\n",
    "precision_test, recall_test, _= metrics.precision_recall_curve(y_test, y_test_predict) \n",
    "pr_auc_test = metrics.auc(recall_test, precision_test)\n",
    "\n",
    "print(f\"Training ROC-AUC score: {auc_train:0.3f}\")\n",
    "print(f\"Training PR-AUC Score: {pr_auc_train:0.3f}\")\n",
    "\n",
    "print(f\"Test ROC-AUC score: {auc_test:0.3f}\")\n",
    "print(f\"Test PR-AUC Score: {pr_auc_test:0.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26816dd3-27ba-44fe-9c6a-ea8412e49345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(ncols=3, figsize=(18,6),constrained_layout=True)\n",
    "\n",
    "# # \n",
    "# ax[0].hist(y_test_predict[y_test==0], bins=np.linspace(0,1,int((y_test==0).sum()/100 + 1)), density=True, color='tab:red', alpha=0.7, label='pseudo-absence')\n",
    "# ax[0].hist(y_test_predict[y_test==1], bins=np.linspace(0,1,int((y_test==1).sum()/10+1)), density=True, color='tab:green', alpha=0.7, label='presence')\n",
    "\n",
    "# ax[0].set_xlabel('Relative Occurrence Probability')\n",
    "# ax[0].set_ylabel('Counts')\n",
    "# ax[0].set_title('Probability Distribution')\n",
    "\n",
    "# ax[0].legend(loc='upper right')\n",
    "\n",
    "# ax[1].plot([0, 1], [0, 1], '--', label=f'AUC score: 0.5 (No Skill)', color='gray')\n",
    "# ax[1].text(0.4, 0.4, 'random classifier', fontsize=12, color='gray',\n",
    "#            rotation=45, rotation_mode='anchor', horizontalalignment='left',\n",
    "#            verticalalignment='bottom',transform=ax[1].transAxes)\n",
    "\n",
    "# ax[1].plot([0, 0, 1], [0, 1, 1], '--', label=f'AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "# ax[1].text(0, 1, '  perfect classifier', fontsize=12, color='tab:blue', \n",
    "#            horizontalalignment='left', verticalalignment='bottom')\n",
    "# ax[1].scatter(0, 1, marker='*', s=100, color='tab:blue')\n",
    "\n",
    "# ax[1].plot(fpr_train, tpr_train, label=f'AUC train score: {auc_train:0.3f}', color='tab:orange')\n",
    "# ax[1].plot(fpr_test, tpr_test, label=f'AUC test score: {auc_test:0.3f}', color='tab:green')\n",
    "\n",
    "# ax[1].axis('equal')\n",
    "# ax[1].set_xlabel('False Positive Rate')\n",
    "# ax[1].set_ylabel('True Positive Rate')\n",
    "# ax[1].set_title('MaxEnt ROC Curve')\n",
    "# ax[1].legend(loc='lower right')\n",
    "\n",
    "# ## \n",
    "# ax[2].plot([0, 1], [0.5, 0.5], '--', color='gray', label=f'AUC score: 0.5 (No Skill)')\n",
    "# ax[2].text(0.5, 0.52, 'random classifier', fontsize=12, color='gray',\n",
    "#            horizontalalignment='center', verticalalignment='center')\n",
    "# ax[2].plot([0, 1, 1], [1, 1, 0], '--', label=f'AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "# ax[2].text(1, 1, 'perfect classifier  ', fontsize=12, color='tab:blue', \n",
    "#            horizontalalignment='right', verticalalignment='bottom')\n",
    "# ax[2].scatter(1, 1, marker='*', s=100, color='tab:blue')\n",
    "\n",
    "\n",
    "# ax[2].plot(recall_train, precision_train, label=f'AUC train score: {pr_auc_train:0.3f}', color='tab:orange')\n",
    "# ax[2].plot(recall_test, precision_test, label=f'AUC test score: {pr_auc_test:0.3f}', color='tab:green')\n",
    "\n",
    "# ax[2].axis('equal')\n",
    "# ax[2].set_xlabel('Recall')\n",
    "# ax[2].set_ylabel('Precision')\n",
    "# ax[2].set_title('MaxEnt PR Curve')\n",
    "# ax[2].legend(loc='lower left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1e0dc-05c9-4a65-809f-42b1055ff5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=False\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 8), constrained_layout=True) #dpi=100\n",
    "\n",
    "cmap = plt.cm.GnBu #'GnBu'\n",
    "bounds = np.linspace(0, 1, 11)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# pcol = train_out.plot(ax=ax[0], vmin=0, vmax=1, cmap='GnBu', add_colorbar=False)\n",
    "gdf_countries.plot(ax=ax[0], facecolor='lightgray', edgecolor='k')\n",
    "pcol = training_output.rop.plot(ax=ax[0], vmin=0, vmax=1, norm=norm, cmap=cmap, add_colorbar=False)\n",
    "presence_train.plot(ax=ax[0], color='tab:red', marker='*', label='presence-train')\n",
    "ax[0].text(0.98, 0.91, 'presence points: %s\\n pseudo-absence points: %s\\n AUC: %.3f' %(len(presence_train), len(background_train), auc_train), fontsize=12, \n",
    "           horizontalalignment='right', verticalalignment='top', transform=ax[0].transAxes)\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[0].set_title('')\n",
    "#ax[0].set_ylim([15, 60])\n",
    "\n",
    "gdf_countries.plot(ax=ax[1], facecolor='lightgray', edgecolor='k')\n",
    "pcol = test_output.rop.plot(ax=ax[1], vmin=0, vmax=1, norm=norm, cmap=cmap, add_colorbar=False)\n",
    "presence_test.plot(ax=ax[1], color='tab:red', marker='*', label='presence-test')\n",
    "ax[1].text(0.98, 0.92, 'presence points: %s\\n pseudo-absence points: %s\\n AUC: %.3f' %(len(presence_test), len(background_test), auc_test), fontsize=12, \n",
    "           horizontalalignment='right', verticalalignment='top', transform=ax[1].transAxes)\n",
    "ax[1].legend()\n",
    "ax[1].set_title('')\n",
    "\n",
    "cbar = fig.colorbar(pcol, ax=ax, aspect=50, pad=0.05, label=\"relative occurrence probability\", orientation='horizontal', fraction=0.03)\n",
    "\n",
    "if doc:\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "if savefig:\n",
    "    fig.savefig(os.path.join(docs_path, '05_rel-occ-prob-_%s_%s_%s.png' %(training, interest, iteration)), transparent=True, bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e7fd3-bb04-4dcc-87e1-77826ef8fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if savefig:\n",
    "    # If a model is specified, add it to the filename\n",
    "    file_path = os.path.join(figs_path, '05_rel-occ-prob-%s_%s_%s_%s_%s.png' %(specie, training, bio, model_prefix, iteration))\n",
    "    fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef88b46-5d31-498a-b827-8ae979468c36",
   "metadata": {},
   "source": [
    "### 2.4 load Future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d184fd-5f95-47c4-92ff-b3bdc6ee0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2.4 Future Data\")\n",
    "\n",
    "rasters, labels = (\n",
    "    (['srtm_%s.tif' % training], ['srtm']) if topo else ([], [])\n",
    ")\n",
    "rasters, labels = (\n",
    "    rasters + (['ndvi_%s.tif' % training] if ndvi else []),\n",
    "    labels  + (['ndvi'] if ndvi else [])\n",
    ")\n",
    "# rasters, labels = (['srtm_%s.tif' %interest], ['srtm']) if topo else ([], []) # 'ndvi_east-asia.tif', 'ndvi' # \n",
    "\n",
    "for no in bioclim:\n",
    "    rasters.append('%s_bio_%s_%s_future.tif' %(model_prefix, no, training))\n",
    "    labels.append('%s_bioclim_%02d' %(model_prefix, no))\n",
    "    \n",
    "raster_paths = [os.path.join(input_path, raster) for raster in rasters]\n",
    "\n",
    "# initialise dataset for model output\n",
    "# future_output = xr.Dataset()\n",
    "# for raster, label in zip(raster_paths, labels):\n",
    "#     da = rioxr.open_rasterio(raster, masked=True).squeeze(drop=True)  \n",
    "#     future_output[label] = da\n",
    "\n",
    "\n",
    "arrays = []\n",
    "for raster in raster_paths:\n",
    "    da = rioxr.open_rasterio(raster, masked=True)\n",
    "    arr = da.squeeze().values  # pastikan 2D\n",
    "    arrays.append(arr)\n",
    "\n",
    "\n",
    "nc_name = '%s_model-future_%s_%s_%s_%s_%s.nc' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)\n",
    "raster_name = '%s_model-future_%s_%s_%s_%s_%s.tif' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71201d62-c6d7-454b-bd66-8374d5f29b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.stack(arrays, axis=-1)  # shape: (rows, cols, features)\n",
    "nrow, ncol, nfeat = stacked.shape\n",
    "\n",
    "X_future = stacked.reshape(-1, nfeat)\n",
    "\n",
    "y_pred = model_train.predict(X_future)  # probabilitas presence\n",
    "\n",
    "# --- 5. Reshape kembali ke raster 2D ---\n",
    "y_map = y_pred.reshape(nrow, ncol)\n",
    "\n",
    "# --- 6. Simpan ke xarray.Dataset ---\n",
    "future_output = xr.Dataset()\n",
    "for raster, label in zip(raster_paths, labels):\n",
    "    da = rioxr.open_rasterio(raster, masked=True)\n",
    "    future_output[label] = da\n",
    "\n",
    "future_output['rop'] = (('band', 'y', 'x'), y_map[np.newaxis, :, :])\n",
    "future_output['rop'].attrs['long_name'] = \"relative occurrence probability\"\n",
    "\n",
    "# --- 7. Simpan ke NetCDF ---\n",
    "future_output.to_netcdf(os.path.join(exp_path, nc_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237f913-c147-4208-85ad-6aedfedfd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=False\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(24, 8), constrained_layout=True) #dpi=100\n",
    "\n",
    "cmap = plt.cm.GnBu #'GnBu'\n",
    "bounds = np.linspace(0, 1, 11)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# pcol = train_out.plot(ax=ax[0], vmin=0, vmax=1, cmap='GnBu', add_colorbar=False)\n",
    "gdf_countries.plot(ax=ax[0], facecolor='lightgray', edgecolor='k')\n",
    "pcol = training_output.rop.plot(ax=ax[0], vmin=0, vmax=1, norm=norm, cmap=cmap, add_colorbar=False)\n",
    "presence_train.plot(ax=ax[0], color='tab:red', marker='*', label='presence-train')\n",
    "ax[0].text(0.98, 0.91, 'presence points: %s\\n pseudo-absence points: %s\\n AUC: %.3f' %(len(presence_train), len(background_train), auc_train), fontsize=12, \n",
    "           horizontalalignment='right', verticalalignment='top', transform=ax[0].transAxes)\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[0].set_title('')\n",
    "#ax[0].set_ylim([15, 60])\n",
    "\n",
    "gdf_countries.plot(ax=ax[1], facecolor='lightgray', edgecolor='k')\n",
    "pcol = test_output.rop.plot(ax=ax[1], vmin=0, vmax=1, norm=norm, cmap=cmap, add_colorbar=False)\n",
    "presence_test.plot(ax=ax[1], color='tab:red', marker='*', label='presence-test')\n",
    "ax[1].text(0.98, 0.92, 'presence points: %s\\n pseudo-absence points: %s\\n AUC: %.3f' %(len(presence_test), len(background_test), auc_test), fontsize=12, \n",
    "           horizontalalignment='right', verticalalignment='top', transform=ax[1].transAxes)\n",
    "ax[1].legend()\n",
    "ax[1].set_title('')\n",
    "\n",
    "gdf_countries.plot(ax=ax[2], facecolor='lightgray', edgecolor='k')\n",
    "pcol = future_output.rop.plot(ax=ax[2], vmin=0, vmax=1, norm=norm, cmap=cmap, add_colorbar=False)\n",
    "ax[2].set_title('Future prediction')\n",
    "\n",
    "cbar = fig.colorbar(pcol, ax=ax, aspect=50, pad=0.05, label=\"relative occurrence probability\", orientation='horizontal', fraction=0.03)\n",
    "\n",
    "if doc:\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "if savefig:\n",
    "    fig.savefig(os.path.join(docs_path, '05_rel-occ-prob-_%s_%s.png' %(training, iteration)), transparent=True, bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761df818-12ae-4b6f-94f7-e9fcff96b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "if savefig:\n",
    "    # If a model is specified, add it to the filename\n",
    "    file_path = os.path.join(figs_path, '05_rel-occ-prob-%s_%s_%s_%s_%s_future.png' %(specie, training, bio, model_prefix, iteration))\n",
    "    fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edf884-fbce-4d1c-82cf-f446e03030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# --- ASUMSI: Variabel berikut sudah ada dari kode sebelumnya ---\n",
    "# training_output.rop: xarray DataArray untuk hasil training\n",
    "# test_output.rop: xarray DataArray untuk hasil test\n",
    "# gdf_countries: GeoDataFrame untuk peta latar belakang\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "## 1. Menghitung Perbedaan\n",
    "# Kita tidak bisa langsung mengurangi dua xarray jika grid/koordinatnya berbeda.\n",
    "# Gunakan .reindex_like() untuk menyamakan grid 'test_output' dengan 'training_output'.\n",
    "# Area di luar cakupan 'test_output' akan menjadi NaN (Not a Number).\n",
    "# future_aligned = future_output.rop.reindex_like(training_output.rop)\n",
    "\n",
    "# Sekarang kita bisa kurangi keduanya dengan aman\n",
    "# Rumus: Prediksi Test - Prediksi Training\n",
    "\n",
    "\n",
    "difference =future_output.rop - training_output.rop\n",
    "\n",
    "\n",
    "## 2. Menyiapkan Visualisasi\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "# Pilih colormap yang \"diverging\" (bercabang dari titik tengah).\n",
    "# 'coolwarm' (Biru-Putih-Merah) atau 'RdBu_r' sangat cocok untuk ini.\n",
    "# Biru = nilai negatif, Merah = nilai positif, Putih = nol.\n",
    "cmap_diff = plt.cm.coolwarm\n",
    "\n",
    "# Buat normalisasi warna yang berpusat di nol.\n",
    "# Ini memastikan bahwa nilai 0 akan berwarna putih (netral).\n",
    "norm_diff = mcolors.CenteredNorm()\n",
    "\n",
    " \n",
    "## 3. Memplot Perbedaan\n",
    "# Plot semua negara sebagai latar belakang\n",
    "gdf_countries.plot(ax=ax, facecolor='lightgray', edgecolor='k')\n",
    "\n",
    "# Plot raster perbedaan di atasnya\n",
    "# xarray akan secara otomatis mengabaikan nilai NaN\n",
    "diff_plot = difference.plot(ax=ax, cmap=cmap_diff, norm=norm_diff, add_colorbar=False)\n",
    "\n",
    "# Tambahkan colorbar\n",
    "cbar = fig.colorbar(diff_plot, ax=ax, orientation='vertical', label=\"Relative Occurrence Probability (Future - Historical)\")\n",
    "\n",
    "# Atur judul\n",
    "ax.set_title('Potentially suitable', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51838f39-9f3b-493c-8534-ed625f4df697",
   "metadata": {},
   "outputs": [],
   "source": [
    "if savefig:\n",
    "    # If a model is specified, add it to the filename\n",
    "    file_path = os.path.join(figs_path, '05_rel-occ-dif-%s_%s_%s_%s_%s.png' %(specie, training, bio, model_prefix, iteration))\n",
    "    fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf9622-87c1-4363-922d-04939e2028f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.close()\n",
    "future_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aciar",
   "language": "python",
   "name": "aciar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
