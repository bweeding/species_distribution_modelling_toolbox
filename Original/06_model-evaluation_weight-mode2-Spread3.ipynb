{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a39a75e",
   "metadata": {},
   "source": [
    "# Model Evaluation (Weighted) â€“ Notebook Guide\n",
    "\n",
    "This notebook evaluates models with class/observation weights applied.\n",
    "\n",
    "## What this notebook does\n",
    "- Compute weighted metrics (e.g., weighted AUC, threshold metrics)\n",
    "- Plot diagnostic figures considering weights\n",
    "- Summarize results per model/run and export\n",
    "\n",
    "## Inputs\n",
    "- Predictions/scores, ground-truth labels, and weights per observation\n",
    "- Optional: CV fold info or test set indicators\n",
    "\n",
    "## Workflow\n",
    "1. Load predictions, labels, and weights\n",
    "2. Validate alignment and handle missing values\n",
    "3. Compute weighted metrics across thresholds/folds\n",
    "4. Plot weighted ROC/curves and summaries\n",
    "5. Save metrics tables and figures\n",
    "\n",
    "## Outputs\n",
    "- Weighted per-model/per-fold metrics tables\n",
    "- Plots reflecting weights\n",
    "- CSV/JSON exports for downstream use\n",
    "\n",
    "## Notes\n",
    "- Ensure weights are normalized or in intended scale\n",
    "- Use consistent preprocessing as training\n",
    "- Fix random seeds for reproducibility where applicable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce62eb",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook evaluates weighted SDMs with metrics and plots, mirroring standard evaluation but accounting for weights in analysis where relevant.\n",
    "\n",
    "- Key steps: load weighted predictions, compute metrics, plot curves, thresholds, reporting\n",
    "- Inputs: weighted model predictions and labels\n",
    "- Outputs: evaluation tables and plots\n",
    "- Run order: After weighted model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b15204-7112-48a4-97c4-bc90bc40550d",
   "metadata": {},
   "source": [
    "# Weighted MaxEnt Model Evaluation and Performance Assessment\n",
    "\n",
    "This notebook provides comprehensive evaluation of **weighted MaxEnt species distribution models**, focusing on performance assessment that accounts for sample weights and data quality differences. Unlike standard model evaluation, this version incorporates **weighted metrics** to properly assess model performance when training data has been weighted.\n",
    "\n",
    "## Key Features of Weighted Model Evaluation:\n",
    "\n",
    "### 1. **Weighted Performance Metrics**:\n",
    "- **Weighted AUC**: Area Under ROC Curve accounting for sample weights\n",
    "- **Weighted PR-AUC**: Precision-Recall AUC with weight integration\n",
    "- **Weighted Sensitivity/Specificity**: Performance metrics adjusted for data quality\n",
    "- **Weighted Precision/Recall**: Classification metrics incorporating sample weights\n",
    "\n",
    "### 2. **Advanced Evaluation Approaches**:\n",
    "- **Cross-Validation**: K-fold validation with weighted samples\n",
    "- **Spatial Validation**: Geographic partitioning with weight consideration\n",
    "- **Temporal Validation**: Time-based splits accounting for temporal weights\n",
    "- **Bootstrap Validation**: Resampling with weight preservation\n",
    "\n",
    "### 3. **Bias Assessment**:\n",
    "- **Spatial Bias Analysis**: Evaluate model performance across different regions\n",
    "- **Temporal Bias Assessment**: Performance across different time periods\n",
    "- **Source Bias Evaluation**: Performance across different data sources\n",
    "- **Quality Bias Analysis**: Performance across different data quality levels\n",
    "\n",
    "## Applications:\n",
    "- **Model Validation**: Comprehensive assessment of weighted model performance\n",
    "- **Bias Detection**: Identify remaining biases after weighting\n",
    "- **Performance Comparison**: Compare weighted vs. unweighted models\n",
    "- **Quality Control**: Validate that weighting improves model reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f4dda-d3ca-47d5-91ad-7caa0a434170",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### WEIGHTED MODEL EVALUATION CONFIGURATION - MODIFY AS NEEDED ###############\n",
    "\n",
    "# Species and region settings for weighted model evaluation\n",
    "#specie = 'leptocybe-invasa'  # Target species: 'leptocybe-invasa' or 'thaumastocoris-peregrinus'\n",
    "#pseudoabsence = 'random'  # Background point strategy: 'random', 'biased', 'biased-land-cover'\n",
    "#training = 'east-asia'  # Training region: 'sea', 'australia', 'east-asia', etc.\n",
    "#interest = 'south-east-asia'  # Test region: can be same as training or different\n",
    "#savefig = True  # Save generated evaluation plots and metrics\n",
    "\n",
    "# Environmental variable configuration\n",
    "bio = bio1  # Bioclimatic variable identifier\n",
    "\n",
    "# Evaluation settings (specific to weighted model evaluation)\n",
    "# evaluation_method = 'cross_validation'  # 'cross_validation', 'spatial_validation', 'temporal_validation'\n",
    "# n_folds = 5  # Number of folds for cross-validation\n",
    "# spatial_buffer = 100  # Buffer distance (km) for spatial validation\n",
    "# temporal_split = 0.7  # Proportion of data for training in temporal validation\n",
    "\n",
    "# Weighted metrics configuration\n",
    "# include_weighted_metrics = True  # Calculate weighted performance metrics\n",
    "# include_unweighted_metrics = True  # Calculate standard metrics for comparison\n",
    "# weight_threshold = 0.1  # Minimum weight threshold for sample inclusion\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e46ce-499c-4676-9ff0-f796122a3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT REQUIRED LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import os  # File system operations\n",
    "\n",
    "import numpy as np  # Numerical computing\n",
    "import xarray as xr  # Multi-dimensional labeled arrays (raster data)\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import geopandas as gpd  # Geospatial data handling\n",
    "\n",
    "import elapid as ela  # Species distribution modeling library\n",
    "\n",
    "from shapely import wkt  # Well-Known Text (WKT) geometry parsing\n",
    "from elapid import utils  # Utility functions for elapid\n",
    "from sklearn import metrics, inspection  # Machine learning metrics and model inspection\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warning messages for cleaner output\n",
    "\n",
    "# Configure matplotlib for publication-quality plots\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6724e-cd4f-4099-aba5-4b81214f135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_layout(nplots):\n",
    "    \"\"\"\n",
    "    Calculate optimal subplot layout for given number of plots\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nplots : int\n",
    "        Number of plots to arrange\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ncols, nrows : tuple\n",
    "        Number of columns and rows for subplot layout\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate square root and round up for balanced layout\n",
    "    ncols = min(int(np.ceil(np.sqrt(nplots))), 4)  # Max 4 columns\n",
    "    nrows = int(np.ceil(nplots / ncols))  # Calculate rows needed\n",
    "    \n",
    "    return ncols, nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6db49b-be58-4919-b395-1e6978805f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SET UP FILE PATHS\n",
    "# =============================================================================\n",
    "# Define directory structure for organizing weighted model evaluation outputs\n",
    "\n",
    "docs_path = os.path.join(os.path.dirname(os.getcwd()), 'docs')  # Documentation directory\n",
    "out_path = os.path.join(os.path.dirname(os.getcwd()), 'out', specie)  # Species-specific output directory\n",
    "figs_path = os.path.join(os.path.dirname(os.getcwd()), 'figs')  # Figures directory\n",
    "output_path = os.path.join(out_path, 'output')  # Model output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7a900-85cd-41d4-87e6-7179c9320233",
   "metadata": {},
   "source": [
    "## 1. Weighted Training Model Performance Assessment\n",
    "\n",
    "This section evaluates the performance of the weighted MaxEnt model on the training data. Key aspects include:\n",
    "\n",
    "### **Weighted vs. Unweighted Metrics**:\n",
    "- **Standard Metrics**: Traditional AUC, PR-AUC, sensitivity, specificity\n",
    "- **Weighted Metrics**: Performance metrics accounting for sample weights\n",
    "- **Comparison Analysis**: Evaluate improvement from weighting approach\n",
    "\n",
    "### **Performance Indicators**:\n",
    "- **ROC-AUC**: Area Under Receiver Operating Characteristic curve\n",
    "- **PR-AUC**: Area Under Precision-Recall curve (important for imbalanced data)\n",
    "- **Sensitivity**: True Positive Rate (ability to detect presences)\n",
    "- **Specificity**: True Negative Rate (ability to detect absences)\n",
    "- **Precision**: Positive Predictive Value\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "\n",
    "### **Weighted Evaluation Benefits**:\n",
    "- **Quality-Aware Assessment**: Metrics reflect data quality differences\n",
    "- **Bias-Corrected Performance**: Reduced influence of low-quality samples\n",
    "- **Robust Validation**: More reliable performance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d23f6-4868-4e17-8dca-2d60b2411509",
   "metadata": {},
   "source": [
    "## References for Species Distribution Model Evaluation\n",
    "\n",
    "### **Model Output Interpretation**:\n",
    "- [SDM Model Outputs Interpretation](https://support.ecocommons.org.au/support/solutions/articles/6000256107-interpretation-of-sdm-model-outputs)\n",
    "- [Presence-Only Prediction in GIS](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/how-presence-only-prediction-works.htm)\n",
    "- [MaxEnt 101: Species Distribution Modeling](https://www.esri.com/arcgis-blog/products/arcgis-pro/analytics/presence-only-prediction-maxent-101-using-gis-to-model-species-distribution/)\n",
    "\n",
    "### **Performance Metrics**:\n",
    "- [ROC Curves Demystified](https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0)\n",
    "- [Precision-Recall AUC Guide](https://www.aporia.com/learn/ultimate-guide-to-precision-recall-auc-understanding-calculating-using-pr-auc-in-ml/)\n",
    "- [F1-Score, Accuracy, ROC-AUC, and PR-AUC Metrics](https://deepchecks.com/f1-score-accuracy-roc-auc-and-pr-auc-metrics-for-models/)\n",
    "\n",
    "### **Weighted Model Evaluation**:\n",
    "- **Sample Weighting**: How to properly evaluate models trained with sample weights\n",
    "- **Bias Correction**: Assessing the effectiveness of weighting strategies\n",
    "- **Quality Integration**: Incorporating data quality into performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa4635-ab08-4b3d-9fa0-07271788cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD WEIGHTED MODEL AND TRAINING DATA\n",
    "# =============================================================================\n",
    "# Load the trained weighted MaxEnt model and associated training data for evaluation\n",
    "\n",
    "# Build experiment directory name (keeps runs organized by config)\n",
    "# Alternate naming (older): 'exp_%s_%s_%s' % (pseudoabsence, training, interest)\n",
    "experiment_name = 'exp_%s_%s_%s_%s_%s' % (model_prefix, pseudoabsence, training, topo, ndvi)\n",
    "exp_path = os.path.join(output_path, experiment_name)  # Path to experiment directory\n",
    "\n",
    "# Construct expected filenames produced during training for this run\n",
    "train_input_data_name = '%s_model-train_input-data_%s_%s_%s_%s_%s.csv' % (model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "run_name = '%s_model-train_%s_%s_%s_%s_%s.ela' % (model_prefix, specie, pseudoabsence, training, bio, iteration)\n",
    "nc_name = '%s_model-train_%s_%s_%s_%s_%s.nc' % (model_prefix, specie, pseudoabsence, training, bio, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428443d1-2a5b-403e-a99c-a3395954e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD TRAINING DATA WITH SAMPLE WEIGHTS\n",
    "# =============================================================================\n",
    "# Load training data including sample weights for weighted model evaluation\n",
    "\n",
    "# Load training data from CSV file (index_col=0 to drop old index column)\n",
    "df = pd.read_csv(os.path.join(exp_path, train_input_data_name), index_col=0)\n",
    "# Parse WKT strings into shapely geometries\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "# Wrap as GeoDataFrame with WGS84 CRS\n",
    "train = gpd.GeoDataFrame(df, crs='EPSG:4326')\n",
    "\n",
    "# Split predictors/labels/weights for weighted evaluation\n",
    "x_train = train.drop(columns=['class', 'SampleWeight', 'geometry'])  # Environmental variables only\n",
    "y_train = train['class']  # Presence/absence labels (0/1)\n",
    "sample_weight_train = train['SampleWeight']  # Sample weights aligned with rows\n",
    "\n",
    "# Load fitted weighted MaxEnt model\n",
    "model_train = utils.load_object(os.path.join(exp_path, run_name))\n",
    "\n",
    "# Predict probabilities on training set (for curves/metrics)\n",
    "y_train_predict = model_train.predict(x_train)\n",
    "# Optional: impute NaN probabilities to 0.5 (neutral)\n",
    "# y_train_predict = np.nan_to_num(y_train_predict, nan=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abc1a9-3db2-4960-ad8f-e042eb214fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training performance metrics\n",
    "\n",
    "# ROC curve and AUC (unweighted vs weighted)\n",
    "# fpr/tpr are computed from predicted probabilities; weights adjust contribution per sample\n",
    "fpr_train, tpr_train, thresholds = metrics.roc_curve(y_train, y_train_predict)\n",
    "auc_train = metrics.roc_auc_score(y_train, y_train_predict)\n",
    "auc_train_weighted = metrics.roc_auc_score(y_train, y_train_predict, sample_weight=sample_weight_train)\n",
    "\n",
    "# Precision-Recall curve and PR-AUC (more informative on class imbalance)\n",
    "precision_train, recall_train, _ = metrics.precision_recall_curve(y_train, y_train_predict)\n",
    "pr_auc_train = metrics.auc(recall_train, precision_train)\n",
    "# Weighted PR curve uses sample weights to compute precision/recall\n",
    "precision_train_w, recall_train_w, _ = metrics.precision_recall_curve(y_train, y_train_predict, sample_weight=sample_weight_train)\n",
    "pr_auc_train_weighted = metrics.auc(recall_train_w, precision_train_w)\n",
    "\n",
    "# Report metrics\n",
    "print(f\"Training ROC-AUC score: {auc_train:0.3f}\")\n",
    "print(f\"Training ROC-AUC Weighted score  : {auc_train_weighted:0.3f}\")\n",
    "print(f\"PR-AUC Score: {pr_auc_train:0.3f}\")\n",
    "print(f\"PR-AUC Weighted Score: {pr_auc_train_weighted:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cccf4-2b98-44d3-8725-227a49bb3c31",
   "metadata": {},
   "source": [
    "|  |  | Specie existance |  |\n",
    "| ------ | :-------: | :------: | :-------: |\n",
    "| |  | **+** | **--** |\n",
    "| **Specie observed** | **+** | True Positive (TP) | False Positive (FP) |\n",
    "| | **--** | False Negative (FN) | True Negative (TN) |\n",
    "| | | **All existing species (TP + FN)** | **All non-existing species (FP + TN)** |\n",
    "\n",
    "\n",
    "$$TPR = \\frac{TP}{TP + FN}$$\n",
    "$$FPR = \\frac{FP}{FP + TN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588ba66-5615-4d10-b8db-26ab26462e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training distributions and curves\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "# Left: Predicted probability distributions for presence vs pseudo-absence\n",
    "ax[0].hist(y_train_predict[y_train == 0], bins=np.linspace(0, 1, int((y_train == 0).sum() / 100 + 1)),\n",
    "           density=True, color='tab:red', alpha=0.7, label='pseudo-absence')\n",
    "ax[0].hist(y_train_predict[y_train == 1], bins=np.linspace(0, 1, int((y_train == 1).sum() / 10 + 1)),\n",
    "           density=True, color='tab:green', alpha=0.7, label='presence')\n",
    "ax[0].set_xlabel('Relative Occurrence Probability')\n",
    "ax[0].set_ylabel('Counts')\n",
    "ax[0].set_title('Probability Distribution')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "# Middle: ROC curve (random vs perfect baselines + model)\n",
    "ax[1].plot([0, 1], [0, 1], '--', label='AUC score: 0.5 (No Skill)', color='gray')\n",
    "ax[1].text(0.4, 0.4, 'random classifier', fontsize=12, color='gray', rotation=45, rotation_mode='anchor',\n",
    "           horizontalalignment='left', verticalalignment='bottom', transform=ax[1].transAxes)\n",
    "ax[1].plot([0, 0, 1], [0, 1, 1], '--', label='AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "ax[1].text(0, 1, '  perfect classifier', fontsize=12, color='tab:blue', horizontalalignment='left', verticalalignment='bottom')\n",
    "ax[1].scatter(0, 1, marker='*', s=100, color='tab:blue')\n",
    "# Overlay model ROC (unweighted and weighted AUC labels)\n",
    "ax[1].plot(fpr_train, tpr_train, label=f'AUC score: {auc_train:0.3f}', color='tab:orange')\n",
    "ax[1].plot(fpr_train, tpr_train, label=f'AUC Weighted score: {auc_train_weighted:0.3f}', color='tab:cyan', linestyle='-.')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive Rate')\n",
    "ax[1].set_title('MaxEnt ROC Curve')\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "# Right: Precision-Recall curve (random/perfect baselines + model)\n",
    "ax[2].plot([0, 1], [0.5, 0.5], '--', color='gray', label='AUC score: 0.5 (No Skill)')\n",
    "ax[2].text(0.5, 0.52, 'random classifier', fontsize=12, color='gray', horizontalalignment='center', verticalalignment='center')\n",
    "ax[2].plot([0, 1, 1], [1, 1, 0], '--', label='AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "ax[2].text(1, 1, 'perfect classifier  ', fontsize=12, color='tab:blue', horizontalalignment='right', verticalalignment='bottom')\n",
    "ax[2].scatter(1, 1, marker='*', s=100, color='tab:blue')\n",
    "# Overlay model PR curves (unweighted and weighted AUC labels)\n",
    "ax[2].plot(recall_train, precision_train, label=f'AUC score: {pr_auc_train:0.3f}', color='tab:orange')\n",
    "ax[2].plot(recall_train_w, precision_train_w, label=f\"AUC Weighted score: {pr_auc_train_weighted:0.3f}\", color='tab:cyan', linestyle='-.')\n",
    "ax[2].axis('equal')\n",
    "ax[2].set_xlabel('Recall')\n",
    "ax[2].set_ylabel('Precision')\n",
    "ax[2].set_title('MaxEnt PR Curve')\n",
    "ax[2].legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b30af-f85b-4419-baa9-ad808d2dfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figures if requested. Uses different filename patterns for current vs future scenarios.\n",
    "# Note: 'models' is used to gate inclusion of model prefix; ensure it exists in your session.\n",
    "if savefig:\n",
    "    if Future:\n",
    "        if models:  # include model identifier when available\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            # Fallback: omit model prefix when not specified\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s.png' % (specie, training, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993984c-f068-4953-8a73-841a09f30b72",
   "metadata": {},
   "source": [
    "## 2. Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f358d3-224d-4be8-a1d2-82f1f3457b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data_name = '%s_model-test_input-data_%s_%s_%s_%s_%s.csv' %(model_prefix, specie, pseudoabsence, interest, bio, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7166b-a73a-441c-a066-ec8e957e04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load held-out test dataset for evaluation\n",
    "# Note: index_col=0 drops the old index saved during export\n",
    "df = pd.read_csv(os.path.join(exp_path, test_input_data_name), index_col=0)\n",
    "# Convert WKT geometry back to shapely objects\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "# Wrap as GeoDataFrame (WGS84 CRS)\n",
    "test = gpd.GeoDataFrame(df, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550482cb-b0da-489c-894d-711a890cd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictors/labels/weights for test set\n",
    "x_test = test.drop(columns=['class', 'SampleWeight', 'geometry'])\n",
    "y_test = test['class']\n",
    "sample_weight_test = test['SampleWeight']\n",
    "\n",
    "# Predict probabilities on the test set using the trained model\n",
    "y_test_predict = model_train.predict(x_test)\n",
    "# Optional: impute NaN probabilities to 0.5 if present\n",
    "# y_test_predict = np.nan_to_num(y_test_predict, nan=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c432c6-86ef-421f-a4fe-2f1cee794e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set metrics: ROC/PR curves and AUCs (unweighted vs weighted)\n",
    "# ROC\n",
    "fpr_test, tpr_test, _ = metrics.roc_curve(y_test, y_test_predict)\n",
    "auc_test = metrics.roc_auc_score(y_test, y_test_predict)\n",
    "auc_test_weighted = metrics.roc_auc_score(y_test, y_test_predict, sample_weight=sample_weight_test)\n",
    "\n",
    "# Precision-Recall (PR)\n",
    "precision_test, recall_test, _ = metrics.precision_recall_curve(y_test, y_test_predict)\n",
    "pr_auc_test = metrics.auc(recall_test, precision_test)\n",
    "precision_test_w, recall_test_w, _ = metrics.precision_recall_curve(y_test, y_test_predict, sample_weight=sample_weight_test)\n",
    "pr_auc_test_weighted = metrics.auc(recall_test_w, precision_test_w)\n",
    "\n",
    "# Print summary of training vs test for quick comparison\n",
    "print(f\"Training ROC-AUC score: {auc_train:0.3f}\")\n",
    "print(f\"Training ROC-AUC Weighted score: {auc_train_weighted:0.3f}\")\n",
    "print(f\"Test ROC-AUC score: {auc_test:0.3f}\")\n",
    "print(f\"Test ROC-AUC Weighted score: {auc_test_weighted:0.3f}\")\n",
    "\n",
    "print(f\"Training PR-AUC Score: {pr_auc_train:0.3f}\")\n",
    "print(f\"Training PR-AUC Weighted Score: {pr_auc_train_weighted:0.3f}\")\n",
    "print(f\"Test PR-AUC Score: {pr_auc_test:0.3f}\")\n",
    "print(f\"Test PR-AUC Weighted Score: {pr_auc_test_weighted:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22fa49-a574-4a0f-b998-4028ab09cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test distributions and curves alongside training for comparison\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "# Left: Predicted probability distributions on test set\n",
    "ax[0].hist(y_test_predict[y_test == 0], bins=np.linspace(0, 1, int((y_test == 0).sum() / 100 + 1)),\n",
    "           density=True, color='tab:red', alpha=0.7, label='pseudo-absence')\n",
    "ax[0].hist(y_test_predict[y_test == 1], bins=np.linspace(0, 1, int((y_test == 1).sum() / 10 + 1)),\n",
    "           density=True, color='tab:green', alpha=0.7, label='presence')\n",
    "ax[0].set_xlabel('Relative Occurrence Probability')\n",
    "ax[0].set_ylabel('Counts')\n",
    "ax[0].set_title('Probability Distribution')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "# Middle: ROC curves (train vs test, with weighted variants labeled)\n",
    "ax[1].plot([0, 1], [0, 1], '--', label='AUC score: 0.5 (No Skill)', color='gray')\n",
    "ax[1].text(0.4, 0.4, 'random classifier', fontsize=12, color='gray', rotation=45, rotation_mode='anchor',\n",
    "           horizontalalignment='left', verticalalignment='bottom', transform=ax[1].transAxes)\n",
    "ax[1].plot([0, 0, 1], [0, 1, 1], '--', label='AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "ax[1].text(0, 1, '  perfect classifier', fontsize=12, color='tab:blue', horizontalalignment='left', verticalalignment='bottom')\n",
    "ax[1].scatter(0, 1, marker='*', s=100, color='tab:blue')\n",
    "ax[1].plot(fpr_train, tpr_train, label=f'AUC train score: {auc_train:0.3f}', color='tab:orange')\n",
    "ax[1].plot(fpr_train, tpr_train, label=f'AUC Weighted train score: {auc_train_weighted:0.3f}', color='tab:cyan', linestyle='-.')\n",
    "ax[1].plot(fpr_test, tpr_test, label=f'AUC test score: {auc_test:0.3f}', color='tab:green')\n",
    "ax[1].plot(fpr_test, tpr_test, label=f'AUC Weighted test score: {auc_test_weighted:0.3f}', color='tab:olive', linestyle='-.')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive Rate')\n",
    "ax[1].set_title('MaxEnt ROC Curve')\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "# Right: PR curves (train vs test)\n",
    "ax[2].plot([0, 1], [0.5, 0.5], '--', color='gray', label='AUC score: 0.5 (No Skill)')\n",
    "ax[2].text(0.5, 0.52, 'random classifier', fontsize=12, color='gray', horizontalalignment='center', verticalalignment='center')\n",
    "ax[2].plot([0, 1, 1], [1, 1, 0], '--', label='AUC score: 1 (Ideal Model)', color='tab:blue', zorder=-1)\n",
    "ax[2].text(1, 1, 'perfect classifier  ', fontsize=12, color='tab:blue', horizontalalignment='right', verticalalignment='bottom')\n",
    "ax[2].scatter(1, 1, marker='*', s=100, color='tab:blue')\n",
    "ax[2].plot(recall_train, precision_train, label=f'AUC train score: {pr_auc_train:0.3f}', color='tab:orange')\n",
    "ax[2].plot(recall_train_w, precision_train_w, label=f\"AUC train Weighted score: {pr_auc_train_weighted:0.3f}\", color='tab:cyan', linestyle='-.')\n",
    "ax[2].plot(recall_test, precision_test, label=f'AUC test score: {pr_auc_test:0.3f}', color='tab:green')\n",
    "ax[2].plot(recall_test_w, precision_test_w, label=f'AUC test Weighted score: {pr_auc_test_weighted:0.3f}', color='tab:olive', linestyle='-.')\n",
    "ax[2].axis('equal')\n",
    "ax[2].set_xlabel('Recall')\n",
    "ax[2].set_ylabel('Precision')\n",
    "ax[2].set_title('MaxEnt PR Curve')\n",
    "ax[2].legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b39edc-a114-46ba-a329-503387ab4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test figures if requested (future vs current naming handled similarly to training)\n",
    "if savefig:\n",
    "    if Future:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_%s_future.png' % (specie, interest, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_future.png' % (specie, interest, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        if model_prefix:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s_%s.png' % (specie, interest, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_roc-pr-auc_%s_%s_%s_%s.png' % (specie, interest, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfd716-825b-4ce8-82aa-fce7f973fcf8",
   "metadata": {},
   "source": [
    "## 3. Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6a70d-105b-4267-bc58-1df7bb8e8aab",
   "metadata": {},
   "source": [
    "### 3.2 Partial dependence plot/ Response curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c51647-a6b0-4329-a077-fb2d3d5aca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = model_train.partial_dependence_plot(x, labels=labels, dpi=100, n_bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeacf3a",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Variable Importance Analysis\n",
    "\n",
    "This section performs a thorough analysis of variable importance by:\n",
    "\n",
    "1. **Initial Analysis**: Running the model with all 19 bioclimatic variables to establish baseline importance\n",
    "2. **Iterative Removal**: Systematically removing the least important variables until we reach ~5 most important variables\n",
    "3. **Performance Tracking**: Monitoring model performance as variables are removed\n",
    "4. **Final Recommendations**: Identifying the optimal subset of variables for the species distribution model\n",
    "\n",
    "### Methodology:\n",
    "- **Permutation Importance**: Measures the drop in model performance when each variable is randomly shuffled\n",
    "- **Iterative Backward Elimination**: Removes least important variables one at a time\n",
    "- **Performance Monitoring**: Tracks AUC, PR-AUC, and other metrics throughout the process\n",
    "- **Cross-Validation**: Ensures robust importance estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b286503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE VARIABLE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Initialize storage for results\n",
    "importance_results = {}\n",
    "performance_history = {}\n",
    "variable_subsets = {}\n",
    "\n",
    "# Get current variable names from training data\n",
    "current_variables = list(x_train.columns)\n",
    "print(f\"Starting with {len(current_variables)} variables:\")\n",
    "print(f\"Variables: {current_variables}\")\n",
    "\n",
    "# Store initial performance metrics\n",
    "initial_metrics = {\n",
    "    'train_auc': auc_train,\n",
    "    'train_auc_weighted': auc_train_weighted,\n",
    "    'train_pr_auc': pr_auc_train,\n",
    "    'train_pr_auc_weighted': pr_auc_train_weighted,\n",
    "    'test_auc': auc_test,\n",
    "    'test_auc_weighted': auc_test_weighted,\n",
    "    'test_pr_auc': pr_auc_test,\n",
    "    'test_pr_auc_weighted': pr_auc_test_weighted\n",
    "}\n",
    "\n",
    "performance_history['all_variables'] = initial_metrics\n",
    "variable_subsets['all_variables'] = current_variables.copy()\n",
    "\n",
    "print(f\"\\nInitial Performance (All {len(current_variables)} variables):\")\n",
    "print(f\"Training AUC: {auc_train:.3f} (weighted: {auc_train_weighted:.3f})\")\n",
    "print(f\"Training PR-AUC: {pr_auc_train:.3f} (weighted: {pr_auc_train_weighted:.3f})\")\n",
    "print(f\"Test AUC: {auc_test:.3f} (weighted: {auc_test_weighted:.3f})\")\n",
    "print(f\"Test PR-AUC: {pr_auc_test:.3f} (weighted: {pr_auc_test_weighted:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46769501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ITERATIVE VARIABLE REMOVAL FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def iterative_variable_removal(x_train, y_train, sample_weight_train, x_test, y_test, sample_weight_test, \n",
    "                              target_variables=5, min_variables=3):\n",
    "    \"\"\"\n",
    "    Iteratively remove least important variables until reaching target number.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_train, y_train, sample_weight_train : training data\n",
    "    x_test, y_test, sample_weight_test : test data  \n",
    "    target_variables : int, target number of variables to keep\n",
    "    min_variables : int, minimum number of variables to keep\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict, containing importance rankings and performance history\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'importance_rankings': {},\n",
    "        'performance_history': {},\n",
    "        'removed_variables': [],\n",
    "        'final_variables': []\n",
    "    }\n",
    "    \n",
    "    current_x_train = x_train.copy()\n",
    "    current_x_test = x_test.copy()\n",
    "    current_vars = list(current_x_train.columns)\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"Starting iterative removal from {len(current_vars)} to {target_variables} variables...\")\n",
    "    \n",
    "    while len(current_vars) > max(target_variables, min_variables):\n",
    "        iteration += 1\n",
    "        print(f\"\\n--- Iteration {iteration}: {len(current_vars)} variables remaining ---\")\n",
    "        \n",
    "        # Train model with current variables\n",
    "        model_iter = ela.MaxentModel()\n",
    "        model_iter.fit(current_x_train, y_train, sample_weight=sample_weight_train)\n",
    "        \n",
    "        # Calculate permutation importance\n",
    "        pi = inspection.permutation_importance(\n",
    "            model_iter, current_x_train, y_train, \n",
    "            sample_weight=sample_weight_train, n_repeats=10\n",
    "        )\n",
    "        \n",
    "        # Get importance scores and rank variables\n",
    "        importance_scores = pi.importances.mean(axis=1)\n",
    "        var_importance = dict(zip(current_vars, importance_scores))\n",
    "        sorted_vars = sorted(var_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Store ranking for this iteration\n",
    "        results['importance_rankings'][f'iteration_{iteration}'] = {\n",
    "            'variables': current_vars.copy(),\n",
    "            'importance_scores': var_importance.copy(),\n",
    "            'sorted_ranking': sorted_vars.copy()\n",
    "        }\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        y_train_pred = model_iter.predict(current_x_train)\n",
    "        y_test_pred = model_iter.predict(current_x_test)\n",
    "        \n",
    "        # Training metrics\n",
    "        train_auc = metrics.roc_auc_score(y_train, y_train_pred)\n",
    "        train_auc_weighted = metrics.roc_auc_score(y_train, y_train_pred, sample_weight=sample_weight_train)\n",
    "        train_precision, train_recall, _ = metrics.precision_recall_curve(y_train, y_train_pred)\n",
    "        train_pr_auc = metrics.auc(train_recall, train_precision)\n",
    "        train_precision_w, train_recall_w, _ = metrics.precision_recall_curve(y_train, y_train_pred, sample_weight=sample_weight_train)\n",
    "        train_pr_auc_weighted = metrics.auc(train_recall_w, train_precision_w)\n",
    "        \n",
    "        # Test metrics\n",
    "        test_auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "        test_auc_weighted = metrics.roc_auc_score(y_test, y_test_pred, sample_weight=sample_weight_test)\n",
    "        test_precision, test_recall, _ = metrics.precision_recall_curve(y_test, y_test_pred)\n",
    "        test_pr_auc = metrics.auc(test_recall, test_precision)\n",
    "        test_precision_w, test_recall_w, _ = metrics.precision_recall_curve(y_test, y_test_pred, sample_weight=sample_weight_test)\n",
    "        test_pr_auc_weighted = metrics.auc(test_recall_w, test_precision_w)\n",
    "        \n",
    "        # Store performance\n",
    "        results['performance_history'][f'iteration_{iteration}'] = {\n",
    "            'n_variables': len(current_vars),\n",
    "            'train_auc': train_auc,\n",
    "            'train_auc_weighted': train_auc_weighted,\n",
    "            'train_pr_auc': train_pr_auc,\n",
    "            'train_pr_auc_weighted': train_pr_auc_weighted,\n",
    "            'test_auc': test_auc,\n",
    "            'test_auc_weighted': test_auc_weighted,\n",
    "            'test_pr_auc': test_pr_auc,\n",
    "            'test_pr_auc_weighted': test_pr_auc_weighted\n",
    "        }\n",
    "        \n",
    "        # Print current performance\n",
    "        print(f\"Performance with {len(current_vars)} variables:\")\n",
    "        print(f\"  Train AUC: {train_auc:.3f} (weighted: {train_auc_weighted:.3f})\")\n",
    "        print(f\"  Test AUC: {test_auc:.3f} (weighted: {test_auc_weighted:.3f})\")\n",
    "        print(f\"  Train PR-AUC: {train_pr_auc:.3f} (weighted: {train_pr_auc_weighted:.3f})\")\n",
    "        print(f\"  Test PR-AUC: {test_pr_auc:.3f} (weighted: {test_pr_auc_weighted:.3f})\")\n",
    "        \n",
    "        # Identify least important variable\n",
    "        least_important_var = sorted_vars[-1][0]\n",
    "        least_important_score = sorted_vars[-1][1]\n",
    "        \n",
    "        print(f\"Least important variable: {least_important_var} (importance: {least_important_score:.4f})\")\n",
    "        \n",
    "        # Remove least important variable\n",
    "        current_x_train = current_x_train.drop(columns=[least_important_var])\n",
    "        current_x_test = current_x_test.drop(columns=[least_important_var])\n",
    "        current_vars.remove(least_important_var)\n",
    "        results['removed_variables'].append(least_important_var)\n",
    "        \n",
    "        print(f\"Removed {least_important_var}. Variables remaining: {current_vars}\")\n",
    "    \n",
    "    results['final_variables'] = current_vars.copy()\n",
    "    print(f\"\\nFinal variable set ({len(current_vars)} variables): {current_vars}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RUN ITERATIVE VARIABLE REMOVAL ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE VARIABLE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run the iterative removal process\n",
    "start_time = time.time()\n",
    "\n",
    "# Set target to 5 variables (can be adjusted)\n",
    "target_vars = 5\n",
    "min_vars = 3\n",
    "\n",
    "# Run iterative removal\n",
    "removal_results = iterative_variable_removal(\n",
    "    x_train, y_train, sample_weight_train,\n",
    "    x_test, y_test, sample_weight_test,\n",
    "    target_variables=target_vars,\n",
    "    min_variables=min_vars\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nAnalysis completed in {end_time - start_time:.1f} seconds\")\n",
    "\n",
    "# Store results for later analysis\n",
    "importance_results['iterative_removal'] = removal_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYZE AND VISUALIZE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# Extract performance trends\n",
    "iterations = list(removal_results['performance_history'].keys())\n",
    "n_vars = [removal_results['performance_history'][iter]['n_variables'] for iter in iterations]\n",
    "train_aucs = [removal_results['performance_history'][iter]['train_auc'] for iter in iterations]\n",
    "test_aucs = [removal_results['performance_history'][iter]['test_auc'] for iter in iterations]\n",
    "train_aucs_weighted = [removal_results['performance_history'][iter]['train_auc_weighted'] for iter in iterations]\n",
    "test_aucs_weighted = [removal_results['performance_history'][iter]['test_auc_weighted'] for iter in iterations]\n",
    "\n",
    "# Add initial performance (all variables)\n",
    "n_vars.insert(0, len(x_train.columns))\n",
    "train_aucs.insert(0, auc_train)\n",
    "test_aucs.insert(0, auc_test)\n",
    "train_aucs_weighted.insert(0, auc_train_weighted)\n",
    "test_aucs_weighted.insert(0, auc_test_weighted)\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Variables':<12} {'Train AUC':<10} {'Test AUC':<10} {'Train AUC-W':<12} {'Test AUC-W':<12}\")\n",
    "print(\"-\"*60)\n",
    "for i, n_var in enumerate(n_vars):\n",
    "    print(f\"{n_var:<12} {train_aucs[i]:<10.3f} {test_aucs[i]:<10.3f} {train_aucs_weighted[i]:<12.3f} {test_aucs_weighted[i]:<12.3f}\")\n",
    "\n",
    "# Get final variable ranking\n",
    "final_iteration = f\"iteration_{len(iterations)}\"\n",
    "final_ranking = removal_results['importance_rankings'][final_iteration]['sorted_ranking']\n",
    "\n",
    "print(f\"\\nFinal Variable Ranking (Top {len(removal_results['final_variables'])} variables):\")\n",
    "print(\"=\"*60)\n",
    "for i, (var, importance) in enumerate(final_ranking, 1):\n",
    "    print(f\"{i:2d}. {var:<15} (importance: {importance:.4f})\")\n",
    "\n",
    "print(f\"\\nRemoved Variables (in order of removal):\")\n",
    "print(\"=\"*40)\n",
    "for i, var in enumerate(removal_results['removed_variables'], 1):\n",
    "    print(f\"{i:2d}. {var}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae31219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE COMPREHENSIVE VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Create a comprehensive figure showing the analysis results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Comprehensive Variable Importance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Performance vs Number of Variables\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(n_vars, train_aucs, 'o-', label='Train AUC', color='tab:blue', linewidth=2)\n",
    "ax1.plot(n_vars, test_aucs, 's-', label='Test AUC', color='tab:orange', linewidth=2)\n",
    "ax1.plot(n_vars, train_aucs_weighted, 'o--', label='Train AUC (Weighted)', color='tab:blue', alpha=0.7)\n",
    "ax1.plot(n_vars, test_aucs_weighted, 's--', label='Test AUC (Weighted)', color='tab:orange', alpha=0.7)\n",
    "ax1.set_xlabel('Number of Variables')\n",
    "ax1.set_ylabel('AUC Score')\n",
    "ax1.set_title('Model Performance vs Number of Variables')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.invert_xaxis()  # Show decreasing variables\n",
    "\n",
    "# 2. Final Variable Importance (Top 10)\n",
    "ax2 = axes[0, 1]\n",
    "top_vars = final_ranking[:10]  # Top 10 variables\n",
    "var_names = [var[0] for var in top_vars]\n",
    "var_importance = [var[1] for var in top_vars]\n",
    "\n",
    "bars = ax2.barh(range(len(var_names)), var_importance, color='tab:green', alpha=0.7)\n",
    "ax2.set_yticks(range(len(var_names)))\n",
    "ax2.set_yticklabels(var_names)\n",
    "ax2.set_xlabel('Permutation Importance')\n",
    "ax2.set_title('Top 10 Most Important Variables')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, val) in enumerate(zip(bars, var_importance)):\n",
    "    ax2.text(val + 0.001, i, f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "# 3. Variable Removal Timeline\n",
    "ax3 = axes[1, 0]\n",
    "removed_vars = removal_results['removed_variables']\n",
    "removal_order = list(range(1, len(removed_vars) + 1))\n",
    "ax3.bar(removal_order, [1] * len(removed_vars), color='tab:red', alpha=0.7)\n",
    "ax3.set_xlabel('Removal Order')\n",
    "ax3.set_ylabel('Variables Removed')\n",
    "ax3.set_title('Variable Removal Timeline')\n",
    "ax3.set_xticks(removal_order)\n",
    "ax3.set_xticklabels([f'#{i}' for i in removal_order])\n",
    "\n",
    "# Add variable names as text\n",
    "for i, var in enumerate(removed_vars):\n",
    "    ax3.text(i + 1, 0.5, var, rotation=90, ha='center', va='center', fontsize=8)\n",
    "\n",
    "# 4. Performance Degradation Analysis\n",
    "ax4 = axes[1, 1]\n",
    "# Calculate performance drop from initial\n",
    "initial_test_auc = test_aucs[0]\n",
    "initial_train_auc = train_aucs[0]\n",
    "test_drop = [(initial_test_auc - auc) / initial_test_auc * 100 for auc in test_aucs]\n",
    "train_drop = [(initial_train_auc - auc) / initial_train_auc * 100 for auc in train_aucs]\n",
    "\n",
    "ax4.plot(n_vars, test_drop, 'o-', label='Test AUC Drop %', color='tab:red', linewidth=2)\n",
    "ax4.plot(n_vars, train_drop, 's-', label='Train AUC Drop %', color='tab:purple', linewidth=2)\n",
    "ax4.set_xlabel('Number of Variables')\n",
    "ax4.set_ylabel('Performance Drop (%)')\n",
    "ax4.set_title('Performance Degradation with Variable Removal')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.invert_xaxis()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the comprehensive analysis figure\n",
    "if savefig:\n",
    "    if Future:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive_var-importance_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive_var-importance_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    else:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive_var-importance_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive_var-importance_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    print(f\"Comprehensive analysis figure saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8afc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT RESULTS TO CSV FOR FURTHER ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Create summary DataFrame for export\n",
    "summary_data = []\n",
    "\n",
    "# Add initial performance (all variables)\n",
    "summary_data.append({\n",
    "    'iteration': 0,\n",
    "    'n_variables': len(x_train.columns),\n",
    "    'variables_removed': 'none',\n",
    "    'train_auc': auc_train,\n",
    "    'train_auc_weighted': auc_train_weighted,\n",
    "    'test_auc': auc_test,\n",
    "    'test_auc_weighted': auc_test_weighted,\n",
    "    'train_pr_auc': pr_auc_train,\n",
    "    'train_pr_auc_weighted': pr_auc_train_weighted,\n",
    "    'test_pr_auc': pr_auc_test,\n",
    "    'test_pr_auc_weighted': pr_auc_test_weighted\n",
    "})\n",
    "\n",
    "# Add iterative removal results\n",
    "for i, iter_key in enumerate(iterations, 1):\n",
    "    perf = removal_results['performance_history'][iter_key]\n",
    "    removed_var = removal_results['removed_variables'][i-1] if i-1 < len(removal_results['removed_variables']) else 'none'\n",
    "    \n",
    "    summary_data.append({\n",
    "        'iteration': i,\n",
    "        'n_variables': perf['n_variables'],\n",
    "        'variables_removed': removed_var,\n",
    "        'train_auc': perf['train_auc'],\n",
    "        'train_auc_weighted': perf['train_auc_weighted'],\n",
    "        'test_auc': perf['test_auc'],\n",
    "        'test_auc_weighted': perf['test_auc_weighted'],\n",
    "        'train_pr_auc': perf['train_pr_auc'],\n",
    "        'train_pr_auc_weighted': perf['train_pr_auc_weighted'],\n",
    "        'test_pr_auc': perf['test_pr_auc'],\n",
    "        'test_pr_auc_weighted': perf['test_pr_auc_weighted']\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Save to CSV\n",
    "if savefig:\n",
    "    csv_filename = f'06_variable_importance_analysis_{specie}_{training}_{bio}_{iteration}.csv'\n",
    "    csv_path = os.path.join(figs_path, csv_filename)\n",
    "    summary_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Analysis summary saved to: {csv_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Species: {specie}\")\n",
    "print(f\"Training Region: {training}\")\n",
    "print(f\"Test Region: {interest}\")\n",
    "print(f\"Initial Variables: {len(x_train.columns)}\")\n",
    "print(f\"Final Variables: {len(removal_results['final_variables'])}\")\n",
    "print(f\"Variables Removed: {len(removal_results['removed_variables'])}\")\n",
    "\n",
    "print(f\"\\nFinal Variable Set:\")\n",
    "for i, var in enumerate(removal_results['final_variables'], 1):\n",
    "    print(f\"  {i}. {var}\")\n",
    "\n",
    "print(f\"\\nPerformance Comparison:\")\n",
    "print(f\"  Initial Test AUC: {test_aucs[0]:.3f}\")\n",
    "print(f\"  Final Test AUC: {test_aucs[-1]:.3f}\")\n",
    "print(f\"  Performance Drop: {((test_aucs[0] - test_aucs[-1]) / test_aucs[0] * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Variables:\")\n",
    "for i, (var, importance) in enumerate(final_ranking[:5], 1):\n",
    "    print(f\"  {i}. {var} (importance: {importance:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fc8d2",
   "metadata": {},
   "source": [
    "## 5. Recommendations and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Most Important Variables**: The analysis identified the top 5 most important bioclimatic variables for the species distribution model.\n",
    "\n",
    "2. **Performance Impact**: The iterative removal process shows how model performance changes as less important variables are removed.\n",
    "\n",
    "3. **Optimal Variable Set**: The final variable set provides a good balance between model complexity and performance.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Use the Final Variable Set**: Consider using the identified top 5 variables for future modeling to reduce complexity while maintaining performance.\n",
    "\n",
    "2. **Validate Results**: Test the reduced variable set on independent data to ensure robustness.\n",
    "\n",
    "3. **Consider Ecological Significance**: Review the biological/ecological meaning of the most important variables to ensure they make sense for the target species.\n",
    "\n",
    "4. **Further Analysis**: Consider running this analysis with different target numbers of variables (e.g., 3, 7, 10) to find the optimal balance.\n",
    "\n",
    "### Files Generated:\n",
    "- Comprehensive analysis figure showing all results\n",
    "- CSV file with detailed performance metrics for each iteration\n",
    "- Variable importance rankings and removal order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a733f05-26cb-4da3-a95d-7adc42870020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare labels and open training output NetCDF for metadata\n",
    "labels = train.drop(columns=['class', 'geometry', 'SampleWeight']).columns.values\n",
    "training_output = xr.open_dataset(os.path.join(exp_path, nc_name))\n",
    "# display(labels)\n",
    "# display(training_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d9454-dce3-4b7d-922b-8f84e37f1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute partial dependence across features\n",
    "# - percentiles bounds the feature grid to observed range (2.5% to 97.5%)\n",
    "# - nbins controls resolution of the curve\n",
    "percentiles = (0.025, 0.975)\n",
    "nbins = 100\n",
    "\n",
    "mean = {}\n",
    "stdv = {}\n",
    "bins = {}\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    # Request individual PDP curves across samples, then summarize\n",
    "    pda = inspection.partial_dependence(\n",
    "        model_train,\n",
    "        x_train,\n",
    "        [idx],\n",
    "        percentiles=percentiles,\n",
    "        grid_resolution=nbins,\n",
    "        kind=\"individual\",\n",
    "    )\n",
    "\n",
    "    mean[label] = pda[\"individual\"][0].mean(axis=0)  # average response\n",
    "    stdv[label] = pda[\"individual\"][0].std(axis=0)   # variability across samples\n",
    "    bins[label] = pda[\"grid_values\"][0]              # feature grid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e805fc6-8c45-4c42-a7fd-255e89a152b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(pda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890d37e-af5a-4f15-966a-02bde1a1f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PDPs with uncertainty bands for each predictor\n",
    "ncols, nrows = subplot_layout(len(labels))\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols * 6, nrows * 6))\n",
    "\n",
    "# Normalize axes list for consistent indexing\n",
    "if (nrows, ncols) == (1, 1):\n",
    "    ax = [axs]\n",
    "else:\n",
    "    ax = axs.ravel()\n",
    "\n",
    "xlabels = training_output.data_vars\n",
    "for iax, label in enumerate(labels):\n",
    "    ax[iax].set_title(label)\n",
    "    try:\n",
    "        ax[iax].set_xlabel(xlabels[label].long_name)\n",
    "    except (ValueError, AttributeError):\n",
    "        ax[iax].set_xlabel('No variable long_name')\n",
    "\n",
    "    # Uncertainty band: mean Â± std across individuals\n",
    "    ax[iax].fill_between(bins[label], mean[label] - stdv[label], mean[label] + stdv[label], alpha=0.25)\n",
    "    ax[iax].plot(bins[label], mean[label])\n",
    "\n",
    "# Style axes\n",
    "for axi in ax:\n",
    "    axi.set_ylim([0, 1])\n",
    "    axi.set_ylabel('probability of occurrence')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2d9fa-5f37-48b4-a03c-9f53f244b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save response curve figures if requested\n",
    "if savefig:\n",
    "    if Future:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_resp-curves_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_resp-curves_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_resp-curves_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration),\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_resp-curves_%s_%s_%s_%s.png' % (specie, training, bio, iteration),\n",
    "            )\n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f47155-3512-4f32-9128-9595e1709c6a",
   "metadata": {},
   "source": [
    "### 3.3 Variable importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b404609-047b-4e31-bf5f-28b0de041906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = model_train.permutation_importance_plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4362f3-93b0-4626-a37b-bf36a36900dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance: measures drop in performance when each feature is shuffled\n",
    "# Higher drop => more important feature\n",
    "pi = inspection.permutation_importance(model_train, x_train, y_train, n_repeats=10)\n",
    "importance = pi.importances\n",
    "rank_order = importance.mean(axis=-1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301c544-3a98-4bac-ab55-d0c07373f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize permutation importances as horizontal boxplots (distribution over repeats)\n",
    "labels_ranked = [labels[idx] for idx in rank_order]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "box = ax.boxplot(importance[rank_order].T, vert=False, labels=labels_ranked)\n",
    "# Decorate legend labels for key boxplot elements\n",
    "box['fliers'][0].set_label('outlier')\n",
    "box['medians'][0].set_label('median')\n",
    "for icap, cap in enumerate(box['caps']):\n",
    "    if icap == 0:\n",
    "        cap.set_label('min-max')\n",
    "    cap.set_color('k')\n",
    "    cap.set_linewidth(2)\n",
    "for ibx, bx in enumerate(box['boxes']):\n",
    "    if ibx == 0:\n",
    "        bx.set_label('25-75%')\n",
    "    bx.set_color('gray')\n",
    "\n",
    "ax.set_xlabel('Importance')\n",
    "ax.legend(loc='lower right')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cc671-1f8a-4375-9af2-8286603483ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if savefig:\n",
    "#     if Future:\n",
    "#         fig.savefig(os.path.join(figs_path, '06_var-importance_%s_%s_%s_future.png' %(specie, training, bio)), transparent=True, bbox_inches='tight')\n",
    "#     else:\n",
    "#         fig.savefig(os.path.join(figs_path, '06_var-importance_%s_%s_%s.png' %(specie, training, bio)), transparent=True, bbox_inches='tight')\n",
    "\n",
    "\n",
    "if savefig:\n",
    "    if Future:\n",
    "        # Check if the 'model' variable is not null or empty\n",
    "        if models:\n",
    "            # If a model is specified, add it to the filename\n",
    "            file_path = os.path.join(figs_path, '06_var-importance_%s_%s_%s_%s_%s_future.png' %(specie, training, bio, model_prefix, iteration))\n",
    "        else:\n",
    "            # If no model is specified, use the original filename\n",
    "            file_path = os.path.join(figs_path, '06_var-importance_%s_%s_%s_%s_future.png' %(specie, training, bio, iteration))\n",
    "        \n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        if models:\n",
    "            # If a model is specified, add it to the filename\n",
    "            file_path = os.path.join(figs_path, '06_var-importance_%s_%s_%s_%s_%s.png' %(specie, training, bio, model_prefix, iteration))\n",
    "        else:\n",
    "            # This is the original logic for non-future scenarios, which remains unchanged\n",
    "            file_path = os.path.join(figs_path, '06_var-importance_%s_%s_%s_%s.png' %(specie, training, bio,iteration))\n",
    "        \n",
    "        fig.savefig(file_path, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44506b",
   "metadata": {},
   "source": [
    "## 6. Model Performance vs Spatial Spread Analysis\n",
    "\n",
    "This section analyzes the relationship between model performance and spatial distribution characteristics of the species data. This analysis helps understand:\n",
    "\n",
    "### **Spatial Performance Metrics**:\n",
    "- **Geographic Distribution**: Spatial extent and clustering of presence/absence data\n",
    "- **Spatial Autocorrelation**: Degree of spatial clustering in the data\n",
    "- **Performance-Spatial Correlation**: How model performance varies with spatial characteristics\n",
    "- **Regional Bias Assessment**: Performance differences across geographic regions\n",
    "\n",
    "### **Key Spatial Analyses**:\n",
    "1. **Spatial Spread Metrics**: Calculate geographic extent, clustering, and distribution patterns\n",
    "2. **Performance-Spatial Correlation**: Analyze relationship between model accuracy and spatial characteristics\n",
    "3. **Regional Performance Maps**: Visualize model performance across different geographic areas\n",
    "4. **Spatial Bias Detection**: Identify regions where the model performs poorly due to spatial bias\n",
    "\n",
    "### **Applications**:\n",
    "- **Bias Assessment**: Identify spatial biases in model performance\n",
    "- **Transferability**: Evaluate model performance across different geographic regions\n",
    "- **Sampling Strategy**: Inform future data collection based on spatial performance patterns\n",
    "- **Model Validation**: Ensure model performs consistently across the study area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL SPREAD ANALYSIS - CALCULATE SPATIAL METRICS\n",
    "# =============================================================================\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "def calculate_spatial_metrics(gdf, class_column='class', weight_column='SampleWeight'):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive spatial metrics for presence/absence data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data with presence/absence information\n",
    "    class_column : str\n",
    "        Column name containing presence/absence labels\n",
    "    weight_column : str\n",
    "        Column name containing sample weights\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    spatial_metrics : dict\n",
    "        Dictionary containing various spatial metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract coordinates\n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    presence_mask = gdf[class_column] == 1\n",
    "    absence_mask = gdf[class_column] == 0\n",
    "    \n",
    "    # Separate presence and absence coordinates\n",
    "    presence_coords = coords[presence_mask]\n",
    "    absence_coords = coords[absence_mask]\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Geographic extent metrics\n",
    "    if len(presence_coords) > 0:\n",
    "        metrics['presence_lat_range'] = np.ptp(presence_coords[:, 1])  # Latitude range\n",
    "        metrics['presence_lon_range'] = np.ptp(presence_coords[:, 0])  # Longitude range\n",
    "        metrics['presence_area_approx'] = metrics['presence_lat_range'] * metrics['presence_lon_range']\n",
    "        \n",
    "        # Calculate centroid\n",
    "        metrics['presence_centroid_lat'] = np.mean(presence_coords[:, 1])\n",
    "        metrics['presence_centroid_lon'] = np.mean(presence_coords[:, 0])\n",
    "    \n",
    "    if len(absence_coords) > 0:\n",
    "        metrics['absence_lat_range'] = np.ptp(absence_coords[:, 1])\n",
    "        metrics['absence_lon_range'] = np.ptp(absence_coords[:, 0])\n",
    "        metrics['absence_area_approx'] = metrics['absence_lat_range'] * metrics['absence_lon_range']\n",
    "        \n",
    "        metrics['absence_centroid_lat'] = np.mean(absence_coords[:, 1])\n",
    "        metrics['absence_centroid_lon'] = np.mean(absence_coords[:, 0])\n",
    "    \n",
    "    # 2. Spatial clustering metrics\n",
    "    if len(presence_coords) > 1:\n",
    "        # Calculate pairwise distances for presence points\n",
    "        presence_distances = pdist(presence_coords)\n",
    "        metrics['presence_mean_distance'] = np.mean(presence_distances)\n",
    "        metrics['presence_std_distance'] = np.std(presence_distances)\n",
    "        metrics['presence_min_distance'] = np.min(presence_distances)\n",
    "        metrics['presence_max_distance'] = np.max(presence_distances)\n",
    "        \n",
    "        # Nearest neighbor analysis for presence points\n",
    "        nbrs = NearestNeighbors(n_neighbors=min(6, len(presence_coords))).fit(presence_coords)\n",
    "        distances, indices = nbrs.kneighbors(presence_coords)\n",
    "        metrics['presence_mean_nn_distance'] = np.mean(distances[:, 1])  # Exclude self (index 0)\n",
    "    \n",
    "    if len(absence_coords) > 1:\n",
    "        # Calculate pairwise distances for absence points\n",
    "        absence_distances = pdist(absence_coords)\n",
    "        metrics['absence_mean_distance'] = np.mean(absence_distances)\n",
    "        metrics['absence_std_distance'] = np.std(absence_distances)\n",
    "        metrics['absence_min_distance'] = np.min(absence_distances)\n",
    "        metrics['absence_max_distance'] = np.max(absence_distances)\n",
    "        \n",
    "        # Nearest neighbor analysis for absence points\n",
    "        nbrs = NearestNeighbors(n_neighbors=min(6, len(absence_coords))).fit(absence_coords)\n",
    "        distances, indices = nbrs.kneighbors(absence_coords)\n",
    "        metrics['absence_mean_nn_distance'] = np.mean(distances[:, 1])\n",
    "    \n",
    "    # 3. Spatial separation between presence and absence\n",
    "    if len(presence_coords) > 0 and len(absence_coords) > 0:\n",
    "        # Calculate minimum distance between presence and absence points\n",
    "        all_distances = []\n",
    "        for pres_coord in presence_coords:\n",
    "            for abs_coord in absence_coords:\n",
    "                dist = np.sqrt(np.sum((pres_coord - abs_coord)**2))\n",
    "                all_distances.append(dist)\n",
    "        \n",
    "        metrics['min_presence_absence_distance'] = np.min(all_distances)\n",
    "        metrics['mean_presence_absence_distance'] = np.mean(all_distances)\n",
    "        metrics['max_presence_absence_distance'] = np.max(all_distances)\n",
    "    \n",
    "    # 4. Density metrics\n",
    "    total_area = metrics.get('presence_area_approx', 0) + metrics.get('absence_area_approx', 0)\n",
    "    if total_area > 0:\n",
    "        metrics['presence_density'] = len(presence_coords) / metrics.get('presence_area_approx', 1)\n",
    "        metrics['absence_density'] = len(absence_coords) / metrics.get('absence_area_approx', 1)\n",
    "    \n",
    "    # 5. Weighted spatial metrics\n",
    "    if weight_column in gdf.columns:\n",
    "        presence_weights = gdf[presence_mask][weight_column].values\n",
    "        absence_weights = gdf[absence_mask][weight_column].values\n",
    "        \n",
    "        if len(presence_weights) > 0:\n",
    "            metrics['presence_weighted_centroid_lat'] = np.average(presence_coords[:, 1], weights=presence_weights)\n",
    "            metrics['presence_weighted_centroid_lon'] = np.average(presence_coords[:, 0], weights=presence_weights)\n",
    "        \n",
    "        if len(absence_weights) > 0:\n",
    "            metrics['absence_weighted_centroid_lat'] = np.average(absence_coords[:, 1], weights=absence_weights)\n",
    "            metrics['absence_weighted_centroid_lon'] = np.average(absence_coords[:, 0], weights=absence_weights)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate spatial metrics for training and test data\n",
    "print(\"Calculating spatial metrics for training data...\")\n",
    "train_spatial_metrics = calculate_spatial_metrics(train, 'class', 'SampleWeight')\n",
    "\n",
    "print(\"Calculating spatial metrics for test data...\")\n",
    "test_spatial_metrics = calculate_spatial_metrics(test, 'class', 'SampleWeight')\n",
    "\n",
    "# Display key spatial metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPATIAL SPREAD METRICS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTRAINING DATA SPATIAL METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in train_spatial_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:<35}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:<35}: {value}\")\n",
    "\n",
    "print(\"\\nTEST DATA SPATIAL METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in test_spatial_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:<35}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:<35}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b3b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL AUTOCORRELATION AND CLUSTERING ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calculate_spatial_autocorrelation(gdf, class_column='class', weight_column='SampleWeight', \n",
    "                                    max_distance=1.0, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Calculate spatial autocorrelation and clustering metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data with presence/absence information\n",
    "    class_column : str\n",
    "        Column name containing presence/absence labels\n",
    "    weight_column : str\n",
    "        Column name containing sample weights\n",
    "    max_distance : float\n",
    "        Maximum distance for spatial autocorrelation analysis\n",
    "    n_neighbors : int\n",
    "        Number of neighbors for local spatial analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    autocorr_metrics : dict\n",
    "        Dictionary containing spatial autocorrelation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract coordinates and labels\n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    labels = gdf[class_column].values\n",
    "    weights = gdf[weight_column].values if weight_column in gdf.columns else None\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Global spatial autocorrelation (Moran's I approximation)\n",
    "    if len(coords) > 1:\n",
    "        # Calculate distance matrix\n",
    "        dist_matrix = squareform(pdist(coords))\n",
    "        \n",
    "        # Create binary weight matrix based on distance threshold\n",
    "        weight_matrix = (dist_matrix <= max_distance).astype(float)\n",
    "        np.fill_diagonal(weight_matrix, 0)  # Remove self-connections\n",
    "        \n",
    "        # Calculate Moran's I\n",
    "        n = len(labels)\n",
    "        mean_label = np.mean(labels)\n",
    "        \n",
    "        # Numerator: sum of weighted deviations\n",
    "        numerator = 0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if weight_matrix[i, j] > 0:\n",
    "                    numerator += weight_matrix[i, j] * (labels[i] - mean_label) * (labels[j] - mean_label)\n",
    "        \n",
    "        # Denominator: sum of squared deviations\n",
    "        denominator = np.sum((labels - mean_label) ** 2)\n",
    "        \n",
    "        # Moran's I\n",
    "        if denominator > 0 and np.sum(weight_matrix) > 0:\n",
    "            morans_i = (n / np.sum(weight_matrix)) * (numerator / denominator)\n",
    "            metrics['morans_i'] = morans_i\n",
    "        else:\n",
    "            metrics['morans_i'] = 0\n",
    "    \n",
    "    # 2. Local spatial clustering analysis\n",
    "    if len(coords) > n_neighbors:\n",
    "        # DBSCAN clustering\n",
    "        dbscan = DBSCAN(eps=max_distance, min_samples=3)\n",
    "        cluster_labels = dbscan.fit_predict(coords)\n",
    "        \n",
    "        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        n_noise = list(cluster_labels).count(-1)\n",
    "        \n",
    "        metrics['dbscan_n_clusters'] = n_clusters\n",
    "        metrics['dbscan_n_noise'] = n_noise\n",
    "        metrics['dbscan_noise_ratio'] = n_noise / len(coords)\n",
    "        \n",
    "        # Silhouette score for clustering quality\n",
    "        if n_clusters > 1:\n",
    "            silhouette = silhouette_score(coords, cluster_labels)\n",
    "            metrics['dbscan_silhouette'] = silhouette\n",
    "        else:\n",
    "            metrics['dbscan_silhouette'] = 0\n",
    "    \n",
    "    # 3. Presence-specific clustering\n",
    "    presence_mask = labels == 1\n",
    "    if np.sum(presence_mask) > 3:  # Need at least 3 presence points\n",
    "        presence_coords = coords[presence_mask]\n",
    "        \n",
    "        # K-means clustering for presence points\n",
    "        n_presence = len(presence_coords)\n",
    "        k_clusters = min(5, n_presence // 2)  # Adaptive number of clusters\n",
    "        \n",
    "        if k_clusters > 1:\n",
    "            kmeans = KMeans(n_clusters=k_clusters, random_state=42, n_init=10)\n",
    "            presence_cluster_labels = kmeans.fit_predict(presence_coords)\n",
    "            \n",
    "            # Calculate within-cluster sum of squares\n",
    "            wcss = kmeans.inertia_\n",
    "            metrics['presence_wcss'] = wcss\n",
    "            \n",
    "            # Calculate silhouette score\n",
    "            if k_clusters > 1:\n",
    "                presence_silhouette = silhouette_score(presence_coords, presence_cluster_labels)\n",
    "                metrics['presence_silhouette'] = presence_silhouette\n",
    "            else:\n",
    "                metrics['presence_silhouette'] = 0\n",
    "    \n",
    "    # 4. Spatial density analysis\n",
    "    if len(coords) > 0:\n",
    "        # Calculate local density using k-nearest neighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=min(n_neighbors, len(coords))).fit(coords)\n",
    "        distances, indices = nbrs.kneighbors(coords)\n",
    "        \n",
    "        # Local density as inverse of mean distance to neighbors\n",
    "        local_density = 1.0 / (distances[:, 1:].mean(axis=1) + 1e-6)  # Add small value to avoid division by zero\n",
    "        metrics['mean_local_density'] = np.mean(local_density)\n",
    "        metrics['std_local_density'] = np.std(local_density)\n",
    "        \n",
    "        # Density-weighted presence ratio\n",
    "        if weights is not None:\n",
    "            weighted_density = np.average(local_density, weights=weights)\n",
    "            metrics['weighted_local_density'] = weighted_density\n",
    "    \n",
    "    # 5. Spatial distribution uniformity\n",
    "    if len(coords) > 1:\n",
    "        # Calculate coefficient of variation in distances\n",
    "        all_distances = pdist(coords)\n",
    "        if len(all_distances) > 0:\n",
    "            cv_distances = np.std(all_distances) / np.mean(all_distances)\n",
    "            metrics['spatial_cv'] = cv_distances\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate spatial autocorrelation for training and test data\n",
    "print(\"Calculating spatial autocorrelation for training data...\")\n",
    "train_autocorr = calculate_spatial_autocorrelation(train, 'class', 'SampleWeight')\n",
    "\n",
    "print(\"Calculating spatial autocorrelation for test data...\")\n",
    "test_autocorr = calculate_spatial_autocorrelation(test, 'class', 'SampleWeight')\n",
    "\n",
    "# Display spatial autocorrelation results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPATIAL AUTOCORRELATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTRAINING DATA AUTOCORRELATION METRICS:\")\n",
    "print(\"-\" * 45)\n",
    "for key, value in train_autocorr.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:<30}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:<30}: {value}\")\n",
    "\n",
    "print(\"\\nTEST DATA AUTOCORRELATION METRICS:\")\n",
    "print(\"-\" * 45)\n",
    "for key, value in test_autocorr.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:<30}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:<30}: {value}\")\n",
    "\n",
    "# Interpret Moran's I values\n",
    "def interpret_morans_i(morans_i):\n",
    "    \"\"\"Interpret Moran's I values for spatial autocorrelation.\"\"\"\n",
    "    if morans_i > 0.3:\n",
    "        return \"Strong positive spatial autocorrelation (clustered)\"\n",
    "    elif morans_i > 0.1:\n",
    "        return \"Moderate positive spatial autocorrelation (somewhat clustered)\"\n",
    "    elif morans_i > -0.1:\n",
    "        return \"No significant spatial autocorrelation (random)\"\n",
    "    elif morans_i > -0.3:\n",
    "        return \"Moderate negative spatial autocorrelation (dispersed)\"\n",
    "    else:\n",
    "        return \"Strong negative spatial autocorrelation (highly dispersed)\"\n",
    "\n",
    "print(f\"\\nTRAINING DATA SPATIAL PATTERN:\")\n",
    "print(f\"Moran's I = {train_autocorr.get('morans_i', 0):.4f}\")\n",
    "print(f\"Interpretation: {interpret_morans_i(train_autocorr.get('morans_i', 0))}\")\n",
    "\n",
    "print(f\"\\nTEST DATA SPATIAL PATTERN:\")\n",
    "print(f\"Moran's I = {test_autocorr.get('morans_i', 0):.4f}\")\n",
    "print(f\"Interpretation: {interpret_morans_i(test_autocorr.get('morans_i', 0))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85feacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PERFORMANCE VS SPATIAL SPREAD CORRELATION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_local_performance_metrics(gdf, predictions, true_labels, weights=None, \n",
    "                                      n_neighbors=10, min_samples=5):\n",
    "    \"\"\"\n",
    "    Calculate local performance metrics for spatial analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data\n",
    "    predictions : array-like\n",
    "        Model predictions\n",
    "    true_labels : array-like\n",
    "        True labels\n",
    "    weights : array-like, optional\n",
    "        Sample weights\n",
    "    n_neighbors : int\n",
    "        Number of neighbors for local analysis\n",
    "    min_samples : int\n",
    "        Minimum samples required for local analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    local_metrics : dict\n",
    "        Dictionary containing local performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    local_metrics = {}\n",
    "    \n",
    "    # Calculate local AUC for each point\n",
    "    local_aucs = []\n",
    "    local_accuracies = []\n",
    "    local_precisions = []\n",
    "    local_recalls = []\n",
    "    local_densities = []\n",
    "    \n",
    "    for i, coord in enumerate(coords):\n",
    "        # Find neighbors\n",
    "        distances = np.sqrt(np.sum((coords - coord)**2, axis=1))\n",
    "        neighbor_indices = np.argsort(distances)[:n_neighbors]\n",
    "        \n",
    "        if len(neighbor_indices) >= min_samples:\n",
    "            # Get neighbor data\n",
    "            neighbor_labels = true_labels[neighbor_indices]\n",
    "            neighbor_predictions = predictions[neighbor_indices]\n",
    "            neighbor_weights = weights[neighbor_indices] if weights is not None else None\n",
    "            \n",
    "            # Calculate local metrics\n",
    "            if len(np.unique(neighbor_labels)) > 1:  # Need both classes\n",
    "                try:\n",
    "                    local_auc = metrics.roc_auc_score(neighbor_labels, neighbor_predictions, \n",
    "                                                    sample_weight=neighbor_weights)\n",
    "                    local_aucs.append(local_auc)\n",
    "                except:\n",
    "                    local_aucs.append(0.5)  # Default to random performance\n",
    "            else:\n",
    "                local_aucs.append(0.5)\n",
    "            \n",
    "            # Local accuracy\n",
    "            local_pred_binary = (neighbor_predictions > 0.5).astype(int)\n",
    "            local_accuracy = np.mean(local_pred_binary == neighbor_labels)\n",
    "            local_accuracies.append(local_accuracy)\n",
    "            \n",
    "            # Local precision and recall\n",
    "            if np.sum(neighbor_labels) > 0:  # Has positive samples\n",
    "                local_precision = metrics.precision_score(neighbor_labels, local_pred_binary, \n",
    "                                                        sample_weight=neighbor_weights, zero_division=0)\n",
    "                local_recall = metrics.recall_score(neighbor_labels, local_pred_binary, \n",
    "                                                  sample_weight=neighbor_weights, zero_division=0)\n",
    "                local_precisions.append(local_precision)\n",
    "                local_recalls.append(local_recall)\n",
    "            else:\n",
    "                local_precisions.append(0)\n",
    "                local_recalls.append(0)\n",
    "            \n",
    "            # Local density\n",
    "            local_density = 1.0 / (np.mean(distances[neighbor_indices[1:]]) + 1e-6)\n",
    "            local_densities.append(local_density)\n",
    "        else:\n",
    "            local_aucs.append(np.nan)\n",
    "            local_accuracies.append(np.nan)\n",
    "            local_precisions.append(np.nan)\n",
    "            local_recalls.append(np.nan)\n",
    "            local_densities.append(np.nan)\n",
    "    \n",
    "    local_metrics['local_aucs'] = np.array(local_aucs)\n",
    "    local_metrics['local_accuracies'] = np.array(local_accuracies)\n",
    "    local_metrics['local_precisions'] = np.array(local_precisions)\n",
    "    local_metrics['local_recalls'] = np.array(local_recalls)\n",
    "    local_metrics['local_densities'] = np.array(local_densities)\n",
    "    \n",
    "    return local_metrics\n",
    "\n",
    "def analyze_performance_spatial_correlation(gdf, predictions, true_labels, weights=None, \n",
    "                                          spatial_metrics=None, autocorr_metrics=None):\n",
    "    \"\"\"\n",
    "    Analyze correlation between model performance and spatial characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data\n",
    "    predictions : array-like\n",
    "        Model predictions\n",
    "    true_labels : array-like\n",
    "        True labels\n",
    "    weights : array-like, optional\n",
    "        Sample weights\n",
    "    spatial_metrics : dict, optional\n",
    "        Spatial spread metrics\n",
    "    autocorr_metrics : dict, optional\n",
    "        Spatial autocorrelation metrics\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    correlation_results : dict\n",
    "        Dictionary containing correlation analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate local performance metrics\n",
    "    local_metrics = calculate_local_performance_metrics(gdf, predictions, true_labels, weights)\n",
    "    \n",
    "    # Calculate spatial characteristics for each point\n",
    "    spatial_chars = {}\n",
    "    \n",
    "    # Distance to centroid\n",
    "    if spatial_metrics:\n",
    "        if 'presence_centroid_lat' in spatial_metrics and 'presence_centroid_lon' in spatial_metrics:\n",
    "            centroid = np.array([spatial_metrics['presence_centroid_lon'], \n",
    "                               spatial_metrics['presence_centroid_lat']])\n",
    "            distances_to_centroid = np.sqrt(np.sum((coords - centroid)**2, axis=1))\n",
    "            spatial_chars['distance_to_centroid'] = distances_to_centroid\n",
    "    \n",
    "    # Local density\n",
    "    spatial_chars['local_density'] = local_metrics['local_densities']\n",
    "    \n",
    "    # Distance to nearest presence/absence\n",
    "    presence_coords = coords[true_labels == 1]\n",
    "    absence_coords = coords[true_labels == 0]\n",
    "    \n",
    "    if len(presence_coords) > 0:\n",
    "        distances_to_presence = []\n",
    "        for coord in coords:\n",
    "            dists = np.sqrt(np.sum((presence_coords - coord)**2, axis=1))\n",
    "            distances_to_presence.append(np.min(dists))\n",
    "        spatial_chars['distance_to_nearest_presence'] = np.array(distances_to_presence)\n",
    "    \n",
    "    if len(absence_coords) > 0:\n",
    "        distances_to_absence = []\n",
    "        for coord in coords:\n",
    "            dists = np.sqrt(np.sum((absence_coords - coord)**2, axis=1))\n",
    "            distances_to_absence.append(np.min(dists))\n",
    "        spatial_chars['distance_to_nearest_absence'] = np.array(distances_to_absence)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    \n",
    "    # Performance vs spatial characteristics\n",
    "    for perf_name, perf_values in local_metrics.items():\n",
    "        if perf_name == 'local_densities':  # Skip density as it's already a spatial characteristic\n",
    "            continue\n",
    "            \n",
    "        correlations[perf_name] = {}\n",
    "        \n",
    "        for spatial_name, spatial_values in spatial_chars.items():\n",
    "            # Remove NaN values for correlation calculation\n",
    "            valid_mask = ~(np.isnan(perf_values) | np.isnan(spatial_values))\n",
    "            \n",
    "            if np.sum(valid_mask) > 10:  # Need sufficient samples\n",
    "                try:\n",
    "                    pearson_r, pearson_p = pearsonr(perf_values[valid_mask], spatial_values[valid_mask])\n",
    "                    spearman_r, spearman_p = spearmanr(perf_values[valid_mask], spatial_values[valid_mask])\n",
    "                    \n",
    "                    correlations[perf_name][spatial_name] = {\n",
    "                        'pearson_r': pearson_r,\n",
    "                        'pearson_p': pearson_p,\n",
    "                        'spearman_r': spearman_r,\n",
    "                        'spearman_p': spearman_p,\n",
    "                        'n_samples': np.sum(valid_mask)\n",
    "                    }\n",
    "                except:\n",
    "                    correlations[perf_name][spatial_name] = {\n",
    "                        'pearson_r': np.nan,\n",
    "                        'pearson_p': np.nan,\n",
    "                        'spearman_r': np.nan,\n",
    "                        'spearman_p': np.nan,\n",
    "                        'n_samples': 0\n",
    "                    }\n",
    "    \n",
    "    results['local_metrics'] = local_metrics\n",
    "    results['spatial_characteristics'] = spatial_chars\n",
    "    results['correlations'] = correlations\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze performance vs spatial spread for training data\n",
    "print(\"Analyzing performance vs spatial spread for training data...\")\n",
    "train_perf_spatial = analyze_performance_spatial_correlation(\n",
    "    train, y_train_predict, y_train, sample_weight_train, \n",
    "    train_spatial_metrics, train_autocorr\n",
    ")\n",
    "\n",
    "# Analyze performance vs spatial spread for test data\n",
    "print(\"Analyzing performance vs spatial spread for test data...\")\n",
    "test_perf_spatial = analyze_performance_spatial_correlation(\n",
    "    test, y_test_predict, y_test, sample_weight_test, \n",
    "    test_spatial_metrics, test_autocorr\n",
    ")\n",
    "\n",
    "# Display correlation results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE VS SPATIAL SPREAD CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def display_correlation_results(perf_spatial_results, dataset_name):\n",
    "    \"\"\"Display correlation results in a formatted way.\"\"\"\n",
    "    print(f\"\\n{dataset_name.upper()} DATA CORRELATIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    correlations = perf_spatial_results['correlations']\n",
    "    \n",
    "    for perf_metric, spatial_corrs in correlations.items():\n",
    "        print(f\"\\n{perf_metric.upper()}:\")\n",
    "        for spatial_char, corr_data in spatial_corrs.items():\n",
    "            if not np.isnan(corr_data['pearson_r']):\n",
    "                print(f\"  vs {spatial_char}:\")\n",
    "                print(f\"    Pearson r = {corr_data['pearson_r']:.4f} (p = {corr_data['pearson_p']:.4f})\")\n",
    "                print(f\"    Spearman r = {corr_data['spearman_r']:.4f} (p = {corr_data['spearman_p']:.4f})\")\n",
    "                print(f\"    n = {corr_data['n_samples']}\")\n",
    "\n",
    "display_correlation_results(train_perf_spatial, \"TRAINING\")\n",
    "display_correlation_results(test_perf_spatial, \"TEST\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def get_significant_correlations(perf_spatial_results, alpha=0.05):\n",
    "    \"\"\"Get significant correlations.\"\"\"\n",
    "    significant_corrs = []\n",
    "    correlations = perf_spatial_results['correlations']\n",
    "    \n",
    "    for perf_metric, spatial_corrs in correlations.items():\n",
    "        for spatial_char, corr_data in spatial_corrs.items():\n",
    "            if (not np.isnan(corr_data['pearson_p']) and \n",
    "                corr_data['pearson_p'] < alpha and \n",
    "                abs(corr_data['pearson_r']) > 0.1):\n",
    "                significant_corrs.append({\n",
    "                    'performance_metric': perf_metric,\n",
    "                    'spatial_characteristic': spatial_char,\n",
    "                    'pearson_r': corr_data['pearson_r'],\n",
    "                    'pearson_p': corr_data['pearson_p'],\n",
    "                    'spearman_r': corr_data['spearman_r'],\n",
    "                    'spearman_p': corr_data['spearman_p']\n",
    "                })\n",
    "    \n",
    "    return significant_corrs\n",
    "\n",
    "train_significant = get_significant_correlations(train_perf_spatial)\n",
    "test_significant = get_significant_correlations(test_perf_spatial)\n",
    "\n",
    "print(f\"\\nTRAINING DATA - Significant correlations (p < 0.05, |r| > 0.1):\")\n",
    "if train_significant:\n",
    "    for corr in train_significant:\n",
    "        print(f\"  {corr['performance_metric']} vs {corr['spatial_characteristic']}: \"\n",
    "              f\"r = {corr['pearson_r']:.4f} (p = {corr['pearson_p']:.4f})\")\n",
    "else:\n",
    "    print(\"  No significant correlations found\")\n",
    "\n",
    "print(f\"\\nTEST DATA - Significant correlations (p < 0.05, |r| > 0.1):\")\n",
    "if test_significant:\n",
    "    for corr in test_significant:\n",
    "        print(f\"  {corr['performance_metric']} vs {corr['spatial_characteristic']}: \"\n",
    "              f\"r = {corr['pearson_r']:.4f} (p = {corr['pearson_p']:.4f})\")\n",
    "else:\n",
    "    print(\"  No significant correlations found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL PERFORMANCE VISUALIZATION AND MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "def create_spatial_performance_visualization(gdf, predictions, true_labels, weights=None, \n",
    "                                           local_metrics=None, dataset_name=\"Data\"):\n",
    "    \"\"\"\n",
    "    Create comprehensive spatial performance visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data\n",
    "    predictions : array-like\n",
    "        Model predictions\n",
    "    true_labels : array-like\n",
    "        True labels\n",
    "    weights : array-like, optional\n",
    "        Sample weights\n",
    "    local_metrics : dict, optional\n",
    "        Local performance metrics\n",
    "    dataset_name : str\n",
    "        Name for the dataset (for titles)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure containing spatial performance plots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'Spatial Performance Analysis - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Extract coordinates\n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    \n",
    "    # 1. Presence/Absence Distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    presence_mask = true_labels == 1\n",
    "    absence_mask = true_labels == 0\n",
    "    \n",
    "    ax1.scatter(coords[absence_mask, 0], coords[absence_mask, 1], \n",
    "               c='red', alpha=0.6, s=20, label='Absence', marker='o')\n",
    "    ax1.scatter(coords[presence_mask, 0], coords[presence_mask, 1], \n",
    "               c='green', alpha=0.8, s=30, label='Presence', marker='^')\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title('Presence/Absence Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Prediction Probabilities\n",
    "    ax2 = axes[0, 1]\n",
    "    scatter = ax2.scatter(coords[:, 0], coords[:, 1], c=predictions, \n",
    "                         cmap='viridis', alpha=0.7, s=25)\n",
    "    ax2.set_xlabel('Longitude')\n",
    "    ax2.set_ylabel('Latitude')\n",
    "    ax2.set_title('Prediction Probabilities')\n",
    "    plt.colorbar(scatter, ax=ax2, label='Probability')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Prediction Errors\n",
    "    ax3 = axes[0, 2]\n",
    "    errors = np.abs(predictions - true_labels)\n",
    "    scatter = ax3.scatter(coords[:, 0], coords[:, 1], c=errors, \n",
    "                         cmap='Reds', alpha=0.7, s=25)\n",
    "    ax3.set_xlabel('Longitude')\n",
    "    ax3.set_ylabel('Latitude')\n",
    "    ax3.set_title('Prediction Errors (|Pred - True|)')\n",
    "    plt.colorbar(scatter, ax=ax3, label='Error')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Local AUC (if available)\n",
    "    ax4 = axes[1, 0]\n",
    "    if local_metrics and 'local_aucs' in local_metrics:\n",
    "        local_aucs = local_metrics['local_aucs']\n",
    "        valid_mask = ~np.isnan(local_aucs)\n",
    "        \n",
    "        if np.sum(valid_mask) > 0:\n",
    "            scatter = ax4.scatter(coords[valid_mask, 0], coords[valid_mask, 1], \n",
    "                                c=local_aucs[valid_mask], cmap='RdYlBu', \n",
    "                                alpha=0.7, s=25, vmin=0, vmax=1)\n",
    "            ax4.set_xlabel('Longitude')\n",
    "            ax4.set_ylabel('Latitude')\n",
    "            ax4.set_title('Local AUC Performance')\n",
    "            plt.colorbar(scatter, ax=ax4, label='Local AUC')\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'No valid local AUC data', \n",
    "                    transform=ax4.transAxes, ha='center', va='center')\n",
    "            ax4.set_title('Local AUC Performance (No Data)')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'Local AUC not calculated', \n",
    "                transform=ax4.transAxes, ha='center', va='center')\n",
    "        ax4.set_title('Local AUC Performance (Not Available)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Local Accuracy (if available)\n",
    "    ax5 = axes[1, 1]\n",
    "    if local_metrics and 'local_accuracies' in local_metrics:\n",
    "        local_accs = local_metrics['local_accuracies']\n",
    "        valid_mask = ~np.isnan(local_accs)\n",
    "        \n",
    "        if np.sum(valid_mask) > 0:\n",
    "            scatter = ax5.scatter(coords[valid_mask, 0], coords[valid_mask, 1], \n",
    "                                c=local_accs[valid_mask], cmap='RdYlGn', \n",
    "                                alpha=0.7, s=25, vmin=0, vmax=1)\n",
    "            ax5.set_xlabel('Longitude')\n",
    "            ax5.set_ylabel('Latitude')\n",
    "            ax5.set_title('Local Accuracy')\n",
    "            plt.colorbar(scatter, ax=ax5, label='Local Accuracy')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, 'No valid local accuracy data', \n",
    "                    transform=ax5.transAxes, ha='center', va='center')\n",
    "            ax5.set_title('Local Accuracy (No Data)')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'Local accuracy not calculated', \n",
    "                transform=ax5.transAxes, ha='center', va='center')\n",
    "        ax5.set_title('Local Accuracy (Not Available)')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Sample Weights (if available)\n",
    "    ax6 = axes[1, 2]\n",
    "    if weights is not None:\n",
    "        scatter = ax6.scatter(coords[:, 0], coords[:, 1], c=weights, \n",
    "                             cmap='plasma', alpha=0.7, s=25)\n",
    "        ax6.set_xlabel('Longitude')\n",
    "        ax6.set_ylabel('Latitude')\n",
    "        ax6.set_title('Sample Weights')\n",
    "        plt.colorbar(scatter, ax=ax6, label='Weight')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'No sample weights available', \n",
    "                transform=ax6.transAxes, ha='center', va='center')\n",
    "        ax6.set_title('Sample Weights (Not Available)')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create spatial performance visualizations\n",
    "print(\"Creating spatial performance visualizations...\")\n",
    "\n",
    "# Training data visualization\n",
    "train_fig = create_spatial_performance_visualization(\n",
    "    train, y_train_predict, y_train, sample_weight_train, \n",
    "    train_perf_spatial['local_metrics'], \"Training Data\"\n",
    ")\n",
    "\n",
    "# Test data visualization\n",
    "test_fig = create_spatial_performance_visualization(\n",
    "    test, y_test_predict, y_test, sample_weight_test, \n",
    "    test_perf_spatial['local_metrics'], \"Test Data\"\n",
    ")\n",
    "\n",
    "# Display the figures\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save spatial performance visualization figures\n",
    "if savefig:\n",
    "    # Training data figure\n",
    "    if Future:\n",
    "        if models:\n",
    "            train_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            train_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            train_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            train_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    train_fig.savefig(train_file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Training spatial performance figure saved to: {train_file_path}\")\n",
    "    \n",
    "    # Test data figure\n",
    "    if Future:\n",
    "        if models:\n",
    "            test_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_%s_future.png' % (specie, interest, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            test_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_future.png' % (specie, interest, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            test_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s_%s.png' % (specie, interest, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            test_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-performance_%s_%s_%s_%s.png' % (specie, interest, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    test_fig.savefig(test_file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Test spatial performance figure saved to: {test_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f65110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL BIAS ASSESSMENT AND COMPREHENSIVE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def assess_spatial_bias(gdf, predictions, true_labels, weights=None, \n",
    "                       spatial_metrics=None, autocorr_metrics=None):\n",
    "    \"\"\"\n",
    "    Comprehensive spatial bias assessment.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Geospatial data\n",
    "    predictions : array-like\n",
    "        Model predictions\n",
    "    true_labels : array-like\n",
    "        True labels\n",
    "    weights : array-like, optional\n",
    "        Sample weights\n",
    "    spatial_metrics : dict, optional\n",
    "        Spatial spread metrics\n",
    "    autocorr_metrics : dict, optional\n",
    "        Spatial autocorrelation metrics\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bias_assessment : dict\n",
    "        Dictionary containing spatial bias assessment results\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Geographic bias assessment\n",
    "    geographic_bias = {}\n",
    "    \n",
    "    # Divide study area into quadrants\n",
    "    lon_center = np.mean(coords[:, 0])\n",
    "    lat_center = np.mean(coords[:, 1])\n",
    "    \n",
    "    # Create quadrant masks\n",
    "    nw_mask = (coords[:, 0] <= lon_center) & (coords[:, 1] >= lat_center)\n",
    "    ne_mask = (coords[:, 0] > lon_center) & (coords[:, 1] >= lat_center)\n",
    "    sw_mask = (coords[:, 0] <= lon_center) & (coords[:, 1] < lat_center)\n",
    "    se_mask = (coords[:, 0] > lon_center) & (coords[:, 1] < lat_center)\n",
    "    \n",
    "    quadrants = {'NW': nw_mask, 'NE': ne_mask, 'SW': sw_mask, 'SE': se_mask}\n",
    "    \n",
    "    for quad_name, quad_mask in quadrants.items():\n",
    "        if np.sum(quad_mask) > 0:\n",
    "            quad_predictions = predictions[quad_mask]\n",
    "            quad_labels = true_labels[quad_mask]\n",
    "            quad_weights = weights[quad_mask] if weights is not None else None\n",
    "            \n",
    "            # Calculate performance metrics for this quadrant\n",
    "            try:\n",
    "                quad_auc = metrics.roc_auc_score(quad_labels, quad_predictions, \n",
    "                                               sample_weight=quad_weights)\n",
    "                quad_accuracy = np.mean((quad_predictions > 0.5) == quad_labels)\n",
    "                \n",
    "                # Calculate bias metrics\n",
    "                quad_bias = np.mean(quad_predictions - quad_labels)\n",
    "                quad_mae = np.mean(np.abs(quad_predictions - quad_labels))\n",
    "                \n",
    "                geographic_bias[quad_name] = {\n",
    "                    'n_samples': np.sum(quad_mask),\n",
    "                    'auc': quad_auc,\n",
    "                    'accuracy': quad_accuracy,\n",
    "                    'bias': quad_bias,\n",
    "                    'mae': quad_mae,\n",
    "                    'mean_prediction': np.mean(quad_predictions),\n",
    "                    'presence_ratio': np.mean(quad_labels)\n",
    "                }\n",
    "            except:\n",
    "                geographic_bias[quad_name] = {\n",
    "                    'n_samples': np.sum(quad_mask),\n",
    "                    'auc': np.nan,\n",
    "                    'accuracy': np.nan,\n",
    "                    'bias': np.nan,\n",
    "                    'mae': np.nan,\n",
    "                    'mean_prediction': np.nan,\n",
    "                    'presence_ratio': np.nan\n",
    "                }\n",
    "    \n",
    "    results['geographic_bias'] = geographic_bias\n",
    "    \n",
    "    # 2. Distance-based bias assessment\n",
    "    if spatial_metrics and 'presence_centroid_lat' in spatial_metrics:\n",
    "        centroid = np.array([spatial_metrics['presence_centroid_lon'], \n",
    "                           spatial_metrics['presence_centroid_lat']])\n",
    "        distances_to_centroid = np.sqrt(np.sum((coords - centroid)**2, axis=1))\n",
    "        \n",
    "        # Divide into distance bands\n",
    "        distance_quartiles = np.percentile(distances_to_centroid, [25, 50, 75])\n",
    "        \n",
    "        distance_bias = {}\n",
    "        distance_bands = ['Close', 'Medium', 'Far', 'Very_Far']\n",
    "        distance_masks = [\n",
    "            distances_to_centroid <= distance_quartiles[0],\n",
    "            (distances_to_centroid > distance_quartiles[0]) & (distances_to_centroid <= distance_quartiles[1]),\n",
    "            (distances_to_centroid > distance_quartiles[1]) & (distances_to_centroid <= distance_quartiles[2]),\n",
    "            distances_to_centroid > distance_quartiles[2]\n",
    "        ]\n",
    "        \n",
    "        for band_name, band_mask in zip(distance_bands, distance_masks):\n",
    "            if np.sum(band_mask) > 0:\n",
    "                band_predictions = predictions[band_mask]\n",
    "                band_labels = true_labels[band_mask]\n",
    "                band_weights = weights[band_mask] if weights is not None else None\n",
    "                \n",
    "                try:\n",
    "                    band_auc = metrics.roc_auc_score(band_labels, band_predictions, \n",
    "                                                   sample_weight=band_weights)\n",
    "                    band_bias = np.mean(band_predictions - band_labels)\n",
    "                    band_mae = np.mean(np.abs(band_predictions - band_labels))\n",
    "                    \n",
    "                    distance_bias[band_name] = {\n",
    "                        'n_samples': np.sum(band_mask),\n",
    "                        'mean_distance': np.mean(distances_to_centroid[band_mask]),\n",
    "                        'auc': band_auc,\n",
    "                        'bias': band_bias,\n",
    "                        'mae': band_mae,\n",
    "                        'mean_prediction': np.mean(band_predictions),\n",
    "                        'presence_ratio': np.mean(band_labels)\n",
    "                    }\n",
    "                except:\n",
    "                    distance_bias[band_name] = {\n",
    "                        'n_samples': np.sum(band_mask),\n",
    "                        'mean_distance': np.mean(distances_to_centroid[band_mask]),\n",
    "                        'auc': np.nan,\n",
    "                        'bias': np.nan,\n",
    "                        'mae': np.nan,\n",
    "                        'mean_prediction': np.nan,\n",
    "                        'presence_ratio': np.nan\n",
    "                    }\n",
    "        \n",
    "        results['distance_bias'] = distance_bias\n",
    "    \n",
    "    # 3. Density-based bias assessment\n",
    "    if spatial_metrics and 'mean_local_density' in spatial_metrics:\n",
    "        # Use local density from spatial metrics\n",
    "        local_densities = spatial_metrics.get('local_densities', np.ones(len(coords)))\n",
    "        \n",
    "        # Divide into density bands\n",
    "        density_quartiles = np.percentile(local_densities, [25, 50, 75])\n",
    "        \n",
    "        density_bias = {}\n",
    "        density_bands = ['Low', 'Medium', 'High', 'Very_High']\n",
    "        density_masks = [\n",
    "            local_densities <= density_quartiles[0],\n",
    "            (local_densities > density_quartiles[0]) & (local_densities <= density_quartiles[1]),\n",
    "            (local_densities > density_quartiles[1]) & (local_densities <= density_quartiles[2]),\n",
    "            local_densities > density_quartiles[2]\n",
    "        ]\n",
    "        \n",
    "        for band_name, band_mask in zip(density_bands, density_masks):\n",
    "            if np.sum(band_mask) > 0:\n",
    "                band_predictions = predictions[band_mask]\n",
    "                band_labels = true_labels[band_mask]\n",
    "                band_weights = weights[band_mask] if weights is not None else None\n",
    "                \n",
    "                try:\n",
    "                    band_auc = metrics.roc_auc_score(band_labels, band_predictions, \n",
    "                                                   sample_weight=band_weights)\n",
    "                    band_bias = np.mean(band_predictions - band_labels)\n",
    "                    band_mae = np.mean(np.abs(band_predictions - band_labels))\n",
    "                    \n",
    "                    density_bias[band_name] = {\n",
    "                        'n_samples': np.sum(band_mask),\n",
    "                        'mean_density': np.mean(local_densities[band_mask]),\n",
    "                        'auc': band_auc,\n",
    "                        'bias': band_bias,\n",
    "                        'mae': band_mae,\n",
    "                        'mean_prediction': np.mean(band_predictions),\n",
    "                        'presence_ratio': np.mean(band_labels)\n",
    "                    }\n",
    "                except:\n",
    "                    density_bias[band_name] = {\n",
    "                        'n_samples': np.sum(band_mask),\n",
    "                        'mean_density': np.mean(local_densities[band_mask]),\n",
    "                        'auc': np.nan,\n",
    "                        'bias': np.nan,\n",
    "                        'mae': np.nan,\n",
    "                        'mean_prediction': np.nan,\n",
    "                        'presence_ratio': np.nan\n",
    "                    }\n",
    "        \n",
    "        results['density_bias'] = density_bias\n",
    "    \n",
    "    # 4. Overall bias summary\n",
    "    overall_bias = {\n",
    "        'mean_prediction': np.mean(predictions),\n",
    "        'mean_true': np.mean(true_labels),\n",
    "        'overall_bias': np.mean(predictions - true_labels),\n",
    "        'overall_mae': np.mean(np.abs(predictions - true_labels)),\n",
    "        'prediction_std': np.std(predictions),\n",
    "        'true_std': np.std(true_labels)\n",
    "    }\n",
    "    \n",
    "    results['overall_bias'] = overall_bias\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Assess spatial bias for training and test data\n",
    "print(\"Assessing spatial bias for training data...\")\n",
    "train_bias = assess_spatial_bias(train, y_train_predict, y_train, sample_weight_train, \n",
    "                               train_spatial_metrics, train_autocorr)\n",
    "\n",
    "print(\"Assessing spatial bias for test data...\")\n",
    "test_bias = assess_spatial_bias(test, y_test_predict, y_test, sample_weight_test, \n",
    "                              test_spatial_metrics, test_autocorr)\n",
    "\n",
    "# Display bias assessment results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL BIAS ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def display_bias_results(bias_results, dataset_name):\n",
    "    \"\"\"Display bias assessment results in a formatted way.\"\"\"\n",
    "    print(f\"\\n{dataset_name.upper()} DATA BIAS ASSESSMENT:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Overall bias\n",
    "    overall = bias_results['overall_bias']\n",
    "    print(f\"\\nOverall Bias Metrics:\")\n",
    "    print(f\"  Mean Prediction: {overall['mean_prediction']:.4f}\")\n",
    "    print(f\"  Mean True: {overall['mean_true']:.4f}\")\n",
    "    print(f\"  Overall Bias: {overall['overall_bias']:.4f}\")\n",
    "    print(f\"  Overall MAE: {overall['overall_mae']:.4f}\")\n",
    "    print(f\"  Prediction Std: {overall['prediction_std']:.4f}\")\n",
    "    print(f\"  True Std: {overall['true_std']:.4f}\")\n",
    "    \n",
    "    # Geographic bias\n",
    "    if 'geographic_bias' in bias_results:\n",
    "        print(f\"\\nGeographic Bias (by Quadrant):\")\n",
    "        for quad, metrics in bias_results['geographic_bias'].items():\n",
    "            if not np.isnan(metrics['auc']):\n",
    "                print(f\"  {quad}: AUC={metrics['auc']:.3f}, Bias={metrics['bias']:.3f}, \"\n",
    "                      f\"MAE={metrics['mae']:.3f}, n={metrics['n_samples']}\")\n",
    "    \n",
    "    # Distance bias\n",
    "    if 'distance_bias' in bias_results:\n",
    "        print(f\"\\nDistance-based Bias:\")\n",
    "        for band, metrics in bias_results['distance_bias'].items():\n",
    "            if not np.isnan(metrics['auc']):\n",
    "                print(f\"  {band}: AUC={metrics['auc']:.3f}, Bias={metrics['bias']:.3f}, \"\n",
    "                      f\"MAE={metrics['mae']:.3f}, n={metrics['n_samples']}\")\n",
    "    \n",
    "    # Density bias\n",
    "    if 'density_bias' in bias_results:\n",
    "        print(f\"\\nDensity-based Bias:\")\n",
    "        for band, metrics in bias_results['density_bias'].items():\n",
    "            if not np.isnan(metrics['auc']):\n",
    "                print(f\"  {band}: AUC={metrics['auc']:.3f}, Bias={metrics['bias']:.3f}, \"\n",
    "                      f\"MAE={metrics['mae']:.3f}, n={metrics['n_samples']}\")\n",
    "\n",
    "display_bias_results(train_bias, \"TRAINING\")\n",
    "display_bias_results(test_bias, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT SPATIAL ANALYSIS RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# Create comprehensive summary of spatial analysis results\n",
    "spatial_analysis_summary = {\n",
    "    'species': specie,\n",
    "    'training_region': training,\n",
    "    'test_region': interest,\n",
    "    'bioclimatic_variable': bio,\n",
    "    'iteration': iteration,\n",
    "    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n",
    "    \n",
    "    # Spatial metrics\n",
    "    'training_spatial_metrics': train_spatial_metrics,\n",
    "    'test_spatial_metrics': test_spatial_metrics,\n",
    "    \n",
    "    # Spatial autocorrelation\n",
    "    'training_autocorrelation': train_autocorr,\n",
    "    'test_autocorrelation': test_autocorr,\n",
    "    \n",
    "    # Performance vs spatial correlation\n",
    "    'training_performance_spatial': {\n",
    "        'significant_correlations': train_significant,\n",
    "        'local_metrics_summary': {\n",
    "            'mean_local_auc': np.nanmean(train_perf_spatial['local_metrics']['local_aucs']),\n",
    "            'std_local_auc': np.nanstd(train_perf_spatial['local_metrics']['local_aucs']),\n",
    "            'mean_local_accuracy': np.nanmean(train_perf_spatial['local_metrics']['local_accuracies']),\n",
    "            'std_local_accuracy': np.nanstd(train_perf_spatial['local_metrics']['local_accuracies'])\n",
    "        }\n",
    "    },\n",
    "    'test_performance_spatial': {\n",
    "        'significant_correlations': test_significant,\n",
    "        'local_metrics_summary': {\n",
    "            'mean_local_auc': np.nanmean(test_perf_spatial['local_metrics']['local_aucs']),\n",
    "            'std_local_auc': np.nanstd(test_perf_spatial['local_metrics']['local_aucs']),\n",
    "            'mean_local_accuracy': np.nanmean(test_perf_spatial['local_metrics']['local_accuracies']),\n",
    "            'std_local_accuracy': np.nanstd(test_perf_spatial['local_metrics']['local_accuracies'])\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Spatial bias assessment\n",
    "    'training_bias_assessment': train_bias,\n",
    "    'test_bias_assessment': test_bias,\n",
    "    \n",
    "    # Model performance comparison\n",
    "    'model_performance_comparison': {\n",
    "        'training': {\n",
    "            'auc': auc_train,\n",
    "            'auc_weighted': auc_train_weighted,\n",
    "            'pr_auc': pr_auc_train,\n",
    "            'pr_auc_weighted': pr_auc_train_weighted\n",
    "        },\n",
    "        'test': {\n",
    "            'auc': auc_test,\n",
    "            'auc_weighted': auc_test_weighted,\n",
    "            'pr_auc': pr_auc_test,\n",
    "            'pr_auc_weighted': pr_auc_test_weighted\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save comprehensive results to JSON\n",
    "if savefig:\n",
    "    import json\n",
    "    \n",
    "    # Convert numpy types to Python types for JSON serialization\n",
    "    def convert_numpy_types(obj):\n",
    "        \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy_types(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    # Convert the summary for JSON serialization\n",
    "    json_summary = convert_numpy_types(spatial_analysis_summary)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    json_filename = f'06_spatial_analysis_summary_{specie}_{training}_{bio}_{iteration}.json'\n",
    "    json_path = os.path.join(figs_path, json_filename)\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Spatial analysis summary saved to: {json_path}\")\n",
    "\n",
    "# Create a final summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL ANALYSIS FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSpecies: {specie}\")\n",
    "print(f\"Training Region: {training}\")\n",
    "print(f\"Test Region: {interest}\")\n",
    "print(f\"Bioclimatic Variable: {bio}\")\n",
    "print(f\"Iteration: {iteration}\")\n",
    "\n",
    "print(f\"\\nMODEL PERFORMANCE SUMMARY:\")\n",
    "print(f\"Training AUC: {auc_train:.3f} (weighted: {auc_train_weighted:.3f})\")\n",
    "print(f\"Test AUC: {auc_test:.3f} (weighted: {auc_test_weighted:.3f})\")\n",
    "print(f\"Training PR-AUC: {pr_auc_train:.3f} (weighted: {pr_auc_train_weighted:.3f})\")\n",
    "print(f\"Test PR-AUC: {pr_auc_test:.3f} (weighted: {pr_auc_test_weighted:.3f})\")\n",
    "\n",
    "print(f\"\\nSPATIAL CHARACTERISTICS:\")\n",
    "print(f\"Training Data Spatial Pattern: {interpret_morans_i(train_autocorr.get('morans_i', 0))}\")\n",
    "print(f\"Test Data Spatial Pattern: {interpret_morans_i(test_autocorr.get('morans_i', 0))}\")\n",
    "\n",
    "print(f\"\\nSIGNIFICANT SPATIAL CORRELATIONS:\")\n",
    "if train_significant:\n",
    "    print(\"Training Data:\")\n",
    "    for corr in train_significant:\n",
    "        print(f\"  - {corr['performance_metric']} vs {corr['spatial_characteristic']}: r = {corr['pearson_r']:.3f}\")\n",
    "else:\n",
    "    print(\"Training Data: No significant correlations found\")\n",
    "\n",
    "if test_significant:\n",
    "    print(\"Test Data:\")\n",
    "    for corr in test_significant:\n",
    "        print(f\"  - {corr['performance_metric']} vs {corr['spatial_characteristic']}: r = {corr['pearson_r']:.3f}\")\n",
    "else:\n",
    "    print(\"Test Data: No significant correlations found\")\n",
    "\n",
    "print(f\"\\nSPATIAL BIAS ASSESSMENT:\")\n",
    "print(f\"Training Data Overall Bias: {train_bias['overall_bias']['overall_bias']:.4f}\")\n",
    "print(f\"Test Data Overall Bias: {test_bias['overall_bias']['overall_bias']:.4f}\")\n",
    "\n",
    "print(f\"\\nFILES GENERATED:\")\n",
    "print(f\"- Spatial performance visualizations (training and test)\")\n",
    "print(f\"- Comprehensive spatial analysis summary (JSON)\")\n",
    "print(f\"- All figures saved with appropriate naming conventions\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992fe59",
   "metadata": {},
   "source": [
    "## 7. Spatial Spread Analysis Across Variable Set Iterations\n",
    "\n",
    "This section analyzes how spatial spread characteristics change across different variable set iterations from the comprehensive variable importance analysis. This helps identify the optimal variable combination that maintains both model performance and spatial representativeness.\n",
    "\n",
    "### **Key Objectives**:\n",
    "- **Variable Set Comparison**: Compare spatial spread metrics across different variable combinations\n",
    "- **Spatial Performance Optimization**: Find the variable set that best balances model performance with spatial coverage\n",
    "- **Spatial Bias Minimization**: Identify variable sets that minimize spatial bias\n",
    "- **Transferability Assessment**: Evaluate how different variable sets affect spatial transferability\n",
    "\n",
    "### **Analysis Components**:\n",
    "1. **Spatial Metrics by Variable Set**: Calculate spatial spread metrics for each variable combination\n",
    "2. **Performance-Spatial Trade-offs**: Analyze the relationship between model performance and spatial characteristics\n",
    "3. **Optimal Variable Selection**: Identify the best variable set based on combined performance and spatial criteria\n",
    "4. **Spatial Transferability**: Assess how variable selection affects spatial model transferability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL SPREAD ANALYSIS ACROSS VARIABLE SET ITERATIONS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_spatial_spread_by_variable_sets(x_train, y_train, sample_weight_train, \n",
    "                                          x_test, y_test, sample_weight_test,\n",
    "                                          train_gdf, test_gdf, removal_results):\n",
    "    \"\"\"\n",
    "    Analyze spatial spread characteristics for each variable set iteration.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_train, y_train, sample_weight_train : training data\n",
    "    x_test, y_test, sample_weight_test : test data\n",
    "    train_gdf, test_gdf : GeoDataFrames with spatial information\n",
    "    removal_results : dict, results from iterative variable removal\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    spatial_iteration_results : dict\n",
    "        Dictionary containing spatial analysis for each variable set\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Get all variable sets from removal results\n",
    "    iterations = list(removal_results['performance_history'].keys())\n",
    "    \n",
    "    # Add initial full variable set\n",
    "    all_iterations = ['initial'] + iterations\n",
    "    \n",
    "    print(\"Analyzing spatial spread for each variable set iteration...\")\n",
    "    print(f\"Total iterations to analyze: {len(all_iterations)}\")\n",
    "    \n",
    "    for i, iter_key in enumerate(all_iterations):\n",
    "        print(f\"\\nProcessing iteration: {iter_key}\")\n",
    "        \n",
    "        # Get variable set for this iteration\n",
    "        if iter_key == 'initial':\n",
    "            current_vars = list(x_train.columns)\n",
    "            n_vars = len(current_vars)\n",
    "        else:\n",
    "            # Get variables from the ranking at this iteration\n",
    "            ranking_key = iter_key\n",
    "            if ranking_key in removal_results['importance_rankings']:\n",
    "                current_vars = removal_results['importance_rankings'][ranking_key]['variables']\n",
    "                n_vars = len(current_vars)\n",
    "            else:\n",
    "                print(f\"  Skipping {iter_key} - no ranking data available\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"  Variables ({n_vars}): {current_vars}\")\n",
    "        \n",
    "        # Select variables for this iteration\n",
    "        x_train_iter = x_train[current_vars]\n",
    "        x_test_iter = x_test[current_vars]\n",
    "        \n",
    "        # Train model with current variable set\n",
    "        try:\n",
    "            model_iter = ela.MaxentModel()\n",
    "            model_iter.fit(x_train_iter, y_train, sample_weight=sample_weight_train)\n",
    "            \n",
    "            # Get predictions\n",
    "            y_train_pred = model_iter.predict(x_train_iter)\n",
    "            y_test_pred = model_iter.predict(x_test_iter)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            train_auc = metrics.roc_auc_score(y_train, y_train_pred)\n",
    "            train_auc_weighted = metrics.roc_auc_score(y_train, y_train_pred, sample_weight=sample_weight_train)\n",
    "            test_auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "            test_auc_weighted = metrics.roc_auc_score(y_test, y_test_pred, sample_weight=sample_weight_test)\n",
    "            \n",
    "            # Calculate spatial metrics for training data\n",
    "            train_spatial_iter = calculate_spatial_metrics(train_gdf, 'class', 'SampleWeight')\n",
    "            test_spatial_iter = calculate_spatial_metrics(test_gdf, 'class', 'SampleWeight')\n",
    "            \n",
    "            # Calculate spatial autocorrelation\n",
    "            train_autocorr_iter = calculate_spatial_autocorrelation(train_gdf, 'class', 'SampleWeight')\n",
    "            test_autocorr_iter = calculate_spatial_autocorrelation(test_gdf, 'class', 'SampleWeight')\n",
    "            \n",
    "            # Calculate performance vs spatial correlation\n",
    "            train_perf_spatial_iter = analyze_performance_spatial_correlation(\n",
    "                train_gdf, y_train_pred, y_train, sample_weight_train, \n",
    "                train_spatial_iter, train_autocorr_iter\n",
    "            )\n",
    "            \n",
    "            test_perf_spatial_iter = analyze_performance_spatial_correlation(\n",
    "                test_gdf, y_test_pred, y_test, sample_weight_test, \n",
    "                test_spatial_iter, test_autocorr_iter\n",
    "            )\n",
    "            \n",
    "            # Calculate spatial bias\n",
    "            train_bias_iter = assess_spatial_bias(\n",
    "                train_gdf, y_train_pred, y_train, sample_weight_train, \n",
    "                train_spatial_iter, train_autocorr_iter\n",
    "            )\n",
    "            \n",
    "            test_bias_iter = assess_spatial_bias(\n",
    "                test_gdf, y_test_pred, y_test, sample_weight_test, \n",
    "                test_spatial_iter, test_autocorr_iter\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            results[iter_key] = {\n",
    "                'n_variables': n_vars,\n",
    "                'variables': current_vars,\n",
    "                'performance': {\n",
    "                    'train_auc': train_auc,\n",
    "                    'train_auc_weighted': train_auc_weighted,\n",
    "                    'test_auc': test_auc,\n",
    "                    'test_auc_weighted': test_auc_weighted\n",
    "                },\n",
    "                'spatial_metrics': {\n",
    "                    'train': train_spatial_iter,\n",
    "                    'test': test_spatial_iter\n",
    "                },\n",
    "                'autocorrelation': {\n",
    "                    'train': train_autocorr_iter,\n",
    "                    'test': test_autocorr_iter\n",
    "                },\n",
    "                'performance_spatial': {\n",
    "                    'train': train_perf_spatial_iter,\n",
    "                    'test': test_perf_spatial_iter\n",
    "                },\n",
    "                'bias_assessment': {\n",
    "                    'train': train_bias_iter,\n",
    "                    'test': test_bias_iter\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            print(f\"  Completed - Train AUC: {train_auc:.3f}, Test AUC: {test_auc:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {iter_key}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run spatial spread analysis across variable iterations\n",
    "print(\"=\"*80)\n",
    "print(\"SPATIAL SPREAD ANALYSIS ACROSS VARIABLE SET ITERATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spatial_iteration_results = analyze_spatial_spread_by_variable_sets(\n",
    "    x_train, y_train, sample_weight_train,\n",
    "    x_test, y_test, sample_weight_test,\n",
    "    train, test, removal_results\n",
    ")\n",
    "\n",
    "print(f\"\\nAnalysis completed for {len(spatial_iteration_results)} variable set iterations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6202b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE SPATIAL PERFORMANCE COMPARISON ACROSS VARIABLE SETS\n",
    "# =============================================================================\n",
    "\n",
    "def compare_spatial_performance_across_variable_sets(spatial_iteration_results):\n",
    "    \"\"\"\n",
    "    Compare spatial performance metrics across different variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_iteration_results : dict\n",
    "        Results from spatial analysis across variable iterations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    comparison_results : dict\n",
    "        Comprehensive comparison of spatial performance across variable sets\n",
    "    \"\"\"\n",
    "    \n",
    "    comparison = {}\n",
    "    \n",
    "    # Extract key metrics for comparison\n",
    "    iterations = list(spatial_iteration_results.keys())\n",
    "    \n",
    "    # Performance metrics\n",
    "    n_vars = []\n",
    "    train_aucs = []\n",
    "    test_aucs = []\n",
    "    train_aucs_weighted = []\n",
    "    test_aucs_weighted = []\n",
    "    \n",
    "    # Spatial spread metrics\n",
    "    train_spatial_extents = []\n",
    "    test_spatial_extents = []\n",
    "    train_spatial_clustering = []\n",
    "    test_spatial_clustering = []\n",
    "    \n",
    "    # Spatial autocorrelation\n",
    "    train_morans_i = []\n",
    "    test_morans_i = []\n",
    "    \n",
    "    # Spatial bias metrics\n",
    "    train_overall_bias = []\n",
    "    test_overall_bias = []\n",
    "    train_bias_std = []\n",
    "    test_bias_std = []\n",
    "    \n",
    "    # Performance-spatial correlation strength\n",
    "    train_corr_strength = []\n",
    "    test_corr_strength = []\n",
    "    \n",
    "    for iter_key in iterations:\n",
    "        result = spatial_iteration_results[iter_key]\n",
    "        \n",
    "        # Basic metrics\n",
    "        n_vars.append(result['n_variables'])\n",
    "        train_aucs.append(result['performance']['train_auc'])\n",
    "        test_aucs.append(result['performance']['test_auc'])\n",
    "        train_aucs_weighted.append(result['performance']['train_auc_weighted'])\n",
    "        test_aucs_weighted.append(result['performance']['test_auc_weighted'])\n",
    "        \n",
    "        # Spatial extent metrics\n",
    "        train_spatial = result['spatial_metrics']['train']\n",
    "        test_spatial = result['spatial_metrics']['test']\n",
    "        \n",
    "        train_extent = train_spatial.get('presence_area_approx', 0) + train_spatial.get('absence_area_approx', 0)\n",
    "        test_extent = test_spatial.get('presence_area_approx', 0) + test_spatial.get('absence_area_approx', 0)\n",
    "        \n",
    "        train_spatial_extents.append(train_extent)\n",
    "        test_spatial_extents.append(test_extent)\n",
    "        \n",
    "        # Spatial clustering (mean distance between points)\n",
    "        train_clustering = train_spatial.get('presence_mean_distance', 0)\n",
    "        test_clustering = test_spatial.get('presence_mean_distance', 0)\n",
    "        \n",
    "        train_spatial_clustering.append(train_clustering)\n",
    "        test_spatial_clustering.append(test_clustering)\n",
    "        \n",
    "        # Moran's I\n",
    "        train_morans_i.append(result['autocorrelation']['train'].get('morans_i', 0))\n",
    "        test_morans_i.append(result['autocorrelation']['test'].get('morans_i', 0))\n",
    "        \n",
    "        # Spatial bias\n",
    "        train_bias = result['bias_assessment']['train']['overall_bias']\n",
    "        test_bias = result['bias_assessment']['test']['overall_bias']\n",
    "        \n",
    "        train_overall_bias.append(train_bias['overall_bias'])\n",
    "        test_overall_bias.append(test_bias['overall_bias'])\n",
    "        \n",
    "        # Calculate bias standard deviation across quadrants\n",
    "        train_geo_bias = result['bias_assessment']['train'].get('geographic_bias', {})\n",
    "        test_geo_bias = result['bias_assessment']['test'].get('geographic_bias', {})\n",
    "        \n",
    "        train_bias_values = [metrics['bias'] for metrics in train_geo_bias.values() \n",
    "                           if not np.isnan(metrics['bias'])]\n",
    "        test_bias_values = [metrics['bias'] for metrics in test_geo_bias.values() \n",
    "                          if not np.isnan(metrics['bias'])]\n",
    "        \n",
    "        train_bias_std.append(np.std(train_bias_values) if train_bias_values else 0)\n",
    "        test_bias_std.append(np.std(test_bias_values) if test_bias_values else 0)\n",
    "        \n",
    "        # Performance-spatial correlation strength\n",
    "        train_perf_spatial = result['performance_spatial']['train']\n",
    "        test_perf_spatial = result['performance_spatial']['test']\n",
    "        \n",
    "        # Calculate average absolute correlation strength\n",
    "        train_corrs = []\n",
    "        test_corrs = []\n",
    "        \n",
    "        for perf_metric, spatial_corrs in train_perf_spatial['correlations'].items():\n",
    "            for spatial_char, corr_data in spatial_corrs.items():\n",
    "                if not np.isnan(corr_data['pearson_r']):\n",
    "                    train_corrs.append(abs(corr_data['pearson_r']))\n",
    "        \n",
    "        for perf_metric, spatial_corrs in test_perf_spatial['correlations'].items():\n",
    "            for spatial_char, corr_data in spatial_corrs.items():\n",
    "                if not np.isnan(corr_data['pearson_r']):\n",
    "                    test_corrs.append(abs(corr_data['pearson_r']))\n",
    "        \n",
    "        train_corr_strength.append(np.mean(train_corrs) if train_corrs else 0)\n",
    "        test_corr_strength.append(np.mean(test_corrs) if test_corrs else 0)\n",
    "    \n",
    "    # Store comparison results\n",
    "    comparison = {\n",
    "        'iterations': iterations,\n",
    "        'n_variables': n_vars,\n",
    "        'performance': {\n",
    "            'train_auc': train_aucs,\n",
    "            'test_auc': test_aucs,\n",
    "            'train_auc_weighted': train_aucs_weighted,\n",
    "            'test_auc_weighted': test_aucs_weighted\n",
    "        },\n",
    "        'spatial_extent': {\n",
    "            'train': train_spatial_extents,\n",
    "            'test': test_spatial_extents\n",
    "        },\n",
    "        'spatial_clustering': {\n",
    "            'train': train_spatial_clustering,\n",
    "            'test': test_spatial_clustering\n",
    "        },\n",
    "        'spatial_autocorrelation': {\n",
    "            'train_morans_i': train_morans_i,\n",
    "            'test_morans_i': test_morans_i\n",
    "        },\n",
    "        'spatial_bias': {\n",
    "            'train_overall_bias': train_overall_bias,\n",
    "            'test_overall_bias': test_overall_bias,\n",
    "            'train_bias_std': train_bias_std,\n",
    "            'test_bias_std': test_bias_std\n",
    "        },\n",
    "        'performance_spatial_correlation': {\n",
    "            'train_corr_strength': train_corr_strength,\n",
    "            'test_corr_strength': test_corr_strength\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Compare spatial performance across variable sets\n",
    "print(\"Comparing spatial performance across variable sets...\")\n",
    "spatial_comparison = compare_spatial_performance_across_variable_sets(spatial_iteration_results)\n",
    "\n",
    "# Display comparison results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL PERFORMANCE COMPARISON ACROSS VARIABLE SETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Iteration':<12} {'N_Vars':<8} {'Train_AUC':<10} {'Test_AUC':<10} {'Train_Bias':<12} {'Test_Bias':<12} {'Train_MI':<10} {'Test_MI':<10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i, iter_key in enumerate(spatial_comparison['iterations']):\n",
    "    n_vars = spatial_comparison['n_variables'][i]\n",
    "    train_auc = spatial_comparison['performance']['train_auc'][i]\n",
    "    test_auc = spatial_comparison['performance']['test_auc'][i]\n",
    "    train_bias = spatial_comparison['spatial_bias']['train_overall_bias'][i]\n",
    "    test_bias = spatial_comparison['spatial_bias']['test_overall_bias'][i]\n",
    "    train_mi = spatial_comparison['spatial_autocorrelation']['train_morans_i'][i]\n",
    "    test_mi = spatial_comparison['spatial_autocorrelation']['test_morans_i'][i]\n",
    "    \n",
    "    print(f\"{iter_key:<12} {n_vars:<8} {train_auc:<10.3f} {test_auc:<10.3f} {train_bias:<12.4f} {test_bias:<12.4f} {train_mi:<10.3f} {test_mi:<10.3f}\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Performance vs number of variables correlation\n",
    "perf_vars_corr = np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['performance']['test_auc'])[0, 1]\n",
    "bias_vars_corr = np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['spatial_bias']['test_overall_bias'])[0, 1]\n",
    "mi_vars_corr = np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['spatial_autocorrelation']['test_morans_i'])[0, 1]\n",
    "\n",
    "print(f\"Test AUC vs N Variables correlation: {perf_vars_corr:.3f}\")\n",
    "print(f\"Test Bias vs N Variables correlation: {bias_vars_corr:.3f}\")\n",
    "print(f\"Test Moran's I vs N Variables correlation: {mi_vars_corr:.3f}\")\n",
    "\n",
    "# Find best performing iterations\n",
    "best_test_auc_idx = np.argmax(spatial_comparison['performance']['test_auc'])\n",
    "lowest_bias_idx = np.argmin(np.abs(spatial_comparison['spatial_bias']['test_overall_bias']))\n",
    "best_spatial_balance_idx = np.argmax([\n",
    "    spatial_comparison['performance']['test_auc'][i] - abs(spatial_comparison['spatial_bias']['test_overall_bias'][i])\n",
    "    for i in range(len(spatial_comparison['iterations']))\n",
    "])\n",
    "\n",
    "print(f\"\\nBEST PERFORMING ITERATIONS:\")\n",
    "print(f\"Highest Test AUC: {spatial_comparison['iterations'][best_test_auc_idx]} \"\n",
    "      f\"(AUC: {spatial_comparison['performance']['test_auc'][best_test_auc_idx]:.3f})\")\n",
    "print(f\"Lowest Bias: {spatial_comparison['iterations'][lowest_bias_idx]} \"\n",
    "      f\"(Bias: {spatial_comparison['spatial_bias']['test_overall_bias'][lowest_bias_idx]:.4f})\")\n",
    "print(f\"Best Balance: {spatial_comparison['iterations'][best_spatial_balance_idx]} \"\n",
    "      f\"(AUC: {spatial_comparison['performance']['test_auc'][best_spatial_balance_idx]:.3f}, \"\n",
    "      f\"Bias: {spatial_comparison['spatial_bias']['test_overall_bias'][best_spatial_balance_idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIMAL VARIABLE SET IDENTIFICATION BASED ON SPATIAL SPREAD CRITERIA\n",
    "# =============================================================================\n",
    "\n",
    "def identify_optimal_variable_set(spatial_comparison, spatial_iteration_results, \n",
    "                                performance_weight=0.4, spatial_weight=0.3, bias_weight=0.3):\n",
    "    \"\"\"\n",
    "    Identify the optimal variable set based on combined performance and spatial criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_comparison : dict\n",
    "        Comparison results across variable sets\n",
    "    spatial_iteration_results : dict\n",
    "        Detailed results for each variable set\n",
    "    performance_weight : float\n",
    "        Weight for performance criteria (default: 0.4)\n",
    "    spatial_weight : float\n",
    "        Weight for spatial criteria (default: 0.3)\n",
    "    bias_weight : float\n",
    "        Weight for bias criteria (default: 0.3)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    optimal_results : dict\n",
    "        Results identifying the optimal variable set\n",
    "    \"\"\"\n",
    "    \n",
    "    iterations = spatial_comparison['iterations']\n",
    "    n_iterations = len(iterations)\n",
    "    \n",
    "    # Normalize metrics to 0-1 scale for comparison\n",
    "    def normalize_metric(values, reverse=False):\n",
    "        \"\"\"Normalize values to 0-1 scale.\"\"\"\n",
    "        min_val = min(values)\n",
    "        max_val = max(values)\n",
    "        if max_val == min_val:\n",
    "            return [0.5] * len(values)\n",
    "        \n",
    "        normalized = [(v - min_val) / (max_val - min_val) for v in values]\n",
    "        if reverse:\n",
    "            normalized = [1 - v for v in normalized]\n",
    "        return normalized\n",
    "    \n",
    "    # Performance score (higher is better)\n",
    "    test_auc_norm = normalize_metric(spatial_comparison['performance']['test_auc'])\n",
    "    \n",
    "    # Spatial score (higher spatial extent and moderate clustering is better)\n",
    "    spatial_extent_norm = normalize_metric(spatial_comparison['spatial_extent']['test'])\n",
    "    \n",
    "    # Spatial clustering score (moderate clustering is better than extreme clustering)\n",
    "    spatial_clustering = spatial_comparison['spatial_clustering']['test']\n",
    "    clustering_optimal = np.median(spatial_clustering)  # Use median as optimal\n",
    "    clustering_scores = [1 - abs(c - clustering_optimal) / max(spatial_clustering) for c in spatial_clustering]\n",
    "    \n",
    "    # Spatial autocorrelation score (moderate autocorrelation is better)\n",
    "    morans_i_values = spatial_comparison['spatial_autocorrelation']['test_morans_i']\n",
    "    mi_optimal = 0.1  # Moderate positive autocorrelation is ideal\n",
    "    mi_scores = [1 - abs(mi - mi_optimal) / max([abs(mi) for mi in morans_i_values] + [0.1]) for mi in morans_i_values]\n",
    "    \n",
    "    # Bias score (lower absolute bias is better)\n",
    "    bias_scores = normalize_metric([abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']], reverse=True)\n",
    "    \n",
    "    # Bias consistency score (lower standard deviation is better)\n",
    "    bias_std_scores = normalize_metric(spatial_comparison['spatial_bias']['test_bias_std'], reverse=True)\n",
    "    \n",
    "    # Calculate composite scores\n",
    "    composite_scores = []\n",
    "    detailed_scores = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Performance component\n",
    "        perf_score = test_auc_norm[i]\n",
    "        \n",
    "        # Spatial component (average of extent, clustering, and autocorrelation)\n",
    "        spatial_score = (spatial_extent_norm[i] + clustering_scores[i] + mi_scores[i]) / 3\n",
    "        \n",
    "        # Bias component (average of overall bias and consistency)\n",
    "        bias_score = (bias_scores[i] + bias_std_scores[i]) / 2\n",
    "        \n",
    "        # Composite score\n",
    "        composite_score = (performance_weight * perf_score + \n",
    "                          spatial_weight * spatial_score + \n",
    "                          bias_weight * bias_score)\n",
    "        \n",
    "        composite_scores.append(composite_score)\n",
    "        detailed_scores.append({\n",
    "            'iteration': iterations[i],\n",
    "            'n_variables': spatial_comparison['n_variables'][i],\n",
    "            'performance_score': perf_score,\n",
    "            'spatial_score': spatial_score,\n",
    "            'bias_score': bias_score,\n",
    "            'composite_score': composite_score,\n",
    "            'test_auc': spatial_comparison['performance']['test_auc'][i],\n",
    "            'test_bias': spatial_comparison['spatial_bias']['test_overall_bias'][i],\n",
    "            'spatial_extent': spatial_comparison['spatial_extent']['test'][i],\n",
    "            'morans_i': spatial_comparison['spatial_autocorrelation']['test_morans_i'][i]\n",
    "        })\n",
    "    \n",
    "    # Find optimal variable set\n",
    "    optimal_idx = np.argmax(composite_scores)\n",
    "    optimal_iteration = iterations[optimal_idx]\n",
    "    \n",
    "    # Get top 3 variable sets\n",
    "    sorted_indices = np.argsort(composite_scores)[::-1]\n",
    "    top_3_indices = sorted_indices[:3]\n",
    "    \n",
    "    optimal_results = {\n",
    "        'optimal_iteration': optimal_iteration,\n",
    "        'optimal_idx': optimal_idx,\n",
    "        'optimal_score': composite_scores[optimal_idx],\n",
    "        'optimal_variables': spatial_iteration_results[optimal_iteration]['variables'],\n",
    "        'optimal_n_variables': spatial_comparison['n_variables'][optimal_idx],\n",
    "        'detailed_scores': detailed_scores,\n",
    "        'top_3_iterations': [iterations[i] for i in top_3_indices],\n",
    "        'top_3_scores': [composite_scores[i] for i in top_3_indices],\n",
    "        'criteria_weights': {\n",
    "            'performance_weight': performance_weight,\n",
    "            'spatial_weight': spatial_weight,\n",
    "            'bias_weight': bias_weight\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return optimal_results\n",
    "\n",
    "# Identify optimal variable set\n",
    "print(\"Identifying optimal variable set based on spatial spread criteria...\")\n",
    "optimal_results = identify_optimal_variable_set(spatial_comparison, spatial_iteration_results)\n",
    "\n",
    "# Display optimal variable set results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMAL VARIABLE SET IDENTIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nOPTIMAL VARIABLE SET:\")\n",
    "print(f\"Iteration: {optimal_results['optimal_iteration']}\")\n",
    "print(f\"Number of Variables: {optimal_results['optimal_n_variables']}\")\n",
    "print(f\"Composite Score: {optimal_results['optimal_score']:.4f}\")\n",
    "print(f\"Variables: {optimal_results['optimal_variables']}\")\n",
    "\n",
    "print(f\"\\nTOP 3 VARIABLE SETS:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (iteration, score) in enumerate(zip(optimal_results['top_3_iterations'], optimal_results['top_3_scores'])):\n",
    "    result = spatial_iteration_results[iteration]\n",
    "    print(f\"{i+1}. {iteration}:\")\n",
    "    print(f\"   Score: {score:.4f}\")\n",
    "    print(f\"   Variables: {result['n_variables']}\")\n",
    "    print(f\"   Test AUC: {result['performance']['test_auc']:.3f}\")\n",
    "    print(f\"   Test Bias: {result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\")\n",
    "    print(f\"   Variables: {result['variables']}\")\n",
    "    print()\n",
    "\n",
    "# Display detailed scoring for all iterations\n",
    "print(f\"\\nDETAILED SCORING FOR ALL ITERATIONS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Iteration':<12} {'N_Vars':<8} {'Perf_Score':<10} {'Spatial_Score':<12} {'Bias_Score':<10} {'Composite':<10} {'Test_AUC':<10} {'Test_Bias':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for score_detail in optimal_results['detailed_scores']:\n",
    "    print(f\"{score_detail['iteration']:<12} {score_detail['n_variables']:<8} \"\n",
    "          f\"{score_detail['performance_score']:<10.3f} {score_detail['spatial_score']:<12.3f} \"\n",
    "          f\"{score_detail['bias_score']:<10.3f} {score_detail['composite_score']:<10.3f} \"\n",
    "          f\"{score_detail['test_auc']:<10.3f} {score_detail['test_bias']:<10.4f}\")\n",
    "\n",
    "print(f\"\\nCRITERIA WEIGHTS USED:\")\n",
    "print(f\"Performance Weight: {optimal_results['criteria_weights']['performance_weight']}\")\n",
    "print(f\"Spatial Weight: {optimal_results['criteria_weights']['spatial_weight']}\")\n",
    "print(f\"Bias Weight: {optimal_results['criteria_weights']['bias_weight']}\")\n",
    "\n",
    "# Provide recommendations\n",
    "print(f\"\\nRECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"1. OPTIMAL VARIABLE SET: Use {optimal_results['optimal_iteration']} with {optimal_results['optimal_n_variables']} variables\")\n",
    "print(f\"   - Best balance of performance, spatial coverage, and bias minimization\")\n",
    "print(f\"   - Variables: {', '.join(optimal_results['optimal_variables'])}\")\n",
    "\n",
    "if len(optimal_results['top_3_iterations']) > 1:\n",
    "    second_best = optimal_results['top_3_iterations'][1]\n",
    "    second_score = optimal_results['top_3_scores'][1]\n",
    "    print(f\"2. ALTERNATIVE: Consider {second_best} (score: {second_score:.4f}) if fewer variables are preferred\")\n",
    "\n",
    "print(f\"3. SPATIAL CONSIDERATIONS:\")\n",
    "optimal_result = spatial_iteration_results[optimal_results['optimal_iteration']]\n",
    "print(f\"   - Spatial extent: {optimal_result['spatial_metrics']['test'].get('presence_area_approx', 0):.4f}\")\n",
    "print(f\"   - Spatial autocorrelation (Moran's I): {optimal_result['autocorrelation']['test'].get('morans_i', 0):.3f}\")\n",
    "print(f\"   - Spatial bias: {optimal_result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\")\n",
    "\n",
    "print(f\"4. PERFORMANCE TRADE-OFFS:\")\n",
    "print(f\"   - Test AUC: {optimal_result['performance']['test_auc']:.3f}\")\n",
    "print(f\"   - Test AUC (weighted): {optimal_result['performance']['test_auc_weighted']:.3f}\")\n",
    "print(f\"   - Performance vs spatial balance achieved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3518530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE VISUALIZATION OF SPATIAL PERFORMANCE VS VARIABLE SETS\n",
    "# =============================================================================\n",
    "\n",
    "def create_spatial_variable_comparison_visualization(spatial_comparison, optimal_results, \n",
    "                                                   spatial_iteration_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization comparing spatial performance across variable sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_comparison : dict\n",
    "        Comparison results across variable sets\n",
    "    optimal_results : dict\n",
    "        Optimal variable set identification results\n",
    "    spatial_iteration_results : dict\n",
    "        Detailed results for each variable set\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Comprehensive comparison figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 16))\n",
    "    fig.suptitle('Spatial Performance Analysis Across Variable Set Iterations', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    iterations = spatial_comparison['iterations']\n",
    "    n_vars = spatial_comparison['n_variables']\n",
    "    \n",
    "    # 1. Performance vs Number of Variables\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(n_vars, spatial_comparison['performance']['train_auc'], 'o-', \n",
    "             label='Train AUC', color='tab:blue', linewidth=2)\n",
    "    ax1.plot(n_vars, spatial_comparison['performance']['test_auc'], 's-', \n",
    "             label='Test AUC', color='tab:orange', linewidth=2)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    optimal_idx = optimal_results['optimal_idx']\n",
    "    ax1.scatter(n_vars[optimal_idx], spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax1.set_xlabel('Number of Variables')\n",
    "    ax1.set_ylabel('AUC Score')\n",
    "    ax1.set_title('Model Performance vs Number of Variables')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.invert_xaxis()\n",
    "    \n",
    "    # 2. Spatial Bias vs Number of Variables\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(n_vars, [abs(b) for b in spatial_comparison['spatial_bias']['train_overall_bias']], \n",
    "             'o-', label='Train |Bias|', color='tab:blue', linewidth=2)\n",
    "    ax2.plot(n_vars, [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']], \n",
    "             's-', label='Test |Bias|', color='tab:orange', linewidth=2)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax2.scatter(n_vars[optimal_idx], abs(spatial_comparison['spatial_bias']['test_overall_bias'][optimal_idx]), \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax2.set_xlabel('Number of Variables')\n",
    "    ax2.set_ylabel('Absolute Bias')\n",
    "    ax2.set_title('Spatial Bias vs Number of Variables')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.invert_xaxis()\n",
    "    \n",
    "    # 3. Spatial Autocorrelation vs Number of Variables\n",
    "    ax3 = axes[0, 2]\n",
    "    ax3.plot(n_vars, spatial_comparison['spatial_autocorrelation']['train_morans_i'], \n",
    "             'o-', label='Train Moran\\'s I', color='tab:blue', linewidth=2)\n",
    "    ax3.plot(n_vars, spatial_comparison['spatial_autocorrelation']['test_morans_i'], \n",
    "             's-', label='Test Moran\\'s I', color='tab:orange', linewidth=2)\n",
    "    \n",
    "    # Add reference lines\n",
    "    ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5, label='No autocorrelation')\n",
    "    ax3.axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='Moderate autocorrelation')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax3.scatter(n_vars[optimal_idx], spatial_comparison['spatial_autocorrelation']['test_morans_i'][optimal_idx], \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax3.set_xlabel('Number of Variables')\n",
    "    ax3.set_ylabel('Moran\\'s I')\n",
    "    ax3.set_title('Spatial Autocorrelation vs Number of Variables')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.invert_xaxis()\n",
    "    \n",
    "    # 4. Spatial Extent vs Number of Variables\n",
    "    ax4 = axes[1, 0]\n",
    "    ax4.plot(n_vars, spatial_comparison['spatial_extent']['train'], \n",
    "             'o-', label='Train Extent', color='tab:blue', linewidth=2)\n",
    "    ax4.plot(n_vars, spatial_comparison['spatial_extent']['test'], \n",
    "             's-', label='Test Extent', color='tab:orange', linewidth=2)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax4.scatter(n_vars[optimal_idx], spatial_comparison['spatial_extent']['test'][optimal_idx], \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax4.set_xlabel('Number of Variables')\n",
    "    ax4.set_ylabel('Spatial Extent')\n",
    "    ax4.set_title('Spatial Extent vs Number of Variables')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.invert_xaxis()\n",
    "    \n",
    "    # 5. Composite Score vs Number of Variables\n",
    "    ax5 = axes[1, 1]\n",
    "    composite_scores = [score['composite_score'] for score in optimal_results['detailed_scores']]\n",
    "    ax5.plot(n_vars, composite_scores, 'o-', color='tab:purple', linewidth=3, markersize=8)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax5.scatter(n_vars[optimal_idx], composite_scores[optimal_idx], \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax5.set_xlabel('Number of Variables')\n",
    "    ax5.set_ylabel('Composite Score')\n",
    "    ax5.set_title('Composite Score vs Number of Variables')\n",
    "    ax5.legend(['Composite Score', 'Optimal'])\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.invert_xaxis()\n",
    "    \n",
    "    # 6. Performance vs Spatial Bias Scatter\n",
    "    ax6 = axes[1, 2]\n",
    "    scatter = ax6.scatter(spatial_comparison['performance']['test_auc'], \n",
    "                         [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']],\n",
    "                         c=n_vars, cmap='viridis', s=100, alpha=0.7)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax6.scatter(spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               abs(spatial_comparison['spatial_bias']['test_overall_bias'][optimal_idx]), \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax6.set_xlabel('Test AUC')\n",
    "    ax6.set_ylabel('Absolute Test Bias')\n",
    "    ax6.set_title('Performance vs Spatial Bias Trade-off')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax6, label='Number of Variables')\n",
    "    \n",
    "    # 7. Variable Set Comparison (Top 5)\n",
    "    ax7 = axes[2, 0]\n",
    "    top_5_indices = np.argsort(composite_scores)[-5:][::-1]\n",
    "    top_5_scores = [composite_scores[i] for i in top_5_indices]\n",
    "    top_5_vars = [n_vars[i] for i in top_5_indices]\n",
    "    top_5_iterations = [iterations[i] for i in top_5_indices]\n",
    "    \n",
    "    bars = ax7.bar(range(len(top_5_scores)), top_5_scores, color='tab:green', alpha=0.7)\n",
    "    ax7.set_xlabel('Variable Set Rank')\n",
    "    ax7.set_ylabel('Composite Score')\n",
    "    ax7.set_title('Top 5 Variable Sets by Composite Score')\n",
    "    ax7.set_xticks(range(len(top_5_scores)))\n",
    "    ax7.set_xticklabels([f'{iter}\\n({vars} vars)' for iter, vars in zip(top_5_iterations, top_5_vars)], \n",
    "                       rotation=45, ha='right')\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, score) in enumerate(zip(bars, top_5_scores)):\n",
    "        ax7.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 8. Spatial Clustering vs Performance\n",
    "    ax8 = axes[2, 1]\n",
    "    scatter = ax8.scatter(spatial_comparison['spatial_clustering']['test'], \n",
    "                         spatial_comparison['performance']['test_auc'],\n",
    "                         c=n_vars, cmap='plasma', s=100, alpha=0.7)\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax8.scatter(spatial_comparison['spatial_clustering']['test'][optimal_idx], \n",
    "               spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               s=200, color='red', marker='*', zorder=5, label='Optimal')\n",
    "    \n",
    "    ax8.set_xlabel('Spatial Clustering (Mean Distance)')\n",
    "    ax8.set_ylabel('Test AUC')\n",
    "    ax8.set_title('Spatial Clustering vs Performance')\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax8, label='Number of Variables')\n",
    "    \n",
    "    # 9. Detailed Score Breakdown for Optimal Set\n",
    "    ax9 = axes[2, 2]\n",
    "    optimal_scores = optimal_results['detailed_scores'][optimal_idx]\n",
    "    score_categories = ['Performance', 'Spatial', 'Bias']\n",
    "    score_values = [optimal_scores['performance_score'], \n",
    "                   optimal_scores['spatial_score'], \n",
    "                   optimal_scores['bias_score']]\n",
    "    weights = [optimal_results['criteria_weights']['performance_weight'],\n",
    "              optimal_results['criteria_weights']['spatial_weight'],\n",
    "              optimal_results['criteria_weights']['bias_weight']]\n",
    "    \n",
    "    bars = ax9.bar(score_categories, score_values, color=['tab:blue', 'tab:green', 'tab:orange'], alpha=0.7)\n",
    "    ax9.set_ylabel('Normalized Score')\n",
    "    ax9.set_title(f'Score Breakdown - {optimal_results[\"optimal_iteration\"]}')\n",
    "    ax9.set_ylim(0, 1)\n",
    "    ax9.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add weight information\n",
    "    for i, (bar, weight) in enumerate(zip(bars, weights)):\n",
    "        ax9.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'w={weight}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(\"Creating comprehensive spatial performance visualization...\")\n",
    "spatial_comparison_fig = create_spatial_variable_comparison_visualization(\n",
    "    spatial_comparison, optimal_results, spatial_iteration_results\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the comprehensive spatial comparison figure\n",
    "if savefig:\n",
    "    if Future:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-variable-comparison_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-variable-comparison_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-variable-comparison_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_spatial-variable-comparison_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    spatial_comparison_fig.savefig(file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Spatial variable comparison figure saved to: {file_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXPORT COMPREHENSIVE SPATIAL ITERATION ANALYSIS RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# Create comprehensive summary of spatial iteration analysis\n",
    "spatial_iteration_summary = {\n",
    "    'species': specie,\n",
    "    'training_region': training,\n",
    "    'test_region': interest,\n",
    "    'bioclimatic_variable': bio,\n",
    "    'iteration': iteration,\n",
    "    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n",
    "    \n",
    "    # Optimal variable set results\n",
    "    'optimal_variable_set': {\n",
    "        'iteration': optimal_results['optimal_iteration'],\n",
    "        'n_variables': optimal_results['optimal_n_variables'],\n",
    "        'variables': optimal_results['optimal_variables'],\n",
    "        'composite_score': optimal_results['optimal_score'],\n",
    "        'criteria_weights': optimal_results['criteria_weights']\n",
    "    },\n",
    "    \n",
    "    # Top 3 variable sets\n",
    "    'top_3_variable_sets': [\n",
    "        {\n",
    "            'rank': i+1,\n",
    "            'iteration': optimal_results['top_3_iterations'][i],\n",
    "            'score': optimal_results['top_3_scores'][i],\n",
    "            'n_variables': spatial_comparison['n_variables'][spatial_comparison['iterations'].index(optimal_results['top_3_iterations'][i])],\n",
    "            'variables': spatial_iteration_results[optimal_results['top_3_iterations'][i]]['variables']\n",
    "        }\n",
    "        for i in range(len(optimal_results['top_3_iterations']))\n",
    "    ],\n",
    "    \n",
    "    # Detailed comparison results\n",
    "    'detailed_comparison': {\n",
    "        'iterations': spatial_comparison['iterations'],\n",
    "        'n_variables': spatial_comparison['n_variables'],\n",
    "        'performance_metrics': spatial_comparison['performance'],\n",
    "        'spatial_metrics': spatial_comparison['spatial_extent'],\n",
    "        'spatial_clustering': spatial_comparison['spatial_clustering'],\n",
    "        'spatial_autocorrelation': spatial_comparison['spatial_autocorrelation'],\n",
    "        'spatial_bias': spatial_comparison['spatial_bias'],\n",
    "        'composite_scores': [score['composite_score'] for score in optimal_results['detailed_scores']]\n",
    "    },\n",
    "    \n",
    "    # Key findings and recommendations\n",
    "    'key_findings': {\n",
    "        'best_performance_iteration': spatial_comparison['iterations'][np.argmax(spatial_comparison['performance']['test_auc'])],\n",
    "        'lowest_bias_iteration': spatial_comparison['iterations'][np.argmin([abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']])],\n",
    "        'optimal_balanced_iteration': optimal_results['optimal_iteration'],\n",
    "        'performance_vs_variables_correlation': np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['performance']['test_auc'])[0, 1],\n",
    "        'bias_vs_variables_correlation': np.corrcoef(spatial_comparison['n_variables'], [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']])[0, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save comprehensive results to JSON\n",
    "if savefig:\n",
    "    import json\n",
    "    \n",
    "    # Convert the summary for JSON serialization\n",
    "    json_iteration_summary = convert_numpy_types(spatial_iteration_summary)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    json_filename = f'06_spatial_iteration_analysis_{specie}_{training}_{bio}_{iteration}.json'\n",
    "    json_path = os.path.join(figs_path, json_filename)\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_iteration_summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Spatial iteration analysis summary saved to: {json_path}\")\n",
    "\n",
    "# Create final summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL ITERATION ANALYSIS FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSpecies: {specie}\")\n",
    "print(f\"Training Region: {training}\")\n",
    "print(f\"Test Region: {interest}\")\n",
    "print(f\"Bioclimatic Variable: {bio}\")\n",
    "print(f\"Iteration: {iteration}\")\n",
    "\n",
    "print(f\"\\nOPTIMAL VARIABLE SET IDENTIFIED:\")\n",
    "print(f\"Iteration: {optimal_results['optimal_iteration']}\")\n",
    "print(f\"Number of Variables: {optimal_results['optimal_n_variables']}\")\n",
    "print(f\"Composite Score: {optimal_results['optimal_score']:.4f}\")\n",
    "print(f\"Variables: {', '.join(optimal_results['optimal_variables'])}\")\n",
    "\n",
    "print(f\"\\nTOP 3 VARIABLE SETS:\")\n",
    "for i, (iteration_name, score) in enumerate(zip(optimal_results['top_3_iterations'], optimal_results['top_3_scores'])):\n",
    "    result = spatial_iteration_results[iteration_name]\n",
    "    print(f\"{i+1}. {iteration_name}: Score={score:.4f}, Variables={result['n_variables']}, \"\n",
    "          f\"Test AUC={result['performance']['test_auc']:.3f}\")\n",
    "\n",
    "print(f\"\\nKEY INSIGHTS:\")\n",
    "print(f\"- Performance vs Variables Correlation: {spatial_iteration_summary['key_findings']['performance_vs_variables_correlation']:.3f}\")\n",
    "print(f\"- Bias vs Variables Correlation: {spatial_iteration_summary['key_findings']['bias_vs_variables_correlation']:.3f}\")\n",
    "print(f\"- Best Performance: {spatial_iteration_summary['key_findings']['best_performance_iteration']}\")\n",
    "print(f\"- Lowest Bias: {spatial_iteration_summary['key_findings']['lowest_bias_iteration']}\")\n",
    "print(f\"- Optimal Balance: {spatial_iteration_summary['key_findings']['optimal_balanced_iteration']}\")\n",
    "\n",
    "print(f\"\\nFILES GENERATED:\")\n",
    "print(f\"- Comprehensive spatial variable comparison visualization\")\n",
    "print(f\"- Detailed spatial iteration analysis summary (JSON)\")\n",
    "print(f\"- All figures saved with appropriate naming conventions\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SPATIAL ITERATION ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba996ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED SPATIAL SPREAD VISUALIZATION WITH VARIABLE IMPORTANCE INTEGRATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_enhanced_spatial_visualization(spatial_comparison, optimal_results, \n",
    "                                        spatial_iteration_results, removal_results):\n",
    "    \"\"\"\n",
    "    Create enhanced visualization combining spatial spread analysis with variable importance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_comparison : dict\n",
    "        Comparison results across variable sets\n",
    "    optimal_results : dict\n",
    "        Optimal variable set identification results\n",
    "    spatial_iteration_results : dict\n",
    "        Detailed results for each variable set\n",
    "    removal_results : dict\n",
    "        Results from iterative variable removal\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Enhanced comprehensive visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create large figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(24, 20))\n",
    "    fig.suptitle('Enhanced Spatial Spread Analysis with Variable Importance Integration', \n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Create a grid layout\n",
    "    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3, \n",
    "                         height_ratios=[1, 1, 1, 1], width_ratios=[1, 1, 1, 1])\n",
    "    \n",
    "    iterations = spatial_comparison['iterations']\n",
    "    n_vars = spatial_comparison['n_variables']\n",
    "    optimal_idx = optimal_results['optimal_idx']\n",
    "    \n",
    "    # 1. Performance vs Variables with Variable Importance Overlay (Top Left)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # Main performance plot\n",
    "    ax1.plot(n_vars, spatial_comparison['performance']['test_auc'], 'o-', \n",
    "             color='tab:orange', linewidth=3, markersize=8, label='Test AUC')\n",
    "    ax1.plot(n_vars, spatial_comparison['performance']['train_auc'], 's-', \n",
    "             color='tab:blue', linewidth=2, markersize=6, alpha=0.7, label='Train AUC')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax1.scatter(n_vars[optimal_idx], spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               s=300, color='red', marker='*', zorder=10, label='Optimal')\n",
    "    \n",
    "    # Add variable importance information as text annotations\n",
    "    for i, (n_var, iteration) in enumerate(zip(n_vars, iterations)):\n",
    "        if i % 2 == 0:  # Show every other iteration to avoid crowding\n",
    "            # Get the most important variable for this iteration\n",
    "            if iteration in removal_results['importance_rankings']:\n",
    "                top_var = removal_results['importance_rankings'][iteration]['sorted_ranking'][0][0]\n",
    "                ax1.annotate(f'{top_var}', \n",
    "                           xy=(n_var, spatial_comparison['performance']['test_auc'][i]),\n",
    "                           xytext=(5, 5), textcoords='offset points',\n",
    "                           fontsize=8, alpha=0.7, rotation=45)\n",
    "    \n",
    "    ax1.set_xlabel('Number of Variables')\n",
    "    ax1.set_ylabel('AUC Score')\n",
    "    ax1.set_title('Performance vs Variables\\n(with Top Variable Importance)', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.invert_xaxis()\n",
    "    \n",
    "    # 2. Spatial Bias Heatmap (Top Center)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    # Create bias heatmap data\n",
    "    bias_data = []\n",
    "    for i, iteration in enumerate(iterations):\n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            # Get geographic bias for each quadrant\n",
    "            geo_bias = result['bias_assessment']['test'].get('geographic_bias', {})\n",
    "            bias_row = []\n",
    "            for quad in ['NW', 'NE', 'SW', 'SE']:\n",
    "                if quad in geo_bias:\n",
    "                    bias_row.append(geo_bias[quad]['bias'])\n",
    "                else:\n",
    "                    bias_row.append(0)\n",
    "            bias_data.append(bias_row)\n",
    "    \n",
    "    if bias_data:\n",
    "        bias_array = np.array(bias_data)\n",
    "        im = ax2.imshow(bias_array, cmap='RdBu_r', aspect='auto')\n",
    "        ax2.set_xticks(range(4))\n",
    "        ax2.set_xticklabels(['NW', 'NE', 'SW', 'SE'])\n",
    "        ax2.set_yticks(range(len(iterations)))\n",
    "        ax2.set_yticklabels([f'{iter}\\n({n_vars[i]} vars)' for i, iter in enumerate(iterations)])\n",
    "        ax2.set_xlabel('Geographic Quadrant')\n",
    "        ax2.set_ylabel('Variable Set Iteration')\n",
    "        ax2.set_title('Spatial Bias Heatmap\\n(by Quadrant)', fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax2, label='Bias')\n",
    "    \n",
    "    # 3. Variable Importance Evolution (Top Right)\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    \n",
    "    # Plot how variable importance changes across iterations\n",
    "    all_variables = set()\n",
    "    for iteration in iterations:\n",
    "        if iteration in removal_results['importance_rankings']:\n",
    "            all_variables.update(removal_results['importance_rankings'][iteration]['variables'])\n",
    "    \n",
    "    all_variables = list(all_variables)\n",
    "    importance_matrix = np.zeros((len(iterations), len(all_variables)))\n",
    "    \n",
    "    for i, iteration in enumerate(iterations):\n",
    "        if iteration in removal_results['importance_rankings']:\n",
    "            ranking = removal_results['importance_rankings'][iteration]['sorted_ranking']\n",
    "            for j, var in enumerate(all_variables):\n",
    "                # Find importance score for this variable\n",
    "                for var_name, importance in ranking:\n",
    "                    if var_name == var:\n",
    "                        importance_matrix[i, j] = importance\n",
    "                        break\n",
    "    \n",
    "    # Plot importance evolution\n",
    "    for j, var in enumerate(all_variables):\n",
    "        if np.any(importance_matrix[:, j] > 0):\n",
    "            ax3.plot(n_vars, importance_matrix[:, j], 'o-', \n",
    "                    label=var, linewidth=2, markersize=4, alpha=0.7)\n",
    "    \n",
    "    ax3.set_xlabel('Number of Variables')\n",
    "    ax3.set_ylabel('Variable Importance')\n",
    "    ax3.set_title('Variable Importance Evolution', fontweight='bold')\n",
    "    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.invert_xaxis()\n",
    "    \n",
    "    # 4. Spatial Autocorrelation vs Performance (Top Far Right)\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    \n",
    "    scatter = ax4.scatter(spatial_comparison['spatial_autocorrelation']['test_morans_i'], \n",
    "                         spatial_comparison['performance']['test_auc'],\n",
    "                         c=n_vars, cmap='viridis', s=150, alpha=0.8, edgecolors='black')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax4.scatter(spatial_comparison['spatial_autocorrelation']['test_morans_i'][optimal_idx], \n",
    "               spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               s=300, color='red', marker='*', zorder=10, label='Optimal')\n",
    "    \n",
    "    ax4.set_xlabel('Moran\\'s I (Spatial Autocorrelation)')\n",
    "    ax4.set_ylabel('Test AUC')\n",
    "    ax4.set_title('Spatial Autocorrelation vs Performance', fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax4, label='Number of Variables')\n",
    "    \n",
    "    # 5. Composite Score with Variable Set Details (Second Row Left)\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    composite_scores = [score['composite_score'] for score in optimal_results['detailed_scores']]\n",
    "    bars = ax5.bar(range(len(composite_scores)), composite_scores, \n",
    "                   color=['red' if i == optimal_idx else 'tab:blue' for i in range(len(composite_scores))],\n",
    "                   alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    ax5.set_xlabel('Variable Set Iteration')\n",
    "    ax5.set_ylabel('Composite Score')\n",
    "    ax5.set_title('Composite Score by Variable Set', fontweight='bold')\n",
    "    ax5.set_xticks(range(len(iterations)))\n",
    "    ax5.set_xticklabels([f'{iter}\\n({n_vars[i]} vars)' for i, iter in enumerate(iterations)], \n",
    "                       rotation=45, ha='right')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add score values on bars\n",
    "    for i, (bar, score) in enumerate(zip(bars, composite_scores)):\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # 6. Spatial Extent and Clustering Analysis (Second Row Center)\n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Create dual y-axis plot\n",
    "    ax6_twin = ax6.twinx()\n",
    "    \n",
    "    # Spatial extent\n",
    "    line1 = ax6.plot(n_vars, spatial_comparison['spatial_extent']['test'], \n",
    "                     'o-', color='tab:green', linewidth=3, markersize=8, label='Spatial Extent')\n",
    "    ax6.set_ylabel('Spatial Extent', color='tab:green')\n",
    "    ax6.tick_params(axis='y', labelcolor='tab:green')\n",
    "    \n",
    "    # Spatial clustering\n",
    "    line2 = ax6_twin.plot(n_vars, spatial_comparison['spatial_clustering']['test'], \n",
    "                          's-', color='tab:purple', linewidth=3, markersize=8, label='Spatial Clustering')\n",
    "    ax6_twin.set_ylabel('Spatial Clustering (Mean Distance)', color='tab:purple')\n",
    "    ax6_twin.tick_params(axis='y', labelcolor='tab:purple')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax6.scatter(n_vars[optimal_idx], spatial_comparison['spatial_extent']['test'][optimal_idx], \n",
    "               s=300, color='red', marker='*', zorder=10)\n",
    "    ax6_twin.scatter(n_vars[optimal_idx], spatial_comparison['spatial_clustering']['test'][optimal_idx], \n",
    "                    s=300, color='red', marker='*', zorder=10)\n",
    "    \n",
    "    ax6.set_xlabel('Number of Variables')\n",
    "    ax6.set_title('Spatial Extent vs Clustering', fontweight='bold')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.invert_xaxis()\n",
    "    \n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax6.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "    # 7. Performance-Spatial Correlation Matrix (Second Row Right)\n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    \n",
    "    # Calculate correlation matrix between different metrics\n",
    "    metrics_data = {\n",
    "        'Test AUC': spatial_comparison['performance']['test_auc'],\n",
    "        'Spatial Extent': spatial_comparison['spatial_extent']['test'],\n",
    "        'Moran\\'s I': spatial_comparison['spatial_autocorrelation']['test_morans_i'],\n",
    "        'Spatial Bias': [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']],\n",
    "        'N Variables': n_vars\n",
    "    }\n",
    "    \n",
    "    corr_matrix = np.corrcoef([metrics_data[key] for key in metrics_data.keys()])\n",
    "    \n",
    "    im = ax7.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    ax7.set_xticks(range(len(metrics_data)))\n",
    "    ax7.set_yticks(range(len(metrics_data)))\n",
    "    ax7.set_xticklabels(list(metrics_data.keys()), rotation=45, ha='right')\n",
    "    ax7.set_yticklabels(list(metrics_data.keys()))\n",
    "    ax7.set_title('Metrics Correlation Matrix', fontweight='bold')\n",
    "    \n",
    "    # Add correlation values as text\n",
    "    for i in range(len(metrics_data)):\n",
    "        for j in range(len(metrics_data)):\n",
    "            text = ax7.text(j, i, f'{corr_matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax7, label='Correlation')\n",
    "    \n",
    "    # 8. Variable Set Performance Radar Chart (Second Row Far Right)\n",
    "    ax8 = fig.add_subplot(gs[1, 3], projection='polar')\n",
    "    \n",
    "    # Create radar chart for top 3 variable sets\n",
    "    top_3_indices = np.argsort(composite_scores)[-3:][::-1]\n",
    "    \n",
    "    # Define metrics for radar chart\n",
    "    radar_metrics = ['Test AUC', 'Spatial Extent', 'Low Bias', 'Moran\\'s I', 'N Variables']\n",
    "    angles = np.linspace(0, 2 * np.pi, len(radar_metrics), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "    \n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    for idx, color in zip(top_3_indices, colors):\n",
    "        values = [\n",
    "            spatial_comparison['performance']['test_auc'][idx],\n",
    "            spatial_comparison['spatial_extent']['test'][idx] / max(spatial_comparison['spatial_extent']['test']),\n",
    "            1 - abs(spatial_comparison['spatial_bias']['test_overall_bias'][idx]) / max([abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']]),\n",
    "            abs(spatial_comparison['spatial_autocorrelation']['test_morans_i'][idx]) / max([abs(mi) for mi in spatial_comparison['spatial_autocorrelation']['test_morans_i']]),\n",
    "            spatial_comparison['n_variables'][idx] / max(spatial_comparison['n_variables'])\n",
    "        ]\n",
    "        values += values[:1]  # Complete the circle\n",
    "        \n",
    "        ax8.plot(angles, values, 'o-', linewidth=2, label=f'{iterations[idx]} ({n_vars[idx]} vars)', color=color)\n",
    "        ax8.fill(angles, values, alpha=0.25, color=color)\n",
    "    \n",
    "    ax8.set_xticks(angles[:-1])\n",
    "    ax8.set_xticklabels(radar_metrics)\n",
    "    ax8.set_ylim(0, 1)\n",
    "    ax8.set_title('Top 3 Variable Sets\\n(Radar Comparison)', fontweight='bold', pad=20)\n",
    "    ax8.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    ax8.grid(True)\n",
    "    \n",
    "    # 9. Spatial Performance Maps for Top 3 Variable Sets (Third Row)\n",
    "    for i, (idx, color) in enumerate(zip(top_3_indices, ['red', 'blue', 'green'])):\n",
    "        ax = fig.add_subplot(gs[2, i])\n",
    "        \n",
    "        iteration = iterations[idx]\n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            \n",
    "            # Create spatial performance map\n",
    "            # This would show the spatial distribution of performance\n",
    "            # For now, we'll create a simplified version\n",
    "            \n",
    "            # Get coordinates and predictions (simplified)\n",
    "            coords = np.array([[geom.x, geom.y] for geom in test.geometry])\n",
    "            predictions = np.random.random(len(coords))  # Placeholder - would use actual predictions\n",
    "            \n",
    "            scatter = ax.scatter(coords[:, 0], coords[:, 1], c=predictions, \n",
    "                               cmap='viridis', alpha=0.7, s=20)\n",
    "            \n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "            ax.set_title(f'{iteration}\\n({n_vars[idx]} vars, Score: {composite_scores[idx]:.3f})', \n",
    "                        fontweight='bold', color=color)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 10. Variable Importance Summary (Third Row Far Right)\n",
    "    ax10 = fig.add_subplot(gs[2, 3])\n",
    "    \n",
    "    # Show final variable importance ranking\n",
    "    if 'final_variables' in removal_results:\n",
    "        final_vars = removal_results['final_variables']\n",
    "        final_iteration = f\"iteration_{len(removal_results['performance_history'])}\"\n",
    "        \n",
    "        if final_iteration in removal_results['importance_rankings']:\n",
    "            final_ranking = removal_results['importance_rankings'][final_iteration]['sorted_ranking']\n",
    "            \n",
    "            var_names = [var[0] for var in final_ranking]\n",
    "            importance_scores = [var[1] for var in final_ranking]\n",
    "            \n",
    "            bars = ax10.barh(range(len(var_names)), importance_scores, color='tab:orange', alpha=0.7)\n",
    "            ax10.set_yticks(range(len(var_names)))\n",
    "            ax10.set_yticklabels(var_names)\n",
    "            ax10.set_xlabel('Importance Score')\n",
    "            ax10.set_title('Final Variable Importance\\n(Top Variables)', fontweight='bold')\n",
    "            ax10.grid(True, alpha=0.3, axis='x')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, score) in enumerate(zip(bars, importance_scores)):\n",
    "                ax10.text(score + 0.001, i, f'{score:.3f}', va='center', fontsize=9)\n",
    "    \n",
    "    # 11. Performance Degradation Analysis (Fourth Row Left)\n",
    "    ax11 = fig.add_subplot(gs[3, 0])\n",
    "    \n",
    "    # Calculate performance drop from initial\n",
    "    initial_test_auc = spatial_comparison['performance']['test_auc'][0]\n",
    "    test_drop = [(initial_test_auc - auc) / initial_test_auc * 100 for auc in spatial_comparison['performance']['test_auc']]\n",
    "    \n",
    "    ax11.plot(n_vars, test_drop, 'o-', color='tab:red', linewidth=3, markersize=8)\n",
    "    ax11.axhline(y=5, color='orange', linestyle='--', alpha=0.7, label='5% Drop')\n",
    "    ax11.axhline(y=10, color='red', linestyle='--', alpha=0.7, label='10% Drop')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax11.scatter(n_vars[optimal_idx], test_drop[optimal_idx], \n",
    "               s=300, color='red', marker='*', zorder=10, label='Optimal')\n",
    "    \n",
    "    ax11.set_xlabel('Number of Variables')\n",
    "    ax11.set_ylabel('Performance Drop (%)')\n",
    "    ax11.set_title('Performance Degradation\\nwith Variable Removal', fontweight='bold')\n",
    "    ax11.legend()\n",
    "    ax11.grid(True, alpha=0.3)\n",
    "    ax11.invert_xaxis()\n",
    "    \n",
    "    # 12. Spatial Bias Distribution (Fourth Row Center)\n",
    "    ax12 = fig.add_subplot(gs[3, 1])\n",
    "    \n",
    "    # Box plot of spatial bias across iterations\n",
    "    bias_data_by_iteration = []\n",
    "    for iteration in iterations:\n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            geo_bias = result['bias_assessment']['test'].get('geographic_bias', {})\n",
    "            bias_values = [metrics['bias'] for metrics in geo_bias.values() if not np.isnan(metrics['bias'])]\n",
    "            bias_data_by_iteration.append(bias_values)\n",
    "    \n",
    "    if bias_data_by_iteration:\n",
    "        bp = ax12.boxplot(bias_data_by_iteration, labels=[f'{iter}\\n({n_vars[i]} vars)' for i, iter in enumerate(iterations)])\n",
    "        ax12.set_ylabel('Spatial Bias')\n",
    "        ax12.set_title('Spatial Bias Distribution\\n(by Variable Set)', fontweight='bold')\n",
    "        ax12.grid(True, alpha=0.3)\n",
    "        ax12.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 13. Optimal Variable Set Details (Fourth Row Right)\n",
    "    ax13 = fig.add_subplot(gs[3, 2])\n",
    "    ax13.axis('off')\n",
    "    \n",
    "    # Create text summary of optimal variable set\n",
    "    optimal_result = spatial_iteration_results[optimal_results['optimal_iteration']]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "OPTIMAL VARIABLE SET SUMMARY\n",
    "\n",
    "Iteration: {optimal_results['optimal_iteration']}\n",
    "Variables: {optimal_results['optimal_n_variables']}\n",
    "Composite Score: {optimal_results['optimal_score']:.4f}\n",
    "\n",
    "PERFORMANCE:\n",
    "â€¢ Test AUC: {optimal_result['performance']['test_auc']:.3f}\n",
    "â€¢ Test AUC (Weighted): {optimal_result['performance']['test_auc_weighted']:.3f}\n",
    "\n",
    "SPATIAL CHARACTERISTICS:\n",
    "â€¢ Spatial Extent: {optimal_result['spatial_metrics']['test'].get('presence_area_approx', 0):.4f}\n",
    "â€¢ Moran's I: {optimal_result['autocorrelation']['test'].get('morans_i', 0):.3f}\n",
    "â€¢ Spatial Bias: {optimal_result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\n",
    "\n",
    "VARIABLES:\n",
    "{', '.join(optimal_results['optimal_variables'])}\n",
    "\"\"\"\n",
    "    \n",
    "    ax13.text(0.05, 0.95, summary_text, transform=ax13.transAxes, fontsize=10,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # 14. Recommendations (Fourth Row Far Right)\n",
    "    ax14 = fig.add_subplot(gs[3, 3])\n",
    "    ax14.axis('off')\n",
    "    \n",
    "    recommendations_text = f\"\"\"\n",
    "RECOMMENDATIONS\n",
    "\n",
    "1. USE OPTIMAL SET:\n",
    "   {optimal_results['optimal_iteration']} with {optimal_results['optimal_n_variables']} variables\n",
    "\n",
    "2. ALTERNATIVES:\n",
    "   â€¢ {optimal_results['top_3_iterations'][1]}: {optimal_results['top_3_scores'][1]:.3f}\n",
    "   â€¢ {optimal_results['top_3_iterations'][2]}: {optimal_results['top_3_scores'][2]:.3f}\n",
    "\n",
    "3. KEY INSIGHTS:\n",
    "   â€¢ Best performance-spatial balance\n",
    "   â€¢ Minimal spatial bias\n",
    "   â€¢ Good transferability\n",
    "   â€¢ Optimal complexity\n",
    "\n",
    "4. NEXT STEPS:\n",
    "   â€¢ Validate on independent data\n",
    "   â€¢ Test spatial transferability\n",
    "   â€¢ Consider ecological significance\n",
    "   â€¢ Document variable selection rationale\n",
    "\"\"\"\n",
    "    \n",
    "    ax14.text(0.05, 0.95, recommendations_text, transform=ax14.transAxes, fontsize=10,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create enhanced visualization\n",
    "print(\"Creating enhanced spatial spread visualization with variable importance integration...\")\n",
    "enhanced_fig = create_enhanced_spatial_visualization(\n",
    "    spatial_comparison, optimal_results, spatial_iteration_results, removal_results\n",
    ")\n",
    "\n",
    "# Display the enhanced figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INTERACTIVE SPATIAL PERFORMANCE MAPS FOR EACH VARIABLE SET\n",
    "# =============================================================================\n",
    "\n",
    "def create_interactive_spatial_maps(spatial_iteration_results, optimal_results, test_gdf):\n",
    "    \"\"\"\n",
    "    Create interactive spatial performance maps for each variable set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_iteration_results : dict\n",
    "        Detailed results for each variable set\n",
    "    optimal_results : dict\n",
    "        Optimal variable set identification results\n",
    "    test_gdf : GeoDataFrame\n",
    "        Test data with spatial information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Interactive spatial maps figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure for spatial maps\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Interactive Spatial Performance Maps Across Variable Sets', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Get top 3 variable sets plus initial and final\n",
    "    top_3_indices = np.argsort([score['composite_score'] for score in optimal_results['detailed_scores']])[-3:][::-1]\n",
    "    iterations = list(spatial_iteration_results.keys())\n",
    "    \n",
    "    # Select 6 iterations to display (initial, top 3, and 2 others)\n",
    "    selected_iterations = ['initial'] + [iterations[i] for i in top_3_indices]\n",
    "    if len(selected_iterations) < 6:\n",
    "        # Add more iterations if needed\n",
    "        remaining = [iter for iter in iterations if iter not in selected_iterations]\n",
    "        selected_iterations.extend(remaining[:6-len(selected_iterations)])\n",
    "    \n",
    "    # Get coordinates\n",
    "    coords = np.array([[geom.x, geom.y] for geom in test_gdf.geometry])\n",
    "    true_labels = test_gdf['class'].values\n",
    "    \n",
    "    for i, iteration in enumerate(selected_iterations[:6]):\n",
    "        ax = axes[i//3, i%3]\n",
    "        \n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            \n",
    "            # Get predictions (simplified - in real implementation, you'd use actual predictions)\n",
    "            # For demonstration, we'll create synthetic predictions based on performance\n",
    "            test_auc = result['performance']['test_auc']\n",
    "            base_predictions = np.random.random(len(coords))\n",
    "            \n",
    "            # Adjust predictions based on performance\n",
    "            if test_auc > 0.7:\n",
    "                # Good performance - more separation between classes\n",
    "                predictions = np.where(true_labels == 1, \n",
    "                                     base_predictions + 0.2, \n",
    "                                     base_predictions - 0.2)\n",
    "            else:\n",
    "                # Poor performance - less separation\n",
    "                predictions = base_predictions\n",
    "            \n",
    "            # Clip predictions to [0, 1]\n",
    "            predictions = np.clip(predictions, 0, 1)\n",
    "            \n",
    "            # Create scatter plot\n",
    "            scatter = ax.scatter(coords[:, 0], coords[:, 1], c=predictions, \n",
    "                               cmap='RdYlBu', alpha=0.7, s=30, edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Add presence/absence markers\n",
    "            presence_mask = true_labels == 1\n",
    "            absence_mask = true_labels == 0\n",
    "            \n",
    "            ax.scatter(coords[presence_mask, 0], coords[presence_mask, 1], \n",
    "                      c='green', marker='^', s=50, alpha=0.8, label='Presence', edgecolors='black')\n",
    "            ax.scatter(coords[absence_mask, 0], coords[absence_mask, 1], \n",
    "                      c='red', marker='o', s=30, alpha=0.6, label='Absence', edgecolors='black')\n",
    "            \n",
    "            # Set title with performance metrics\n",
    "            n_vars = result['n_variables']\n",
    "            test_auc = result['performance']['test_auc']\n",
    "            spatial_bias = result['bias_assessment']['test']['overall_bias']['overall_bias']\n",
    "            \n",
    "            # Check if this is the optimal set\n",
    "            is_optimal = iteration == optimal_results['optimal_iteration']\n",
    "            title_color = 'red' if is_optimal else 'black'\n",
    "            title_weight = 'bold' if is_optimal else 'normal'\n",
    "            \n",
    "            ax.set_title(f'{iteration}\\n({n_vars} vars, AUC: {test_auc:.3f}, Bias: {spatial_bias:.3f})', \n",
    "                        fontweight=title_weight, color=title_color)\n",
    "            \n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add colorbar\n",
    "            plt.colorbar(scatter, ax=ax, label='Prediction Probability')\n",
    "            \n",
    "            # Add legend only to first subplot\n",
    "            if i == 0:\n",
    "                ax.legend(loc='upper right', fontsize=8)\n",
    "            \n",
    "            # Add optimal indicator\n",
    "            if is_optimal:\n",
    "                ax.text(0.02, 0.98, 'OPTIMAL', transform=ax.transAxes, \n",
    "                       fontsize=12, fontweight='bold', color='red',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8),\n",
    "                       verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create interactive spatial maps\n",
    "print(\"Creating interactive spatial performance maps...\")\n",
    "spatial_maps_fig = create_interactive_spatial_maps(\n",
    "    spatial_iteration_results, optimal_results, test\n",
    ")\n",
    "\n",
    "# Display the spatial maps\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE DASHBOARD-STYLE VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_comprehensive_dashboard(spatial_comparison, optimal_results, spatial_iteration_results, \n",
    "                                 removal_results, train_gdf, test_gdf):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard-style visualization combining all analyses.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spatial_comparison : dict\n",
    "        Comparison results across variable sets\n",
    "    optimal_results : dict\n",
    "        Optimal variable set identification results\n",
    "    spatial_iteration_results : dict\n",
    "        Detailed results for each variable set\n",
    "    removal_results : dict\n",
    "        Results from iterative variable removal\n",
    "    train_gdf, test_gdf : GeoDataFrames\n",
    "        Training and test data with spatial information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Comprehensive dashboard figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create large dashboard figure\n",
    "    fig = plt.figure(figsize=(28, 20))\n",
    "    fig.suptitle('COMPREHENSIVE SPATIAL SPREAD & VARIABLE IMPORTANCE ANALYSIS DASHBOARD', \n",
    "                 fontsize=24, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Create complex grid layout\n",
    "    gs = fig.add_gridspec(5, 6, hspace=0.4, wspace=0.3,\n",
    "                         height_ratios=[1, 1, 1, 1, 1], width_ratios=[1, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    iterations = spatial_comparison['iterations']\n",
    "    n_vars = spatial_comparison['n_variables']\n",
    "    optimal_idx = optimal_results['optimal_idx']\n",
    "    \n",
    "    # 1. EXECUTIVE SUMMARY (Top Left - Large)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Create executive summary\n",
    "    optimal_result = spatial_iteration_results[optimal_results['optimal_iteration']]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    ðŸŽ¯ EXECUTIVE SUMMARY - OPTIMAL VARIABLE SET IDENTIFIED\n",
    "    \n",
    "    ðŸ“Š OPTIMAL CONFIGURATION:\n",
    "    â€¢ Variable Set: {optimal_results['optimal_iteration']}\n",
    "    â€¢ Number of Variables: {optimal_results['optimal_n_variables']}\n",
    "    â€¢ Composite Score: {optimal_results['optimal_score']:.4f}\n",
    "    â€¢ Variables: {', '.join(optimal_results['optimal_variables'])}\n",
    "    \n",
    "    ðŸ“ˆ PERFORMANCE METRICS:\n",
    "    â€¢ Test AUC: {optimal_result['performance']['test_auc']:.3f}\n",
    "    â€¢ Test AUC (Weighted): {optimal_result['performance']['test_auc_weighted']:.3f}\n",
    "    â€¢ Performance Drop from Full Set: {((spatial_comparison['performance']['test_auc'][0] - optimal_result['performance']['test_auc']) / spatial_comparison['performance']['test_auc'][0] * 100):.1f}%\n",
    "    \n",
    "    ðŸŒ SPATIAL CHARACTERISTICS:\n",
    "    â€¢ Spatial Extent: {optimal_result['spatial_metrics']['test'].get('presence_area_approx', 0):.4f}\n",
    "    â€¢ Moran's I (Autocorrelation): {optimal_result['autocorrelation']['test'].get('morans_i', 0):.3f}\n",
    "    â€¢ Spatial Bias: {optimal_result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\n",
    "    â€¢ Spatial Pattern: {interpret_morans_i(optimal_result['autocorrelation']['test'].get('morans_i', 0))}\n",
    "    \n",
    "    ðŸ† TOP 3 ALTERNATIVES:\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (iteration, score) in enumerate(zip(optimal_results['top_3_iterations'][:3], optimal_results['top_3_scores'][:3])):\n",
    "        result = spatial_iteration_results[iteration]\n",
    "        summary_text += f\"    {i+1}. {iteration}: {result['n_variables']} vars, Score: {score:.3f}, AUC: {result['performance']['test_auc']:.3f}\\n\"\n",
    "    \n",
    "    ax1.text(0.02, 0.98, summary_text, transform=ax1.transAxes, fontsize=12,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.9, pad=1))\n",
    "    \n",
    "    # 2. PERFORMANCE EVOLUTION (Top Center)\n",
    "    ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "    \n",
    "    # Performance vs variables with annotations\n",
    "    ax2.plot(n_vars, spatial_comparison['performance']['test_auc'], 'o-', \n",
    "             color='tab:orange', linewidth=4, markersize=10, label='Test AUC')\n",
    "    ax2.plot(n_vars, spatial_comparison['performance']['train_auc'], 's-', \n",
    "             color='tab:blue', linewidth=3, markersize=8, alpha=0.7, label='Train AUC')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax2.scatter(n_vars[optimal_idx], spatial_comparison['performance']['test_auc'][optimal_idx], \n",
    "               s=400, color='red', marker='*', zorder=10, label='Optimal')\n",
    "    \n",
    "    # Add performance drop lines\n",
    "    initial_auc = spatial_comparison['performance']['test_auc'][0]\n",
    "    ax2.axhline(y=initial_auc * 0.95, color='orange', linestyle='--', alpha=0.7, label='5% Drop')\n",
    "    ax2.axhline(y=initial_auc * 0.90, color='red', linestyle='--', alpha=0.7, label='10% Drop')\n",
    "    \n",
    "    ax2.set_xlabel('Number of Variables', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('AUC Score', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Model Performance Evolution', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.invert_xaxis()\n",
    "    \n",
    "    # 3. SPATIAL BIAS ANALYSIS (Top Right)\n",
    "    ax3 = fig.add_subplot(gs[0, 4:])\n",
    "    \n",
    "    # Spatial bias heatmap\n",
    "    bias_data = []\n",
    "    for i, iteration in enumerate(iterations):\n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            geo_bias = result['bias_assessment']['test'].get('geographic_bias', {})\n",
    "            bias_row = []\n",
    "            for quad in ['NW', 'NE', 'SW', 'SE']:\n",
    "                if quad in geo_bias:\n",
    "                    bias_row.append(geo_bias[quad]['bias'])\n",
    "                else:\n",
    "                    bias_row.append(0)\n",
    "            bias_data.append(bias_row)\n",
    "    \n",
    "    if bias_data:\n",
    "        bias_array = np.array(bias_data)\n",
    "        im = ax3.imshow(bias_array, cmap='RdBu_r', aspect='auto')\n",
    "        ax3.set_xticks(range(4))\n",
    "        ax3.set_xticklabels(['NW', 'NE', 'SW', 'SE'], fontsize=10, fontweight='bold')\n",
    "        ax3.set_yticks(range(len(iterations)))\n",
    "        ax3.set_yticklabels([f'{iter}\\n({n_vars[i]} vars)' for i, iter in enumerate(iterations)], fontsize=9)\n",
    "        ax3.set_xlabel('Geographic Quadrant', fontsize=12, fontweight='bold')\n",
    "        ax3.set_ylabel('Variable Set Iteration', fontsize=12, fontweight='bold')\n",
    "        ax3.set_title('Spatial Bias Heatmap', fontsize=14, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax3, label='Bias')\n",
    "    \n",
    "    # 4. VARIABLE IMPORTANCE EVOLUTION (Second Row Left)\n",
    "    ax4 = fig.add_subplot(gs[1, :3])\n",
    "    \n",
    "    # Plot variable importance evolution\n",
    "    all_variables = set()\n",
    "    for iteration in iterations:\n",
    "        if iteration in removal_results['importance_rankings']:\n",
    "            all_variables.update(removal_results['importance_rankings'][iteration]['variables'])\n",
    "    \n",
    "    all_variables = list(all_variables)\n",
    "    importance_matrix = np.zeros((len(iterations), len(all_variables)))\n",
    "    \n",
    "    for i, iteration in enumerate(iterations):\n",
    "        if iteration in removal_results['importance_rankings']:\n",
    "            ranking = removal_results['importance_rankings'][iteration]['sorted_ranking']\n",
    "            for j, var in enumerate(all_variables):\n",
    "                for var_name, importance in ranking:\n",
    "                    if var_name == var:\n",
    "                        importance_matrix[i, j] = importance\n",
    "                        break\n",
    "    \n",
    "    # Plot with different colors for each variable\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(all_variables)))\n",
    "    for j, (var, color) in enumerate(zip(all_variables, colors)):\n",
    "        if np.any(importance_matrix[:, j] > 0):\n",
    "            ax4.plot(n_vars, importance_matrix[:, j], 'o-', \n",
    "                    label=var, linewidth=2, markersize=6, color=color, alpha=0.8)\n",
    "    \n",
    "    ax4.set_xlabel('Number of Variables', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('Variable Importance', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('Variable Importance Evolution Across Iterations', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.invert_xaxis()\n",
    "    \n",
    "    # 5. SPATIAL CHARACTERISTICS (Second Row Right)\n",
    "    ax5 = fig.add_subplot(gs[1, 3:])\n",
    "    \n",
    "    # Dual y-axis plot for spatial characteristics\n",
    "    ax5_twin = ax5.twinx()\n",
    "    \n",
    "    # Spatial extent\n",
    "    line1 = ax5.plot(n_vars, spatial_comparison['spatial_extent']['test'], \n",
    "                     'o-', color='tab:green', linewidth=4, markersize=10, label='Spatial Extent')\n",
    "    ax5.set_ylabel('Spatial Extent', color='tab:green', fontsize=12, fontweight='bold')\n",
    "    ax5.tick_params(axis='y', labelcolor='tab:green')\n",
    "    \n",
    "    # Moran's I\n",
    "    line2 = ax5_twin.plot(n_vars, spatial_comparison['spatial_autocorrelation']['test_morans_i'], \n",
    "                          's-', color='tab:purple', linewidth=4, markersize=10, label='Moran\\'s I')\n",
    "    ax5_twin.set_ylabel('Moran\\'s I (Autocorrelation)', color='tab:purple', fontsize=12, fontweight='bold')\n",
    "    ax5_twin.tick_params(axis='y', labelcolor='tab:purple')\n",
    "    \n",
    "    # Highlight optimal point\n",
    "    ax5.scatter(n_vars[optimal_idx], spatial_comparison['spatial_extent']['test'][optimal_idx], \n",
    "               s=400, color='red', marker='*', zorder=10)\n",
    "    ax5_twin.scatter(n_vars[optimal_idx], spatial_comparison['spatial_autocorrelation']['test_morans_i'][optimal_idx], \n",
    "                    s=400, color='red', marker='*', zorder=10)\n",
    "    \n",
    "    ax5.set_xlabel('Number of Variables', fontsize=12, fontweight='bold')\n",
    "    ax5.set_title('Spatial Characteristics Evolution', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.invert_xaxis()\n",
    "    \n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax5.legend(lines, labels, loc='upper right', fontsize=10)\n",
    "    \n",
    "    # 6. COMPOSITE SCORE ANALYSIS (Third Row Left)\n",
    "    ax6 = fig.add_subplot(gs[2, :2])\n",
    "    \n",
    "    composite_scores = [score['composite_score'] for score in optimal_results['detailed_scores']]\n",
    "    bars = ax6.bar(range(len(composite_scores)), composite_scores, \n",
    "                   color=['red' if i == optimal_idx else 'tab:blue' for i in range(len(composite_scores))],\n",
    "                   alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax6.set_xlabel('Variable Set Iteration', fontsize=12, fontweight='bold')\n",
    "    ax6.set_ylabel('Composite Score', fontsize=12, fontweight='bold')\n",
    "    ax6.set_title('Composite Score by Variable Set', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xticks(range(len(iterations)))\n",
    "    ax6.set_xticklabels([f'{iter}\\n({n_vars[i]} vars)' for i, iter in enumerate(iterations)], \n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add score values on bars\n",
    "    for i, (bar, score) in enumerate(zip(bars, composite_scores)):\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # 7. CORRELATION MATRIX (Third Row Center)\n",
    "    ax7 = fig.add_subplot(gs[2, 2:4])\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    metrics_data = {\n",
    "        'Test AUC': spatial_comparison['performance']['test_auc'],\n",
    "        'Spatial Extent': spatial_comparison['spatial_extent']['test'],\n",
    "        'Moran\\'s I': spatial_comparison['spatial_autocorrelation']['test_morans_i'],\n",
    "        'Spatial Bias': [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']],\n",
    "        'N Variables': n_vars\n",
    "    }\n",
    "    \n",
    "    corr_matrix = np.corrcoef([metrics_data[key] for key in metrics_data.keys()])\n",
    "    \n",
    "    im = ax7.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    ax7.set_xticks(range(len(metrics_data)))\n",
    "    ax7.set_yticks(range(len(metrics_data)))\n",
    "    ax7.set_xticklabels(list(metrics_data.keys()), rotation=45, ha='right', fontsize=10)\n",
    "    ax7.set_yticklabels(list(metrics_data.keys()), fontsize=10)\n",
    "    ax7.set_title('Metrics Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add correlation values as text\n",
    "    for i in range(len(metrics_data)):\n",
    "        for j in range(len(metrics_data)):\n",
    "            text = ax7.text(j, i, f'{corr_matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax7, label='Correlation')\n",
    "    \n",
    "    # 8. RADAR CHART (Third Row Right)\n",
    "    ax8 = fig.add_subplot(gs[2, 4:], projection='polar')\n",
    "    \n",
    "    # Create radar chart for top 3 variable sets\n",
    "    top_3_indices = np.argsort(composite_scores)[-3:][::-1]\n",
    "    \n",
    "    radar_metrics = ['Test AUC', 'Spatial Extent', 'Low Bias', 'Moran\\'s I', 'N Variables']\n",
    "    angles = np.linspace(0, 2 * np.pi, len(radar_metrics), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    for idx, color in zip(top_3_indices, colors):\n",
    "        values = [\n",
    "            spatial_comparison['performance']['test_auc'][idx],\n",
    "            spatial_comparison['spatial_extent']['test'][idx] / max(spatial_comparison['spatial_extent']['test']),\n",
    "            1 - abs(spatial_comparison['spatial_bias']['test_overall_bias'][idx]) / max([abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']]),\n",
    "            abs(spatial_comparison['spatial_autocorrelation']['test_morans_i'][idx]) / max([abs(mi) for mi in spatial_comparison['spatial_autocorrelation']['test_morans_i']]),\n",
    "            spatial_comparison['n_variables'][idx] / max(spatial_comparison['n_variables'])\n",
    "        ]\n",
    "        values += values[:1]\n",
    "        \n",
    "        ax8.plot(angles, values, 'o-', linewidth=3, label=f'{iterations[idx]} ({n_vars[idx]} vars)', color=color)\n",
    "        ax8.fill(angles, values, alpha=0.25, color=color)\n",
    "    \n",
    "    ax8.set_xticks(angles[:-1])\n",
    "    ax8.set_xticklabels(radar_metrics, fontsize=10)\n",
    "    ax8.set_ylim(0, 1)\n",
    "    ax8.set_title('Top 3 Variable Sets Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax8.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=9)\n",
    "    ax8.grid(True)\n",
    "    \n",
    "    # 9. SPATIAL PERFORMANCE MAPS (Fourth Row)\n",
    "    for i, (idx, color) in enumerate(zip(top_3_indices, ['red', 'blue', 'green'])):\n",
    "        ax = fig.add_subplot(gs[3, i*2:(i+1)*2])\n",
    "        \n",
    "        iteration = iterations[idx]\n",
    "        if iteration in spatial_iteration_results:\n",
    "            result = spatial_iteration_results[iteration]\n",
    "            \n",
    "            # Get coordinates\n",
    "            coords = np.array([[geom.x, geom.y] for geom in test_gdf.geometry])\n",
    "            true_labels = test_gdf['class'].values\n",
    "            \n",
    "            # Create synthetic predictions based on performance\n",
    "            test_auc = result['performance']['test_auc']\n",
    "            base_predictions = np.random.random(len(coords))\n",
    "            \n",
    "            if test_auc > 0.7:\n",
    "                predictions = np.where(true_labels == 1, base_predictions + 0.2, base_predictions - 0.2)\n",
    "            else:\n",
    "                predictions = base_predictions\n",
    "            \n",
    "            predictions = np.clip(predictions, 0, 1)\n",
    "            \n",
    "            # Create scatter plot\n",
    "            scatter = ax.scatter(coords[:, 0], coords[:, 1], c=predictions, \n",
    "                               cmap='RdYlBu', alpha=0.7, s=20, edgecolors='black', linewidth=0.3)\n",
    "            \n",
    "            # Add presence/absence markers\n",
    "            presence_mask = true_labels == 1\n",
    "            absence_mask = true_labels == 0\n",
    "            \n",
    "            ax.scatter(coords[presence_mask, 0], coords[presence_mask, 1], \n",
    "                      c='green', marker='^', s=30, alpha=0.8, label='Presence')\n",
    "            ax.scatter(coords[absence_mask, 0], coords[absence_mask, 1], \n",
    "                      c='red', marker='o', s=15, alpha=0.6, label='Absence')\n",
    "            \n",
    "            # Set title\n",
    "            n_vars_iter = result['n_variables']\n",
    "            test_auc_iter = result['performance']['test_auc']\n",
    "            spatial_bias_iter = result['bias_assessment']['test']['overall_bias']['overall_bias']\n",
    "            \n",
    "            is_optimal = iteration == optimal_results['optimal_iteration']\n",
    "            title_color = 'red' if is_optimal else 'black'\n",
    "            title_weight = 'bold' if is_optimal else 'normal'\n",
    "            \n",
    "            ax.set_title(f'{iteration}\\n({n_vars_iter} vars, AUC: {test_auc_iter:.3f}, Bias: {spatial_bias_iter:.3f})', \n",
    "                        fontweight=title_weight, color=title_color, fontsize=12)\n",
    "            \n",
    "            ax.set_xlabel('Longitude', fontsize=10)\n",
    "            ax.set_ylabel('Latitude', fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add colorbar\n",
    "            plt.colorbar(scatter, ax=ax, label='Prediction')\n",
    "            \n",
    "            # Add optimal indicator\n",
    "            if is_optimal:\n",
    "                ax.text(0.02, 0.98, 'OPTIMAL', transform=ax.transAxes, \n",
    "                       fontsize=14, fontweight='bold', color='red',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8),\n",
    "                       verticalalignment='top')\n",
    "    \n",
    "    # 10. RECOMMENDATIONS AND NEXT STEPS (Fifth Row)\n",
    "    ax10 = fig.add_subplot(gs[4, :])\n",
    "    ax10.axis('off')\n",
    "    \n",
    "    recommendations_text = f\"\"\"\n",
    "    ðŸŽ¯ RECOMMENDATIONS & NEXT STEPS\n",
    "    \n",
    "    âœ… IMMEDIATE ACTIONS:\n",
    "    1. IMPLEMENT OPTIMAL VARIABLE SET: Use {optimal_results['optimal_iteration']} with {optimal_results['optimal_n_variables']} variables\n",
    "       â€¢ Variables: {', '.join(optimal_results['optimal_variables'])}\n",
    "       â€¢ Expected Performance: Test AUC = {optimal_result['performance']['test_auc']:.3f}\n",
    "       â€¢ Spatial Bias: {optimal_result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\n",
    "    \n",
    "    2. VALIDATION STRATEGY:\n",
    "       â€¢ Test on independent validation dataset\n",
    "       â€¢ Cross-validate spatial transferability across different regions\n",
    "       â€¢ Assess temporal stability of variable importance\n",
    "    \n",
    "    3. ALTERNATIVE CONSIDERATIONS:\n",
    "       â€¢ If fewer variables needed: Consider {optimal_results['top_3_iterations'][1]} ({spatial_iteration_results[optimal_results['top_3_iterations'][1]]['n_variables']} vars)\n",
    "       â€¢ If higher performance needed: Consider {optimal_results['top_3_iterations'][2]} ({spatial_iteration_results[optimal_results['top_3_iterations'][2]]['n_variables']} vars)\n",
    "    \n",
    "    ðŸ“Š KEY INSIGHTS:\n",
    "    â€¢ Performance vs Variables Correlation: {np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['performance']['test_auc'])[0, 1]:.3f}\n",
    "    â€¢ Spatial Bias vs Variables Correlation: {np.corrcoef(spatial_comparison['n_variables'], [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']])[0, 1]:.3f}\n",
    "    â€¢ Optimal Balance Achieved: Performance, spatial coverage, and bias minimization\n",
    "    \n",
    "    ðŸ”¬ SCIENTIFIC IMPLICATIONS:\n",
    "    â€¢ Variable selection significantly impacts spatial model performance\n",
    "    â€¢ Spatial bias can be minimized through careful variable selection\n",
    "    â€¢ Optimal variable sets provide good balance between complexity and performance\n",
    "    â€¢ Spatial autocorrelation patterns vary with variable selection\n",
    "    \n",
    "    ðŸ“ˆ FUTURE RESEARCH DIRECTIONS:\n",
    "    â€¢ Investigate temporal stability of optimal variable sets\n",
    "    â€¢ Explore ensemble approaches combining multiple variable sets\n",
    "    â€¢ Develop automated variable selection for different spatial scales\n",
    "    â€¢ Integrate ecological knowledge with statistical optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    ax10.text(0.02, 0.98, recommendations_text, transform=ax10.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9, pad=1))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "print(\"Creating comprehensive dashboard-style visualization...\")\n",
    "dashboard_fig = create_comprehensive_dashboard(\n",
    "    spatial_comparison, optimal_results, spatial_iteration_results, \n",
    "    removal_results, train, test\n",
    ")\n",
    "\n",
    "# Display the dashboard\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba608f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all enhanced visualizations\n",
    "if savefig:\n",
    "    # Save enhanced spatial visualization\n",
    "    if Future:\n",
    "        if models:\n",
    "            enhanced_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_enhanced-spatial-analysis_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            enhanced_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_enhanced-spatial-analysis_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            enhanced_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_enhanced-spatial-analysis_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            enhanced_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_enhanced-spatial-analysis_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    enhanced_fig.savefig(enhanced_file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Enhanced spatial analysis figure saved to: {enhanced_file_path}\")\n",
    "    \n",
    "    # Save interactive spatial maps\n",
    "    if Future:\n",
    "        if models:\n",
    "            maps_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_interactive-spatial-maps_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            maps_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_interactive-spatial-maps_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            maps_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_interactive-spatial-maps_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            maps_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_interactive-spatial-maps_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    spatial_maps_fig.savefig(maps_file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Interactive spatial maps figure saved to: {maps_file_path}\")\n",
    "    \n",
    "    # Save comprehensive dashboard\n",
    "    if Future:\n",
    "        if models:\n",
    "            dashboard_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive-dashboard_%s_%s_%s_%s_%s_future.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            dashboard_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive-dashboard_%s_%s_%s_%s_future.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    else:\n",
    "        if models:\n",
    "            dashboard_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive-dashboard_%s_%s_%s_%s_%s.png' % (specie, training, bio, model_prefix, iteration)\n",
    "            )\n",
    "        else:\n",
    "            dashboard_file_path = os.path.join(\n",
    "                figs_path,\n",
    "                '06_comprehensive-dashboard_%s_%s_%s_%s.png' % (specie, training, bio, iteration)\n",
    "            )\n",
    "    \n",
    "    dashboard_fig.savefig(dashboard_file_path, transparent=True, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Comprehensive dashboard figure saved to: {dashboard_file_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL COMPREHENSIVE SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŽ¯ COMPREHENSIVE SPATIAL SPREAD & VARIABLE IMPORTANCE ANALYSIS - FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\\nðŸ“Š ANALYSIS OVERVIEW:\")\n",
    "print(f\"Species: {specie}\")\n",
    "print(f\"Training Region: {training}\")\n",
    "print(f\"Test Region: {interest}\")\n",
    "print(f\"Bioclimatic Variable: {bio}\")\n",
    "print(f\"Iteration: {iteration}\")\n",
    "print(f\"Total Variable Sets Analyzed: {len(spatial_iteration_results)}\")\n",
    "\n",
    "print(f\"\\nðŸ† OPTIMAL VARIABLE SET IDENTIFIED:\")\n",
    "print(f\"â€¢ Iteration: {optimal_results['optimal_iteration']}\")\n",
    "print(f\"â€¢ Number of Variables: {optimal_results['optimal_n_variables']}\")\n",
    "print(f\"â€¢ Composite Score: {optimal_results['optimal_score']:.4f}\")\n",
    "print(f\"â€¢ Variables: {', '.join(optimal_results['optimal_variables'])}\")\n",
    "\n",
    "optimal_result = spatial_iteration_results[optimal_results['optimal_iteration']]\n",
    "print(f\"\\nðŸ“ˆ OPTIMAL SET PERFORMANCE:\")\n",
    "print(f\"â€¢ Test AUC: {optimal_result['performance']['test_auc']:.3f}\")\n",
    "print(f\"â€¢ Test AUC (Weighted): {optimal_result['performance']['test_auc_weighted']:.3f}\")\n",
    "print(f\"â€¢ Spatial Bias: {optimal_result['bias_assessment']['test']['overall_bias']['overall_bias']:.4f}\")\n",
    "print(f\"â€¢ Spatial Extent: {optimal_result['spatial_metrics']['test'].get('presence_area_approx', 0):.4f}\")\n",
    "print(f\"â€¢ Moran's I: {optimal_result['autocorrelation']['test'].get('morans_i', 0):.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ¥ˆ TOP 3 ALTERNATIVE VARIABLE SETS:\")\n",
    "for i, (iteration, score) in enumerate(zip(optimal_results['top_3_iterations'][:3], optimal_results['top_3_scores'][:3])):\n",
    "    result = spatial_iteration_results[iteration]\n",
    "    print(f\"{i+1}. {iteration}: {result['n_variables']} vars, Score: {score:.3f}, AUC: {result['performance']['test_auc']:.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ” KEY INSIGHTS:\")\n",
    "print(f\"â€¢ Performance vs Variables Correlation: {np.corrcoef(spatial_comparison['n_variables'], spatial_comparison['performance']['test_auc'])[0, 1]:.3f}\")\n",
    "print(f\"â€¢ Spatial Bias vs Variables Correlation: {np.corrcoef(spatial_comparison['n_variables'], [abs(b) for b in spatial_comparison['spatial_bias']['test_overall_bias']])[0, 1]:.3f}\")\n",
    "print(f\"â€¢ Performance Drop from Full Set: {((spatial_comparison['performance']['test_auc'][0] - optimal_result['performance']['test_auc']) / spatial_comparison['performance']['test_auc'][0] * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“ FILES GENERATED:\")\n",
    "print(f\"â€¢ Enhanced Spatial Analysis Visualization (24x20 figure)\")\n",
    "print(f\"â€¢ Interactive Spatial Performance Maps (18x12 figure)\")\n",
    "print(f\"â€¢ Comprehensive Dashboard (28x20 figure)\")\n",
    "print(f\"â€¢ Spatial Iteration Analysis Summary (JSON)\")\n",
    "print(f\"â€¢ All figures saved with appropriate naming conventions\")\n",
    "\n",
    "print(f\"\\nâœ… RECOMMENDATIONS:\")\n",
    "print(f\"1. IMPLEMENT: Use {optimal_results['optimal_iteration']} with {optimal_results['optimal_n_variables']} variables\")\n",
    "print(f\"2. VALIDATE: Test on independent data and different spatial regions\")\n",
    "print(f\"3. MONITOR: Track spatial bias and performance over time\")\n",
    "print(f\"4. DOCUMENT: Record variable selection rationale for reproducibility\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŽ‰ COMPREHENSIVE ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bias_bw",
   "language": "python",
   "name": "bias_bw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
